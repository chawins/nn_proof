{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from skimage.transform import resize\n",
    "from imageio import imread, imwrite\n",
    "import pandas as pd\n",
    "import glob\n",
    "import pickle\n",
    "import keras.backend as K\n",
    "\n",
    "from stn.conv_model import conv_model\n",
    "from stn.conv_model import conv_model_no_color_adjust\n",
    "from sklearn.utils import resample\n",
    "from lib.utils import load_gtsrb\n",
    "from keras.metrics import sparse_categorical_accuracy\n",
    "\n",
    "from parameters import *\n",
    "from small_net import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "n_train = len(X_train)\n",
    "n_val = int(n_train*0.1)\n",
    "ind = np.arange(n_train)\n",
    "np.random.shuffle(ind)\n",
    "# X_val, y_val = X_train[ind[:n_val]], y_train[ind[:n_val]]\n",
    "# X_train, y_train = X_train[ind[n_val:]], y_train[ind[n_val:]]\n",
    "X_val, y_val = X_test, y_test\n",
    "\n",
    "data = (X_train[:, :, :, np.newaxis], y_train, \n",
    "        X_val[:, :, :, np.newaxis], y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa719fc0d30>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleverhans.utils import set_log_level\n",
    "import logging\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "y_val = to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from hinge_net import HingeNet\n",
    "\n",
    "hingenet = HingeNet(\"hingenet_v1\", [28, 28, 1], [10], learning_rate=1e-3, \n",
    "                    loss=\"hinge\", margin=1, load_model=True, \n",
    "                    save_path=\"model/hingenet_v1.h5\")\n",
    "# hingenet.train_model(sess, data, n_epoch=20, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9906, 0.024141100704669953)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hingenet.eval_model(sess, (X_test[:, :, :, np.newaxis], np.argmax(y_test, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Least likeley class\n",
    "n_attack = 1000\n",
    "X_atk = X_test[:, :, :, np.newaxis][:n_attack]\n",
    "y_atk = np.argmax(y_test[:n_attack], axis=1)\n",
    "\n",
    "y_pred = hingenet.predict_model(sess, X_atk)\n",
    "y_target = to_categorical(np.argmin(y_pred, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.989, 0.023215327084064482)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hingenet.eval_model(sess, (X_atk, y_atk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Softmax xent\n",
    "\n",
    "keras.backend.set_learning_phase(0)\n",
    "set_log_level(logging.DEBUG)\n",
    "\n",
    "from lib.my_pgd import ProjectedGradientDescent\n",
    "\n",
    "pgd_params = {'eps': 0.3,\n",
    "              'eps_iter': 0.05,\n",
    "              'clip_min': 0.,\n",
    "              'clip_max': 1.,\n",
    "              'ord': np.inf, \n",
    "              'nb_iter': 10,\n",
    "              'rand_init': True,\n",
    "              'batch_size': n_attack,\n",
    "              'y_target': y_target}\n",
    "pgd = ProjectedGradientDescent(hingenet, sess=sess)\n",
    "\n",
    "y_tar = np.argmax(y_target, axis=1)\n",
    "best_adv = np.zeros_like(X_atk)\n",
    "best_dist = np.zeros([n_attack]) + 1e5\n",
    "for i in range(10):\n",
    "    adv = pgd.generate_np(X_atk, **pgd_params)\n",
    "    print(hingenet.eval_model(sess, (adv, y_tar)))\n",
    "    dist = np.sqrt(np.sum((adv - X_atk)**2, (1, 2, 3)))\n",
    "    print(np.mean(dist))\n",
    "    pred = hingenet.predict_model(sess, adv)\n",
    "    y_pred = np.argmax(pred, axis=1)\n",
    "    for j in range(n_attack):\n",
    "        if y_pred[j] == y_tar[j] and dist[j] < best_dist[j]:\n",
    "            best_adv[j] = adv[j]\n",
    "            best_dist[j] = dist[j]\n",
    "print(np.mean(best_dist < 1e5))\n",
    "print(np.mean(best_dist[best_dist < 1e5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Hinge\n",
    "\n",
    "keras.backend.set_learning_phase(0)\n",
    "set_log_level(logging.DEBUG)\n",
    "\n",
    "from lib.my_pgd import ProjectedGradientDescent\n",
    "\n",
    "pgd_params = {'eps': 0.3,\n",
    "              'eps_iter': 0.05,\n",
    "              'clip_min': 0.,\n",
    "              'clip_max': 1.,\n",
    "              'ord': np.inf, \n",
    "              'nb_iter': 10,\n",
    "              'rand_init': True,\n",
    "              'batch_size': n_attack,\n",
    "              'y_target': y_target}\n",
    "pgd = ProjectedGradientDescent(hingenet, sess=sess)\n",
    "\n",
    "y_tar = np.argmax(y_target, axis=1)\n",
    "best_adv = np.zeros_like(X_atk)\n",
    "best_dist = np.zeros([n_attack]) + 1e5\n",
    "for i in range(10):\n",
    "    adv = pgd.generate_np(X_atk, **pgd_params)\n",
    "    print(hingenet.eval_model(sess, (adv, y_tar)))\n",
    "    dist = np.sqrt(np.sum((adv - X_atk)**2, (1, 2, 3)))\n",
    "    print(np.mean(dist))\n",
    "    pred = hingenet.predict_model(sess, adv)\n",
    "    y_pred = np.argmax(pred, axis=1)\n",
    "    for j in range(n_attack):\n",
    "        if y_pred[j] == y_tar[j] and dist[j] < best_dist[j]:\n",
    "            best_adv[j] = adv[j]\n",
    "            best_dist[j] = dist[j]\n",
    "print(np.mean(best_dist < 1e5))\n",
    "print(np.mean(best_dist[best_dist < 1e5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2018-10-25 03:44:42,421 cleverhans] Constructing new graph for attack CarliniWagnerL2\n",
      "[DEBUG 2018-10-25 03:44:42,843 cleverhans] Running CWL2 attack on instance 0 of 1000\n",
      "[DEBUG 2018-10-25 03:44:42,975 cleverhans]   Binary search step 0 of 10\n",
      "[DEBUG 2018-10-25 03:44:43,210 cleverhans]     Iteration 0 of 1000: loss=16.6 l2=0\n",
      "[DEBUG 2018-10-25 03:44:46,814 cleverhans]     Iteration 100 of 1000: loss=7.64 l2=5.01\n",
      "[DEBUG 2018-10-25 03:44:50,281 cleverhans]     Iteration 200 of 1000: loss=7.19 l2=4.98\n",
      "[DEBUG 2018-10-25 03:44:53,685 cleverhans]     Iteration 300 of 1000: loss=6.18 l2=4.68\n",
      "[DEBUG 2018-10-25 03:44:57,083 cleverhans]     Iteration 400 of 1000: loss=5.45 l2=4.36\n",
      "[DEBUG 2018-10-25 03:45:00,423 cleverhans]     Iteration 500 of 1000: loss=4.98 l2=4.15\n",
      "[DEBUG 2018-10-25 03:45:03,698 cleverhans]     Iteration 600 of 1000: loss=4.68 l2=4.01\n",
      "[DEBUG 2018-10-25 03:45:06,946 cleverhans]     Iteration 700 of 1000: loss=4.46 l2=3.89\n",
      "[DEBUG 2018-10-25 03:45:10,110 cleverhans]     Iteration 800 of 1000: loss=4.32 l2=3.81\n",
      "[DEBUG 2018-10-25 03:45:13,254 cleverhans]     Iteration 900 of 1000: loss=4.21 l2=3.76\n",
      "[DEBUG 2018-10-25 03:45:16,355 cleverhans]   Successfully generated adversarial examples on 573 of 1000 instances.\n",
      "[DEBUG 2018-10-25 03:45:16,356 cleverhans]    Mean successful distortion: 1.902\n",
      "[DEBUG 2018-10-25 03:45:16,357 cleverhans]   Binary search step 1 of 10\n",
      "[DEBUG 2018-10-25 03:45:16,375 cleverhans]     Iteration 0 of 1000: loss=72.9 l2=0\n",
      "[DEBUG 2018-10-25 03:45:20,025 cleverhans]     Iteration 100 of 1000: loss=9.55 l2=7.21\n",
      "[DEBUG 2018-10-25 03:45:23,370 cleverhans]     Iteration 200 of 1000: loss=7.68 l2=5.85\n",
      "[DEBUG 2018-10-25 03:45:26,603 cleverhans]     Iteration 300 of 1000: loss=6.64 l2=5.09\n",
      "[DEBUG 2018-10-25 03:45:29,746 cleverhans]     Iteration 400 of 1000: loss=5.96 l2=4.75\n",
      "[DEBUG 2018-10-25 03:45:32,848 cleverhans]     Iteration 500 of 1000: loss=5.46 l2=4.54\n",
      "[DEBUG 2018-10-25 03:45:35,877 cleverhans]     Iteration 600 of 1000: loss=5.13 l2=4.38\n",
      "[DEBUG 2018-10-25 03:45:38,908 cleverhans]     Iteration 700 of 1000: loss=4.93 l2=4.28\n",
      "[DEBUG 2018-10-25 03:45:41,953 cleverhans]     Iteration 800 of 1000: loss=4.77 l2=4.19\n",
      "[DEBUG 2018-10-25 03:45:45,057 cleverhans]     Iteration 900 of 1000: loss=4.67 l2=4.16\n",
      "[DEBUG 2018-10-25 03:45:48,098 cleverhans]   Successfully generated adversarial examples on 998 of 1000 instances.\n",
      "[DEBUG 2018-10-25 03:45:48,099 cleverhans]    Mean successful distortion: 2.038\n",
      "[DEBUG 2018-10-25 03:45:48,101 cleverhans]   Binary search step 2 of 10\n",
      "[DEBUG 2018-10-25 03:45:48,119 cleverhans]     Iteration 0 of 1000: loss=46.2 l2=0\n",
      "[DEBUG 2018-10-25 03:45:51,402 cleverhans]     Iteration 100 of 1000: loss=9.04 l2=6.45\n",
      "[DEBUG 2018-10-25 03:45:54,541 cleverhans]     Iteration 200 of 1000: loss=7.42 l2=5.67\n",
      "[DEBUG 2018-10-25 03:45:57,689 cleverhans]     Iteration 300 of 1000: loss=6.35 l2=4.95\n",
      "[DEBUG 2018-10-25 03:46:00,741 cleverhans]     Iteration 400 of 1000: loss=5.63 l2=4.53\n",
      "[DEBUG 2018-10-25 03:46:03,780 cleverhans]     Iteration 500 of 1000: loss=5.19 l2=4.27\n",
      "[DEBUG 2018-10-25 03:46:06,777 cleverhans]     Iteration 600 of 1000: loss=4.9 l2=4.11\n",
      "[DEBUG 2018-10-25 03:46:09,806 cleverhans]     Iteration 700 of 1000: loss=4.7 l2=4.01\n",
      "[DEBUG 2018-10-25 03:46:12,871 cleverhans]     Iteration 800 of 1000: loss=4.54 l2=3.94\n",
      "[DEBUG 2018-10-25 03:46:15,966 cleverhans]     Iteration 900 of 1000: loss=4.43 l2=3.88\n",
      "[DEBUG 2018-10-25 03:46:18,984 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 03:46:18,985 cleverhans]    Mean successful distortion: 2.011\n",
      "[DEBUG 2018-10-25 03:46:18,986 cleverhans]   Binary search step 3 of 10\n",
      "[DEBUG 2018-10-25 03:46:19,004 cleverhans]     Iteration 0 of 1000: loss=30.1 l2=0\n",
      "[DEBUG 2018-10-25 03:46:22,334 cleverhans]     Iteration 100 of 1000: loss=8.67 l2=5.8\n",
      "[DEBUG 2018-10-25 03:46:25,543 cleverhans]     Iteration 200 of 1000: loss=7.5 l2=5.46\n",
      "[DEBUG 2018-10-25 03:46:28,710 cleverhans]     Iteration 300 of 1000: loss=6.4 l2=4.89\n",
      "[DEBUG 2018-10-25 03:46:31,822 cleverhans]     Iteration 400 of 1000: loss=5.69 l2=4.56\n",
      "[DEBUG 2018-10-25 03:46:34,871 cleverhans]     Iteration 500 of 1000: loss=5.21 l2=4.36\n",
      "[DEBUG 2018-10-25 03:46:37,904 cleverhans]     Iteration 600 of 1000: loss=4.88 l2=4.22\n",
      "[DEBUG 2018-10-25 03:46:40,981 cleverhans]     Iteration 700 of 1000: loss=4.65 l2=4.13\n",
      "[DEBUG 2018-10-25 03:46:44,040 cleverhans]     Iteration 800 of 1000: loss=4.48 l2=4.06\n",
      "[DEBUG 2018-10-25 03:46:47,157 cleverhans]     Iteration 900 of 1000: loss=4.35 l2=3.99\n",
      "[DEBUG 2018-10-25 03:46:50,231 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 03:46:50,233 cleverhans]    Mean successful distortion: 1.994\n",
      "[DEBUG 2018-10-25 03:46:50,234 cleverhans]   Binary search step 4 of 10\n",
      "[DEBUG 2018-10-25 03:46:50,254 cleverhans]     Iteration 0 of 1000: loss=22.2 l2=0\n",
      "[DEBUG 2018-10-25 03:46:53,544 cleverhans]     Iteration 100 of 1000: loss=8.24 l2=5.21\n",
      "[DEBUG 2018-10-25 03:46:56,809 cleverhans]     Iteration 200 of 1000: loss=7.43 l2=5.03\n",
      "[DEBUG 2018-10-25 03:47:00,014 cleverhans]     Iteration 300 of 1000: loss=6.39 l2=4.67\n",
      "[DEBUG 2018-10-25 03:47:03,235 cleverhans]     Iteration 400 of 1000: loss=5.66 l2=4.41\n",
      "[DEBUG 2018-10-25 03:47:06,373 cleverhans]     Iteration 500 of 1000: loss=5.16 l2=4.28\n",
      "[DEBUG 2018-10-25 03:47:09,541 cleverhans]     Iteration 600 of 1000: loss=4.82 l2=4.16\n",
      "[DEBUG 2018-10-25 03:47:12,724 cleverhans]     Iteration 700 of 1000: loss=4.59 l2=4.08\n",
      "[DEBUG 2018-10-25 03:47:15,847 cleverhans]     Iteration 800 of 1000: loss=4.42 l2=4.01\n",
      "[DEBUG 2018-10-25 03:47:19,018 cleverhans]     Iteration 900 of 1000: loss=4.3 l2=3.96\n",
      "[DEBUG 2018-10-25 03:47:22,203 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 03:47:22,204 cleverhans]    Mean successful distortion: 1.985\n",
      "[DEBUG 2018-10-25 03:47:22,206 cleverhans]   Binary search step 5 of 10\n",
      "[DEBUG 2018-10-25 03:47:22,225 cleverhans]     Iteration 0 of 1000: loss=18.9 l2=0\n",
      "[DEBUG 2018-10-25 03:47:25,532 cleverhans]     Iteration 100 of 1000: loss=7.97 l2=4.79\n",
      "[DEBUG 2018-10-25 03:47:28,839 cleverhans]     Iteration 200 of 1000: loss=7.34 l2=4.69\n",
      "[DEBUG 2018-10-25 03:47:32,111 cleverhans]     Iteration 300 of 1000: loss=6.38 l2=4.41\n",
      "[DEBUG 2018-10-25 03:47:35,362 cleverhans]     Iteration 400 of 1000: loss=5.66 l2=4.24\n",
      "[DEBUG 2018-10-25 03:47:38,636 cleverhans]     Iteration 500 of 1000: loss=5.16 l2=4.13\n",
      "[DEBUG 2018-10-25 03:47:41,909 cleverhans]     Iteration 600 of 1000: loss=4.81 l2=4.05\n",
      "[DEBUG 2018-10-25 03:47:45,168 cleverhans]     Iteration 700 of 1000: loss=4.57 l2=4\n",
      "[DEBUG 2018-10-25 03:47:48,433 cleverhans]     Iteration 800 of 1000: loss=4.4 l2=3.95\n",
      "[DEBUG 2018-10-25 03:47:51,701 cleverhans]     Iteration 900 of 1000: loss=4.29 l2=3.9\n",
      "[DEBUG 2018-10-25 03:47:55,048 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 03:47:55,049 cleverhans]    Mean successful distortion: 1.981\n",
      "[DEBUG 2018-10-25 03:47:55,051 cleverhans]   Binary search step 6 of 10\n",
      "[DEBUG 2018-10-25 03:47:55,070 cleverhans]     Iteration 0 of 1000: loss=18 l2=0\n",
      "[DEBUG 2018-10-25 03:47:58,429 cleverhans]     Iteration 100 of 1000: loss=7.86 l2=4.62\n",
      "[DEBUG 2018-10-25 03:48:01,732 cleverhans]     Iteration 200 of 1000: loss=7.31 l2=4.55\n",
      "[DEBUG 2018-10-25 03:48:05,035 cleverhans]     Iteration 300 of 1000: loss=6.37 l2=4.3\n",
      "[DEBUG 2018-10-25 03:48:08,357 cleverhans]     Iteration 400 of 1000: loss=5.67 l2=4.15\n",
      "[DEBUG 2018-10-25 03:48:11,652 cleverhans]     Iteration 500 of 1000: loss=5.17 l2=4.08\n",
      "[DEBUG 2018-10-25 03:48:14,967 cleverhans]     Iteration 600 of 1000: loss=4.83 l2=4.03\n",
      "[DEBUG 2018-10-25 03:48:18,281 cleverhans]     Iteration 700 of 1000: loss=4.59 l2=3.98\n",
      "[DEBUG 2018-10-25 03:48:21,603 cleverhans]     Iteration 800 of 1000: loss=4.41 l2=3.94\n",
      "[DEBUG 2018-10-25 03:48:24,973 cleverhans]     Iteration 900 of 1000: loss=4.28 l2=3.9\n",
      "[DEBUG 2018-10-25 03:48:28,312 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 03:48:28,313 cleverhans]    Mean successful distortion: 1.979\n",
      "[DEBUG 2018-10-25 03:48:28,314 cleverhans]   Binary search step 7 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DEBUG 2018-10-25 03:48:28,332 cleverhans]     Iteration 0 of 1000: loss=17.7 l2=0\n",
      "[DEBUG 2018-10-25 03:48:31,713 cleverhans]     Iteration 100 of 1000: loss=7.82 l2=4.56\n",
      "[DEBUG 2018-10-25 03:48:35,046 cleverhans]     Iteration 200 of 1000: loss=7.27 l2=4.5\n",
      "[DEBUG 2018-10-25 03:48:38,330 cleverhans]     Iteration 300 of 1000: loss=6.36 l2=4.28\n",
      "[DEBUG 2018-10-25 03:48:41,617 cleverhans]     Iteration 400 of 1000: loss=5.67 l2=4.11\n",
      "[DEBUG 2018-10-25 03:48:44,916 cleverhans]     Iteration 500 of 1000: loss=5.18 l2=4.04\n",
      "[DEBUG 2018-10-25 03:48:48,248 cleverhans]     Iteration 600 of 1000: loss=4.83 l2=3.98\n",
      "[DEBUG 2018-10-25 03:48:51,609 cleverhans]     Iteration 700 of 1000: loss=4.58 l2=3.95\n",
      "[DEBUG 2018-10-25 03:48:54,932 cleverhans]     Iteration 800 of 1000: loss=4.42 l2=3.91\n",
      "[DEBUG 2018-10-25 03:48:58,292 cleverhans]     Iteration 900 of 1000: loss=4.29 l2=3.9\n",
      "[DEBUG 2018-10-25 03:49:01,658 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 03:49:01,659 cleverhans]    Mean successful distortion: 1.977\n",
      "[DEBUG 2018-10-25 03:49:01,661 cleverhans]   Binary search step 8 of 10\n",
      "[DEBUG 2018-10-25 03:49:01,679 cleverhans]     Iteration 0 of 1000: loss=17.6 l2=0\n",
      "[DEBUG 2018-10-25 03:49:05,035 cleverhans]     Iteration 100 of 1000: loss=7.81 l2=4.55\n",
      "[DEBUG 2018-10-25 03:49:08,344 cleverhans]     Iteration 200 of 1000: loss=7.27 l2=4.48\n",
      "[DEBUG 2018-10-25 03:49:11,639 cleverhans]     Iteration 300 of 1000: loss=6.36 l2=4.27\n",
      "[DEBUG 2018-10-25 03:49:14,959 cleverhans]     Iteration 400 of 1000: loss=5.67 l2=4.11\n",
      "[DEBUG 2018-10-25 03:49:18,226 cleverhans]     Iteration 500 of 1000: loss=5.17 l2=4.04\n",
      "[DEBUG 2018-10-25 03:49:21,590 cleverhans]     Iteration 600 of 1000: loss=4.83 l2=3.98\n",
      "[DEBUG 2018-10-25 03:49:24,947 cleverhans]     Iteration 700 of 1000: loss=4.59 l2=3.95\n",
      "[DEBUG 2018-10-25 03:49:28,317 cleverhans]     Iteration 800 of 1000: loss=4.42 l2=3.92\n",
      "[DEBUG 2018-10-25 03:49:31,737 cleverhans]     Iteration 900 of 1000: loss=4.29 l2=3.9\n",
      "[DEBUG 2018-10-25 03:49:35,188 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 03:49:35,189 cleverhans]    Mean successful distortion: 1.977\n",
      "[DEBUG 2018-10-25 03:49:35,191 cleverhans]   Binary search step 9 of 10\n",
      "[DEBUG 2018-10-25 03:49:35,209 cleverhans]     Iteration 0 of 1000: loss=17.8 l2=0\n",
      "[DEBUG 2018-10-25 03:49:38,481 cleverhans]     Iteration 100 of 1000: loss=7.85 l2=4.62\n",
      "[DEBUG 2018-10-25 03:49:41,743 cleverhans]     Iteration 200 of 1000: loss=7.28 l2=4.55\n",
      "[DEBUG 2018-10-25 03:49:45,028 cleverhans]     Iteration 300 of 1000: loss=6.36 l2=4.33\n",
      "[DEBUG 2018-10-25 03:49:48,307 cleverhans]     Iteration 400 of 1000: loss=5.67 l2=4.17\n",
      "[DEBUG 2018-10-25 03:49:51,579 cleverhans]     Iteration 500 of 1000: loss=5.16 l2=4.11\n",
      "[DEBUG 2018-10-25 03:49:54,879 cleverhans]     Iteration 600 of 1000: loss=4.82 l2=4.05\n",
      "[DEBUG 2018-10-25 03:49:58,174 cleverhans]     Iteration 700 of 1000: loss=4.57 l2=4.03\n",
      "[DEBUG 2018-10-25 03:50:01,491 cleverhans]     Iteration 800 of 1000: loss=4.39 l2=4\n",
      "[DEBUG 2018-10-25 03:50:04,822 cleverhans]     Iteration 900 of 1000: loss=4.25 l2=3.98\n",
      "[DEBUG 2018-10-25 03:50:08,031 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 03:50:08,032 cleverhans]    Mean successful distortion: 1.976\n"
     ]
    }
   ],
   "source": [
    "keras.backend.set_learning_phase(0)\n",
    "set_log_level(logging.DEBUG)\n",
    "\n",
    "# CarliniWagner attack\n",
    "from lib.my_cw import CarliniWagnerL2\n",
    "\n",
    "attack_iterations = 1000\n",
    "cw_params = {'binary_search_steps': 10,\n",
    "             'max_iterations': attack_iterations,\n",
    "             'learning_rate': 0.1,\n",
    "             'batch_size': n_attack,\n",
    "             'initial_const': 1,\n",
    "             'y_target': y_target}\n",
    "cw = CarliniWagnerL2(hingenet, sess=sess)\n",
    "adv = cw.generate_np(X_atk, **cw_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.91379666\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dist = np.sqrt(np.sum((X_atk - adv)**2, (1, 2, 3)))\n",
    "plt.hist(dist, bins=10, range=(1, 5))\n",
    "print(np.min(dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2018-10-25 03:54:25,789 cleverhans] Constructing new graph for attack CarliniWagnerL2\n",
      "[DEBUG 2018-10-25 03:54:26,251 cleverhans] Running CWL2 attack on instance 0 of 1000\n",
      "[DEBUG 2018-10-25 03:54:26,379 cleverhans]   Binary search step 0 of 10\n",
      "[DEBUG 2018-10-25 03:54:26,626 cleverhans]     Iteration 0 of 500: loss=7.67 l2=0\n",
      "[DEBUG 2018-10-25 03:54:28,390 cleverhans]     Iteration 50 of 500: loss=3.88 l2=2.47\n",
      "[DEBUG 2018-10-25 03:54:30,008 cleverhans]     Iteration 100 of 500: loss=3.77 l2=2.41\n",
      "[DEBUG 2018-10-25 03:54:31,554 cleverhans]     Iteration 150 of 500: loss=3.75 l2=2.41\n",
      "[DEBUG 2018-10-25 03:54:33,097 cleverhans]     Iteration 200 of 500: loss=3.66 l2=2.39\n",
      "[DEBUG 2018-10-25 03:54:34,639 cleverhans]     Iteration 250 of 500: loss=3.47 l2=2.34\n",
      "[DEBUG 2018-10-25 03:54:36,162 cleverhans]     Iteration 300 of 500: loss=3.19 l2=2.31\n",
      "[DEBUG 2018-10-25 03:54:37,642 cleverhans]     Iteration 350 of 500: loss=2.94 l2=2.26\n",
      "[DEBUG 2018-10-25 03:54:39,107 cleverhans]     Iteration 400 of 500: loss=2.74 l2=2.2\n",
      "[DEBUG 2018-10-25 03:54:40,531 cleverhans]     Iteration 450 of 500: loss=2.58 l2=2.14\n",
      "[DEBUG 2018-10-25 03:54:41,933 cleverhans]   Successfully generated adversarial examples on 845 of 1000 instances.\n",
      "[DEBUG 2018-10-25 03:54:41,934 cleverhans]    Mean successful distortion: 1.342\n",
      "[DEBUG 2018-10-25 03:54:41,936 cleverhans]   Binary search step 1 of 10\n",
      "[DEBUG 2018-10-25 03:54:41,954 cleverhans]     Iteration 0 of 500: loss=16.3 l2=0\n",
      "[DEBUG 2018-10-25 03:54:43,715 cleverhans]     Iteration 50 of 500: loss=4.26 l2=2.43\n",
      "[DEBUG 2018-10-25 03:54:45,390 cleverhans]     Iteration 100 of 500: loss=3.68 l2=2.05\n",
      "[DEBUG 2018-10-25 03:54:47,046 cleverhans]     Iteration 150 of 500: loss=3.4 l2=1.95\n",
      "[DEBUG 2018-10-25 03:54:48,663 cleverhans]     Iteration 200 of 500: loss=3.28 l2=1.84\n",
      "[DEBUG 2018-10-25 03:54:50,306 cleverhans]     Iteration 250 of 500: loss=3.16 l2=1.74\n",
      "[DEBUG 2018-10-25 03:54:51,940 cleverhans]     Iteration 300 of 500: loss=3.02 l2=1.67\n",
      "[DEBUG 2018-10-25 03:54:53,554 cleverhans]     Iteration 350 of 500: loss=2.9 l2=1.63\n",
      "[DEBUG 2018-10-25 03:54:55,193 cleverhans]     Iteration 400 of 500: loss=2.77 l2=1.63\n",
      "[DEBUG 2018-10-25 03:54:56,789 cleverhans]     Iteration 450 of 500: loss=2.67 l2=1.64\n",
      "[DEBUG 2018-10-25 03:54:58,391 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 03:54:58,392 cleverhans]    Mean successful distortion: 1.431\n",
      "[DEBUG 2018-10-25 03:54:58,393 cleverhans]   Binary search step 2 of 10\n",
      "[DEBUG 2018-10-25 03:54:58,412 cleverhans]     Iteration 0 of 500: loss=10.8 l2=0\n",
      "[DEBUG 2018-10-25 03:55:00,095 cleverhans]     Iteration 50 of 500: loss=4.01 l2=2.33\n",
      "[DEBUG 2018-10-25 03:55:01,733 cleverhans]     Iteration 100 of 500: loss=3.73 l2=2.12\n",
      "[DEBUG 2018-10-25 03:55:03,411 cleverhans]     Iteration 150 of 500: loss=3.53 l2=2.09\n",
      "[DEBUG 2018-10-25 03:55:05,031 cleverhans]     Iteration 200 of 500: loss=3.41 l2=1.99\n",
      "[DEBUG 2018-10-25 03:55:06,655 cleverhans]     Iteration 250 of 500: loss=3.27 l2=1.92\n",
      "[DEBUG 2018-10-25 03:55:08,264 cleverhans]     Iteration 300 of 500: loss=3.1 l2=1.88\n",
      "[DEBUG 2018-10-25 03:55:09,876 cleverhans]     Iteration 350 of 500: loss=2.91 l2=1.87\n",
      "[DEBUG 2018-10-25 03:55:11,488 cleverhans]     Iteration 400 of 500: loss=2.73 l2=1.86\n",
      "[DEBUG 2018-10-25 03:55:13,095 cleverhans]     Iteration 450 of 500: loss=2.58 l2=1.84\n",
      "[DEBUG 2018-10-25 03:55:14,686 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 03:55:14,687 cleverhans]    Mean successful distortion: 1.416\n",
      "[DEBUG 2018-10-25 03:55:14,688 cleverhans]   Binary search step 3 of 10\n",
      "[DEBUG 2018-10-25 03:55:14,707 cleverhans]     Iteration 0 of 500: loss=7.93 l2=0\n",
      "[DEBUG 2018-10-25 03:55:16,450 cleverhans]     Iteration 50 of 500: loss=3.89 l2=2.17\n",
      "[DEBUG 2018-10-25 03:55:18,146 cleverhans]     Iteration 100 of 500: loss=3.74 l2=2.06\n",
      "[DEBUG 2018-10-25 03:55:19,840 cleverhans]     Iteration 150 of 500: loss=3.64 l2=2.05\n",
      "[DEBUG 2018-10-25 03:55:21,517 cleverhans]     Iteration 200 of 500: loss=3.52 l2=2.01\n",
      "[DEBUG 2018-10-25 03:55:23,181 cleverhans]     Iteration 250 of 500: loss=3.37 l2=1.92\n",
      "[DEBUG 2018-10-25 03:55:24,827 cleverhans]     Iteration 300 of 500: loss=3.2 l2=1.91\n",
      "[DEBUG 2018-10-25 03:55:26,472 cleverhans]     Iteration 350 of 500: loss=3.03 l2=1.91\n",
      "[DEBUG 2018-10-25 03:55:28,109 cleverhans]     Iteration 400 of 500: loss=2.85 l2=1.93\n",
      "[DEBUG 2018-10-25 03:55:29,748 cleverhans]     Iteration 450 of 500: loss=2.66 l2=1.96\n",
      "[DEBUG 2018-10-25 03:55:31,369 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 03:55:31,370 cleverhans]    Mean successful distortion: 1.409\n",
      "[DEBUG 2018-10-25 03:55:31,371 cleverhans]   Binary search step 4 of 10\n",
      "[DEBUG 2018-10-25 03:55:31,390 cleverhans]     Iteration 0 of 500: loss=6.49 l2=0\n",
      "[DEBUG 2018-10-25 03:55:33,157 cleverhans]     Iteration 50 of 500: loss=3.84 l2=1.98\n",
      "[DEBUG 2018-10-25 03:55:34,873 cleverhans]     Iteration 100 of 500: loss=3.75 l2=1.94\n",
      "[DEBUG 2018-10-25 03:55:36,584 cleverhans]     Iteration 150 of 500: loss=3.72 l2=1.93\n",
      "[DEBUG 2018-10-25 03:55:38,279 cleverhans]     Iteration 200 of 500: loss=3.64 l2=1.93\n",
      "[DEBUG 2018-10-25 03:55:39,954 cleverhans]     Iteration 250 of 500: loss=3.45 l2=1.91\n",
      "[DEBUG 2018-10-25 03:55:41,637 cleverhans]     Iteration 300 of 500: loss=3.26 l2=1.89\n",
      "[DEBUG 2018-10-25 03:55:43,316 cleverhans]     Iteration 350 of 500: loss=3.07 l2=1.92\n",
      "[DEBUG 2018-10-25 03:55:44,968 cleverhans]     Iteration 400 of 500: loss=2.87 l2=1.97\n",
      "[DEBUG 2018-10-25 03:55:46,612 cleverhans]     Iteration 450 of 500: loss=2.69 l2=2.02\n",
      "[DEBUG 2018-10-25 03:55:48,229 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 03:55:48,231 cleverhans]    Mean successful distortion: 1.404\n",
      "[DEBUG 2018-10-25 03:55:48,232 cleverhans]   Binary search step 5 of 10\n",
      "[DEBUG 2018-10-25 03:55:48,251 cleverhans]     Iteration 0 of 500: loss=5.82 l2=0\n",
      "[DEBUG 2018-10-25 03:55:50,043 cleverhans]     Iteration 50 of 500: loss=3.8 l2=1.77\n",
      "[DEBUG 2018-10-25 03:55:51,749 cleverhans]     Iteration 100 of 500: loss=3.74 l2=1.77\n",
      "[DEBUG 2018-10-25 03:55:53,473 cleverhans]     Iteration 150 of 500: loss=3.72 l2=1.77\n",
      "[DEBUG 2018-10-25 03:55:55,178 cleverhans]     Iteration 200 of 500: loss=3.68 l2=1.77\n",
      "[DEBUG 2018-10-25 03:55:56,888 cleverhans]     Iteration 250 of 500: loss=3.55 l2=1.78\n",
      "[DEBUG 2018-10-25 03:55:58,597 cleverhans]     Iteration 300 of 500: loss=3.37 l2=1.82\n",
      "[DEBUG 2018-10-25 03:56:00,285 cleverhans]     Iteration 350 of 500: loss=3.15 l2=1.89\n",
      "[DEBUG 2018-10-25 03:56:01,956 cleverhans]     Iteration 400 of 500: loss=2.93 l2=1.95\n",
      "[DEBUG 2018-10-25 03:56:03,620 cleverhans]     Iteration 450 of 500: loss=2.73 l2=2.02\n",
      "[DEBUG 2018-10-25 03:56:05,234 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 03:56:05,235 cleverhans]    Mean successful distortion: 1.4\n",
      "[DEBUG 2018-10-25 03:56:05,236 cleverhans]   Binary search step 6 of 10\n",
      "[DEBUG 2018-10-25 03:56:05,255 cleverhans]     Iteration 0 of 500: loss=5.53 l2=0\n",
      "[DEBUG 2018-10-25 03:56:07,000 cleverhans]     Iteration 50 of 500: loss=3.74 l2=1.66\n",
      "[DEBUG 2018-10-25 03:56:08,754 cleverhans]     Iteration 100 of 500: loss=3.69 l2=1.67\n",
      "[DEBUG 2018-10-25 03:56:10,512 cleverhans]     Iteration 150 of 500: loss=3.68 l2=1.67\n",
      "[DEBUG 2018-10-25 03:56:12,218 cleverhans]     Iteration 200 of 500: loss=3.65 l2=1.67\n",
      "[DEBUG 2018-10-25 03:56:13,935 cleverhans]     Iteration 250 of 500: loss=3.55 l2=1.69\n",
      "[DEBUG 2018-10-25 03:56:15,698 cleverhans]     Iteration 300 of 500: loss=3.39 l2=1.74\n",
      "[DEBUG 2018-10-25 03:56:17,406 cleverhans]     Iteration 350 of 500: loss=3.19 l2=1.83\n",
      "[DEBUG 2018-10-25 03:56:19,087 cleverhans]     Iteration 400 of 500: loss=2.98 l2=1.92\n",
      "[DEBUG 2018-10-25 03:56:20,803 cleverhans]     Iteration 450 of 500: loss=2.78 l2=2\n",
      "[DEBUG 2018-10-25 03:56:22,448 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 03:56:22,449 cleverhans]    Mean successful distortion: 1.399\n",
      "[DEBUG 2018-10-25 03:56:22,451 cleverhans]   Binary search step 7 of 10\n",
      "[DEBUG 2018-10-25 03:56:22,469 cleverhans]     Iteration 0 of 500: loss=5.44 l2=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DEBUG 2018-10-25 03:56:24,264 cleverhans]     Iteration 50 of 500: loss=3.73 l2=1.6\n",
      "[DEBUG 2018-10-25 03:56:25,996 cleverhans]     Iteration 100 of 500: loss=3.67 l2=1.61\n",
      "[DEBUG 2018-10-25 03:56:27,712 cleverhans]     Iteration 150 of 500: loss=3.66 l2=1.61\n",
      "[DEBUG 2018-10-25 03:56:29,442 cleverhans]     Iteration 200 of 500: loss=3.63 l2=1.62\n",
      "[DEBUG 2018-10-25 03:56:31,168 cleverhans]     Iteration 250 of 500: loss=3.54 l2=1.63\n",
      "[DEBUG 2018-10-25 03:56:32,943 cleverhans]     Iteration 300 of 500: loss=3.4 l2=1.69\n",
      "[DEBUG 2018-10-25 03:56:34,706 cleverhans]     Iteration 350 of 500: loss=3.21 l2=1.78\n",
      "[DEBUG 2018-10-25 03:56:36,417 cleverhans]     Iteration 400 of 500: loss=3 l2=1.88\n",
      "[DEBUG 2018-10-25 03:56:38,087 cleverhans]     Iteration 450 of 500: loss=2.79 l2=1.99\n",
      "[DEBUG 2018-10-25 03:56:39,755 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 03:56:39,756 cleverhans]    Mean successful distortion: 1.399\n",
      "[DEBUG 2018-10-25 03:56:39,758 cleverhans]   Binary search step 8 of 10\n",
      "[DEBUG 2018-10-25 03:56:39,778 cleverhans]     Iteration 0 of 500: loss=5.42 l2=0\n",
      "[DEBUG 2018-10-25 03:56:41,543 cleverhans]     Iteration 50 of 500: loss=3.73 l2=1.58\n",
      "[DEBUG 2018-10-25 03:56:43,324 cleverhans]     Iteration 100 of 500: loss=3.69 l2=1.59\n",
      "[DEBUG 2018-10-25 03:56:45,091 cleverhans]     Iteration 150 of 500: loss=3.67 l2=1.6\n",
      "[DEBUG 2018-10-25 03:56:46,801 cleverhans]     Iteration 200 of 500: loss=3.65 l2=1.6\n",
      "[DEBUG 2018-10-25 03:56:48,539 cleverhans]     Iteration 250 of 500: loss=3.56 l2=1.63\n",
      "[DEBUG 2018-10-25 03:56:50,320 cleverhans]     Iteration 300 of 500: loss=3.41 l2=1.68\n",
      "[DEBUG 2018-10-25 03:56:52,083 cleverhans]     Iteration 350 of 500: loss=3.22 l2=1.77\n",
      "[DEBUG 2018-10-25 03:56:53,799 cleverhans]     Iteration 400 of 500: loss=3.02 l2=1.89\n",
      "[DEBUG 2018-10-25 03:56:55,508 cleverhans]     Iteration 450 of 500: loss=2.81 l2=2.01\n",
      "[DEBUG 2018-10-25 03:56:57,166 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 03:56:57,167 cleverhans]    Mean successful distortion: 1.398\n",
      "[DEBUG 2018-10-25 03:56:57,168 cleverhans]   Binary search step 9 of 10\n",
      "[DEBUG 2018-10-25 03:56:57,187 cleverhans]     Iteration 0 of 500: loss=5.47 l2=0\n",
      "[DEBUG 2018-10-25 03:56:58,976 cleverhans]     Iteration 50 of 500: loss=3.72 l2=1.65\n",
      "[DEBUG 2018-10-25 03:57:00,738 cleverhans]     Iteration 100 of 500: loss=3.67 l2=1.68\n",
      "[DEBUG 2018-10-25 03:57:02,515 cleverhans]     Iteration 150 of 500: loss=3.65 l2=1.68\n",
      "[DEBUG 2018-10-25 03:57:04,234 cleverhans]     Iteration 200 of 500: loss=3.62 l2=1.69\n",
      "[DEBUG 2018-10-25 03:57:05,982 cleverhans]     Iteration 250 of 500: loss=3.53 l2=1.71\n",
      "[DEBUG 2018-10-25 03:57:07,711 cleverhans]     Iteration 300 of 500: loss=3.37 l2=1.77\n",
      "[DEBUG 2018-10-25 03:57:09,427 cleverhans]     Iteration 350 of 500: loss=3.17 l2=1.86\n",
      "[DEBUG 2018-10-25 03:57:11,143 cleverhans]     Iteration 400 of 500: loss=2.95 l2=1.98\n",
      "[DEBUG 2018-10-25 03:57:12,823 cleverhans]     Iteration 450 of 500: loss=2.72 l2=2.12\n",
      "[DEBUG 2018-10-25 03:57:14,444 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 03:57:14,445 cleverhans]    Mean successful distortion: 1.398\n"
     ]
    }
   ],
   "source": [
    "keras.backend.set_learning_phase(0)\n",
    "set_log_level(logging.DEBUG)\n",
    "\n",
    "# CarliniWagner attack\n",
    "from lib.my_cw import CarliniWagnerL2\n",
    "\n",
    "attack_iterations = 500\n",
    "cw_params = {'binary_search_steps': 10,\n",
    "             'max_iterations': attack_iterations,\n",
    "             'learning_rate': 0.1,\n",
    "             'batch_size': n_attack,\n",
    "             'initial_const': 1}\n",
    "cw = CarliniWagnerL2(hingenet, sess=sess)\n",
    "adv = cw.generate_np(X_atk, **cw_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = np.sqrt(np.sum((X_atk - adv)**2, (1, 2, 3)))\n",
    "plt.hist(dist, bins=10, range=(1, 5))\n",
    "print(np.min(dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = hingenet.predict_model(sess, adv)\n",
    "\n",
    "for x, y in zip(adv[:10], y_pred[:10]):\n",
    "    print(np.argmax(y))\n",
    "    print(y)\n",
    "    plt.imshow(x[:, :, 0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from hinge_net import HingeNet\n",
    "\n",
    "# v2: margin = 1e2\n",
    "hingenet = HingeNet(\"hingenet_v2\", [28, 28, 1], [10], learning_rate=1e-3, \n",
    "                    loss=\"hinge\", margin=1e2, load_model=True, \n",
    "                    save_path=\"model/hingenet_v2.h5\")\n",
    "# hingenet.train_model(sess, data, n_epoch=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9884, 2.990084765625)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hingenet.eval_model(sess, (X_test[:, :, :, np.newaxis], np.argmax(y_test, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Least likeley class\n",
    "n_attack = 1000\n",
    "X_atk = X_test[:, :, :, np.newaxis][:n_attack]\n",
    "y_atk = np.argmax(y_test[:n_attack], axis=1)\n",
    "\n",
    "y_pred = hingenet.predict_model(sess, X_atk)\n",
    "y_target = to_categorical(np.argmin(y_pred, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.984, 2.9711747179031374)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hingenet.eval_model(sess, (X_atk, y_atk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# hinge\n",
    "\n",
    "keras.backend.set_learning_phase(0)\n",
    "set_log_level(logging.DEBUG)\n",
    "\n",
    "from lib.my_pgd import ProjectedGradientDescent\n",
    "\n",
    "pgd_params = {'eps': 0.3,\n",
    "              'eps_iter': 0.05,\n",
    "              'clip_min': 0.,\n",
    "              'clip_max': 1.,\n",
    "              'ord': np.inf, \n",
    "              'nb_iter': 10,\n",
    "              'rand_init': True,\n",
    "              'batch_size': 100,\n",
    "              'y_target': y_target}\n",
    "pgd = ProjectedGradientDescent(hingenet, sess=sess)\n",
    "\n",
    "y_tar = np.argmax(y_target, axis=1)\n",
    "best_adv = np.zeros_like(X_atk)\n",
    "best_dist = np.zeros([n_attack]) + 1e5\n",
    "for i in range(10):\n",
    "    adv = pgd.generate_np(X_atk, **pgd_params)\n",
    "    print(hingenet.eval_model(sess, (adv, y_tar)))\n",
    "    dist = np.sqrt(np.sum((adv - X_atk)**2, (1, 2, 3)))\n",
    "    print(np.mean(dist))\n",
    "    pred = hingenet.predict_model(sess, adv)\n",
    "    y_pred = np.argmax(pred, axis=1)\n",
    "    for j in range(n_attack):\n",
    "        if y_pred[j] == y_tar[j] and dist[j] < best_dist[j]:\n",
    "            best_adv[j] = adv[j]\n",
    "            best_dist[j] = dist[j]\n",
    "print(np.mean(best_dist < 1e5))\n",
    "print(np.mean(best_dist[best_dist < 1e5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/research/nn_proof/lib/my_pgd.py:698: UserWarning: Supplied extra keyword arguments that are not used in the graph computation. They have been ignored.\n",
      "  warnings.warn(\"Supplied extra keyword arguments that are not \"\n",
      "[INFO 2018-10-25 04:22:05,456 cleverhans] Constructing new graph for attack ProjectedGradientDescent\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.554, 183.33179663085937)\n",
      "2.9768095\n",
      "(0.554, 183.37975463867187)\n",
      "2.9768062\n",
      "(0.548, 183.37214916992187)\n",
      "2.9768112\n",
      "(0.56, 183.84378784179688)\n",
      "2.9762034\n",
      "(0.564, 182.48850793457032)\n",
      "2.975016\n",
      "(0.554, 183.09268420410157)\n",
      "2.9752016\n",
      "(0.563, 182.54222802734375)\n",
      "2.975842\n",
      "(0.562, 183.00726904296874)\n",
      "2.9749937\n",
      "(0.556, 182.86801904296874)\n",
      "2.9760473\n",
      "(0.558, 182.0998671875)\n",
      "2.9771123\n",
      "0.63\n",
      "2.9424975815273466\n"
     ]
    }
   ],
   "source": [
    "# hinge (L2)\n",
    "\n",
    "keras.backend.set_learning_phase(0)\n",
    "set_log_level(logging.DEBUG)\n",
    "\n",
    "from lib.my_pgd import ProjectedGradientDescent\n",
    "\n",
    "pgd_params = {'eps': 3,\n",
    "              'eps_iter': 0.1,\n",
    "              'clip_min': 0.,\n",
    "              'clip_max': 1.,\n",
    "              'ord': 2, \n",
    "              'nb_iter': 50,\n",
    "              'rand_init': True,\n",
    "              'batch_size': 100,\n",
    "              'y_target': y_target}\n",
    "pgd = ProjectedGradientDescent(hingenet, sess=sess)\n",
    "\n",
    "y_tar = np.argmax(y_target, axis=1)\n",
    "best_adv = np.zeros_like(X_atk)\n",
    "best_dist = np.zeros([n_attack]) + 1e5\n",
    "for i in range(10):\n",
    "    adv = pgd.generate_np(X_atk, **pgd_params)\n",
    "    print(hingenet.eval_model(sess, (adv, y_tar)))\n",
    "    dist = np.sqrt(np.sum((adv - X_atk)**2, (1, 2, 3)))\n",
    "    print(np.mean(dist))\n",
    "    pred = hingenet.predict_model(sess, adv)\n",
    "    y_pred = np.argmax(pred, axis=1)\n",
    "    for j in range(n_attack):\n",
    "        if y_pred[j] == y_tar[j] and dist[j] < best_dist[j]:\n",
    "            best_adv[j] = adv[j]\n",
    "            best_dist[j] = dist[j]\n",
    "print(np.mean(best_dist < 1e5))\n",
    "print(np.mean(best_dist[best_dist < 1e5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# hinge (untargeted)\n",
    "\n",
    "keras.backend.set_learning_phase(0)\n",
    "set_log_level(logging.DEBUG)\n",
    "\n",
    "from lib.my_pgd import ProjectedGradientDescent\n",
    "\n",
    "pgd_params = {'eps': 0.3,\n",
    "              'eps_iter': 0.05,\n",
    "              'clip_min': 0.,\n",
    "              'clip_max': 1.,\n",
    "              'ord': np.inf, \n",
    "              'nb_iter': 10,\n",
    "              'rand_init': True,\n",
    "              'batch_size': 100}\n",
    "pgd = ProjectedGradientDescent(hingenet, sess=sess)\n",
    "\n",
    "y_tar = np.argmax(y_target, axis=1)\n",
    "best_adv = np.zeros_like(X_atk)\n",
    "best_dist = np.zeros([n_attack]) + 1e5\n",
    "for i in range(10):\n",
    "    adv = pgd.generate_np(X_atk, **pgd_params)\n",
    "    print(hingenet.eval_model(sess, (adv, y_tar)))\n",
    "    dist = np.sqrt(np.sum((adv - X_atk)**2, (1, 2, 3)))\n",
    "    print(np.mean(dist))\n",
    "    pred = hingenet.predict_model(sess, adv)\n",
    "    y_pred = np.argmax(pred, axis=1)\n",
    "    for j in range(n_attack):\n",
    "        if y_pred[j] == y_tar[j] and dist[j] < best_dist[j]:\n",
    "            best_adv[j] = adv[j]\n",
    "            best_dist[j] = dist[j]\n",
    "print(np.mean(best_dist < 1e5))\n",
    "print(np.mean(best_dist[best_dist < 1e5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2018-10-25 00:46:47,241 cleverhans] Constructing new graph for attack CarliniWagnerL2\n",
      "[DEBUG 2018-10-25 00:46:47,648 cleverhans] Running CWL2 attack on instance 0 of 1000\n",
      "[DEBUG 2018-10-25 00:46:47,759 cleverhans]   Binary search step 0 of 10\n",
      "[DEBUG 2018-10-25 00:46:47,946 cleverhans]     Iteration 0 of 500: loss=1.33e+03 l2=0\n",
      "[DEBUG 2018-10-25 00:46:49,447 cleverhans]     Iteration 50 of 500: loss=86.8 l2=41.6\n",
      "[DEBUG 2018-10-25 00:46:50,574 cleverhans]     Iteration 100 of 500: loss=35.7 l2=35.7\n",
      "[DEBUG 2018-10-25 00:46:52,084 cleverhans]     Iteration 150 of 500: loss=29.9 l2=29.8\n",
      "[DEBUG 2018-10-25 00:46:53,585 cleverhans]     Iteration 200 of 500: loss=26.7 l2=26.7\n",
      "[DEBUG 2018-10-25 00:46:54,958 cleverhans]     Iteration 250 of 500: loss=24.6 l2=24.6\n",
      "[DEBUG 2018-10-25 00:46:56,213 cleverhans]     Iteration 300 of 500: loss=23.1 l2=23.1\n",
      "[DEBUG 2018-10-25 00:46:57,415 cleverhans]     Iteration 350 of 500: loss=21.8 l2=21.7\n",
      "[DEBUG 2018-10-25 00:46:58,605 cleverhans]     Iteration 400 of 500: loss=20.8 l2=20.7\n",
      "[DEBUG 2018-10-25 00:46:59,730 cleverhans]     Iteration 450 of 500: loss=19.9 l2=19.8\n",
      "[DEBUG 2018-10-25 00:47:00,817 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 00:47:00,818 cleverhans]    Mean successful distortion: 4.02\n",
      "[DEBUG 2018-10-25 00:47:00,820 cleverhans]   Binary search step 1 of 10\n",
      "[DEBUG 2018-10-25 00:47:00,840 cleverhans]     Iteration 0 of 500: loss=663 l2=0\n",
      "[DEBUG 2018-10-25 00:47:02,188 cleverhans]     Iteration 50 of 500: loss=60.4 l2=37.6\n",
      "[DEBUG 2018-10-25 00:47:03,383 cleverhans]     Iteration 100 of 500: loss=28.9 l2=28.8\n",
      "[DEBUG 2018-10-25 00:47:04,650 cleverhans]     Iteration 150 of 500: loss=24.3 l2=24.2\n",
      "[DEBUG 2018-10-25 00:47:05,814 cleverhans]     Iteration 200 of 500: loss=21.7 l2=21.6\n",
      "[DEBUG 2018-10-25 00:47:06,919 cleverhans]     Iteration 250 of 500: loss=19.7 l2=19.6\n",
      "[DEBUG 2018-10-25 00:47:07,992 cleverhans]     Iteration 300 of 500: loss=18.1 l2=18\n",
      "[DEBUG 2018-10-25 00:47:09,143 cleverhans]     Iteration 350 of 500: loss=17 l2=16.9\n",
      "[DEBUG 2018-10-25 00:47:10,240 cleverhans]     Iteration 400 of 500: loss=16 l2=15.9\n",
      "[DEBUG 2018-10-25 00:47:11,320 cleverhans]     Iteration 450 of 500: loss=15.4 l2=15.2\n",
      "[DEBUG 2018-10-25 00:47:12,381 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 00:47:12,382 cleverhans]    Mean successful distortion: 3.503\n",
      "[DEBUG 2018-10-25 00:47:12,384 cleverhans]   Binary search step 2 of 10\n",
      "[DEBUG 2018-10-25 00:47:12,404 cleverhans]     Iteration 0 of 500: loss=332 l2=0\n",
      "[DEBUG 2018-10-25 00:47:13,743 cleverhans]     Iteration 50 of 500: loss=42.5 l2=31.1\n",
      "[DEBUG 2018-10-25 00:47:15,050 cleverhans]     Iteration 100 of 500: loss=23.6 l2=23.1\n",
      "[DEBUG 2018-10-25 00:47:16,209 cleverhans]     Iteration 150 of 500: loss=20 l2=19.9\n",
      "[DEBUG 2018-10-25 00:47:17,325 cleverhans]     Iteration 200 of 500: loss=17.5 l2=17.4\n",
      "[DEBUG 2018-10-25 00:47:18,429 cleverhans]     Iteration 250 of 500: loss=15.7 l2=15.5\n",
      "[DEBUG 2018-10-25 00:47:19,495 cleverhans]     Iteration 300 of 500: loss=14.3 l2=14.2\n",
      "[DEBUG 2018-10-25 00:47:20,566 cleverhans]     Iteration 350 of 500: loss=13.4 l2=13.2\n",
      "[DEBUG 2018-10-25 00:47:21,641 cleverhans]     Iteration 400 of 500: loss=12.7 l2=12.6\n",
      "[DEBUG 2018-10-25 00:47:22,706 cleverhans]     Iteration 450 of 500: loss=12.3 l2=12.1\n",
      "[DEBUG 2018-10-25 00:47:23,748 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 00:47:23,750 cleverhans]    Mean successful distortion: 3.178\n",
      "[DEBUG 2018-10-25 00:47:23,751 cleverhans]   Binary search step 3 of 10\n",
      "[DEBUG 2018-10-25 00:47:23,770 cleverhans]     Iteration 0 of 500: loss=166 l2=0\n",
      "[DEBUG 2018-10-25 00:47:25,168 cleverhans]     Iteration 50 of 500: loss=29.3 l2=23.2\n",
      "[DEBUG 2018-10-25 00:47:26,462 cleverhans]     Iteration 100 of 500: loss=21.4 l2=18.9\n",
      "[DEBUG 2018-10-25 00:47:27,637 cleverhans]     Iteration 150 of 500: loss=17.4 l2=17.2\n",
      "[DEBUG 2018-10-25 00:47:28,801 cleverhans]     Iteration 200 of 500: loss=15.2 l2=15\n",
      "[DEBUG 2018-10-25 00:47:29,908 cleverhans]     Iteration 250 of 500: loss=13.5 l2=13.4\n",
      "[DEBUG 2018-10-25 00:47:30,989 cleverhans]     Iteration 300 of 500: loss=12.3 l2=12.2\n",
      "[DEBUG 2018-10-25 00:47:32,039 cleverhans]     Iteration 350 of 500: loss=11.6 l2=11.4\n",
      "[DEBUG 2018-10-25 00:47:33,105 cleverhans]     Iteration 400 of 500: loss=11 l2=10.9\n",
      "[DEBUG 2018-10-25 00:47:34,188 cleverhans]     Iteration 450 of 500: loss=10.7 l2=10.5\n",
      "[DEBUG 2018-10-25 00:47:35,253 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 00:47:35,255 cleverhans]    Mean successful distortion: 3.025\n",
      "[DEBUG 2018-10-25 00:47:35,256 cleverhans]   Binary search step 4 of 10\n",
      "[DEBUG 2018-10-25 00:47:35,276 cleverhans]     Iteration 0 of 500: loss=82.9 l2=0\n",
      "[DEBUG 2018-10-25 00:47:36,755 cleverhans]     Iteration 50 of 500: loss=21.9 l2=18.2\n",
      "[DEBUG 2018-10-25 00:47:38,034 cleverhans]     Iteration 100 of 500: loss=19.5 l2=16.4\n",
      "[DEBUG 2018-10-25 00:47:39,252 cleverhans]     Iteration 150 of 500: loss=16.4 l2=15.8\n",
      "[DEBUG 2018-10-25 00:47:40,453 cleverhans]     Iteration 200 of 500: loss=14.1 l2=13.9\n",
      "[DEBUG 2018-10-25 00:47:41,664 cleverhans]     Iteration 250 of 500: loss=12.5 l2=12.3\n",
      "[DEBUG 2018-10-25 00:47:42,811 cleverhans]     Iteration 300 of 500: loss=11.5 l2=11.3\n",
      "[DEBUG 2018-10-25 00:47:43,927 cleverhans]     Iteration 350 of 500: loss=10.8 l2=10.6\n",
      "[DEBUG 2018-10-25 00:47:45,050 cleverhans]     Iteration 400 of 500: loss=10.3 l2=10.1\n",
      "[DEBUG 2018-10-25 00:47:46,211 cleverhans]     Iteration 450 of 500: loss=9.92 l2=9.73\n",
      "[DEBUG 2018-10-25 00:47:47,379 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 00:47:47,380 cleverhans]    Mean successful distortion: 2.96\n",
      "[DEBUG 2018-10-25 00:47:47,382 cleverhans]   Binary search step 5 of 10\n",
      "[DEBUG 2018-10-25 00:47:47,400 cleverhans]     Iteration 0 of 500: loss=41.4 l2=0\n",
      "[DEBUG 2018-10-25 00:47:48,932 cleverhans]     Iteration 50 of 500: loss=17.8 l2=14\n",
      "[DEBUG 2018-10-25 00:47:50,293 cleverhans]     Iteration 100 of 500: loss=17.1 l2=13.6\n",
      "[DEBUG 2018-10-25 00:47:51,637 cleverhans]     Iteration 150 of 500: loss=16.1 l2=13.4\n",
      "[DEBUG 2018-10-25 00:47:52,950 cleverhans]     Iteration 200 of 500: loss=13.9 l2=12.6\n",
      "[DEBUG 2018-10-25 00:47:54,260 cleverhans]     Iteration 250 of 500: loss=12.2 l2=11.4\n",
      "[DEBUG 2018-10-25 00:47:55,519 cleverhans]     Iteration 300 of 500: loss=11.1 l2=10.6\n",
      "[DEBUG 2018-10-25 00:47:56,732 cleverhans]     Iteration 350 of 500: loss=10.4 l2=9.96\n",
      "[DEBUG 2018-10-25 00:47:57,949 cleverhans]     Iteration 400 of 500: loss=9.84 l2=9.52\n",
      "[DEBUG 2018-10-25 00:47:59,219 cleverhans]     Iteration 450 of 500: loss=9.48 l2=9.18\n",
      "[DEBUG 2018-10-25 00:48:00,485 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 00:48:00,486 cleverhans]    Mean successful distortion: 2.925\n",
      "[DEBUG 2018-10-25 00:48:00,488 cleverhans]   Binary search step 6 of 10\n",
      "[DEBUG 2018-10-25 00:48:00,508 cleverhans]     Iteration 0 of 500: loss=21.1 l2=0\n",
      "[DEBUG 2018-10-25 00:48:02,192 cleverhans]     Iteration 50 of 500: loss=14 l2=7.23\n",
      "[DEBUG 2018-10-25 00:48:03,816 cleverhans]     Iteration 100 of 500: loss=13.9 l2=7.24\n",
      "[DEBUG 2018-10-25 00:48:05,402 cleverhans]     Iteration 150 of 500: loss=13.8 l2=7.25\n",
      "[DEBUG 2018-10-25 00:48:06,992 cleverhans]     Iteration 200 of 500: loss=13.2 l2=7.42\n",
      "[DEBUG 2018-10-25 00:48:08,588 cleverhans]     Iteration 250 of 500: loss=12.1 l2=7.66\n",
      "[DEBUG 2018-10-25 00:48:10,156 cleverhans]     Iteration 300 of 500: loss=11.1 l2=7.71\n",
      "[DEBUG 2018-10-25 00:48:11,729 cleverhans]     Iteration 350 of 500: loss=10.4 l2=7.7\n",
      "[DEBUG 2018-10-25 00:48:13,289 cleverhans]     Iteration 400 of 500: loss=9.82 l2=7.6\n",
      "[DEBUG 2018-10-25 00:48:14,877 cleverhans]     Iteration 450 of 500: loss=9.4 l2=7.56\n",
      "[DEBUG 2018-10-25 00:48:16,489 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 00:48:16,490 cleverhans]    Mean successful distortion: 2.918\n",
      "[DEBUG 2018-10-25 00:48:16,492 cleverhans]   Binary search step 7 of 10\n",
      "[DEBUG 2018-10-25 00:48:16,511 cleverhans]     Iteration 0 of 500: loss=19.6 l2=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DEBUG 2018-10-25 00:48:18,194 cleverhans]     Iteration 50 of 500: loss=13.1 l2=5.94\n",
      "[DEBUG 2018-10-25 00:48:19,832 cleverhans]     Iteration 100 of 500: loss=13 l2=5.92\n",
      "[DEBUG 2018-10-25 00:48:21,478 cleverhans]     Iteration 150 of 500: loss=12.8 l2=5.96\n",
      "[DEBUG 2018-10-25 00:48:23,128 cleverhans]     Iteration 200 of 500: loss=12.1 l2=6.08\n",
      "[DEBUG 2018-10-25 00:48:24,774 cleverhans]     Iteration 250 of 500: loss=11.2 l2=6.09\n",
      "[DEBUG 2018-10-25 00:48:26,417 cleverhans]     Iteration 300 of 500: loss=10.5 l2=6.04\n",
      "[DEBUG 2018-10-25 00:48:28,020 cleverhans]     Iteration 350 of 500: loss=9.88 l2=6.04\n",
      "[DEBUG 2018-10-25 00:48:29,608 cleverhans]     Iteration 400 of 500: loss=9.42 l2=6.04\n",
      "[DEBUG 2018-10-25 00:48:31,218 cleverhans]     Iteration 450 of 500: loss=9.05 l2=6.04\n",
      "[DEBUG 2018-10-25 00:48:32,865 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 00:48:32,866 cleverhans]    Mean successful distortion: 2.914\n",
      "[DEBUG 2018-10-25 00:48:32,868 cleverhans]   Binary search step 8 of 10\n",
      "[DEBUG 2018-10-25 00:48:32,886 cleverhans]     Iteration 0 of 500: loss=20.8 l2=0\n",
      "[DEBUG 2018-10-25 00:48:34,566 cleverhans]     Iteration 50 of 500: loss=14.2 l2=6.73\n",
      "[DEBUG 2018-10-25 00:48:36,249 cleverhans]     Iteration 100 of 500: loss=14.1 l2=6.73\n",
      "[DEBUG 2018-10-25 00:48:37,890 cleverhans]     Iteration 150 of 500: loss=14 l2=6.75\n",
      "[DEBUG 2018-10-25 00:48:39,536 cleverhans]     Iteration 200 of 500: loss=13.3 l2=6.95\n",
      "[DEBUG 2018-10-25 00:48:41,167 cleverhans]     Iteration 250 of 500: loss=12.3 l2=7.25\n",
      "[DEBUG 2018-10-25 00:48:42,784 cleverhans]     Iteration 300 of 500: loss=11.3 l2=7.47\n",
      "[DEBUG 2018-10-25 00:48:44,386 cleverhans]     Iteration 350 of 500: loss=10.6 l2=7.64\n",
      "[DEBUG 2018-10-25 00:48:46,004 cleverhans]     Iteration 400 of 500: loss=9.97 l2=7.71\n",
      "[DEBUG 2018-10-25 00:48:47,614 cleverhans]     Iteration 450 of 500: loss=9.52 l2=7.73\n",
      "[DEBUG 2018-10-25 00:48:49,252 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 00:48:49,253 cleverhans]    Mean successful distortion: 2.912\n",
      "[DEBUG 2018-10-25 00:48:49,255 cleverhans]   Binary search step 9 of 10\n",
      "[DEBUG 2018-10-25 00:48:49,273 cleverhans]     Iteration 0 of 500: loss=23.6 l2=0\n",
      "[DEBUG 2018-10-25 00:48:50,933 cleverhans]     Iteration 50 of 500: loss=15.2 l2=8.41\n",
      "[DEBUG 2018-10-25 00:48:52,520 cleverhans]     Iteration 100 of 500: loss=15 l2=8.44\n",
      "[DEBUG 2018-10-25 00:48:54,117 cleverhans]     Iteration 150 of 500: loss=14.9 l2=8.48\n",
      "[DEBUG 2018-10-25 00:48:55,675 cleverhans]     Iteration 200 of 500: loss=13.9 l2=8.73\n",
      "[DEBUG 2018-10-25 00:48:57,234 cleverhans]     Iteration 250 of 500: loss=12.6 l2=9.03\n",
      "[DEBUG 2018-10-25 00:48:58,751 cleverhans]     Iteration 300 of 500: loss=11.4 l2=9.17\n",
      "[DEBUG 2018-10-25 00:49:00,252 cleverhans]     Iteration 350 of 500: loss=10.6 l2=9.17\n",
      "[DEBUG 2018-10-25 00:49:01,718 cleverhans]     Iteration 400 of 500: loss=9.9 l2=9.02\n",
      "[DEBUG 2018-10-25 00:49:03,206 cleverhans]     Iteration 450 of 500: loss=9.42 l2=8.8\n",
      "[DEBUG 2018-10-25 00:49:04,687 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 00:49:04,689 cleverhans]    Mean successful distortion: 2.912\n"
     ]
    }
   ],
   "source": [
    "keras.backend.set_learning_phase(0)\n",
    "set_log_level(logging.DEBUG)\n",
    "\n",
    "# CarliniWagner attack\n",
    "from lib.my_cw import CarliniWagnerL2\n",
    "\n",
    "attack_iterations = 500\n",
    "cw_params = {'binary_search_steps': 10,\n",
    "             'max_iterations': attack_iterations,\n",
    "             'learning_rate': 0.1,\n",
    "             'batch_size': n_attack,\n",
    "             'initial_const': 1,\n",
    "             'y_target': y_target}\n",
    "cw = CarliniWagnerL2(hingenet, sess=sess)\n",
    "adv = cw.generate_np(X_atk, **cw_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2748419\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dist = np.sqrt(np.sum((X_atk - adv)**2, (1, 2, 3)))\n",
    "plt.hist(dist, bins=10, range=(1, 5))\n",
    "print(np.min(dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2018-10-25 00:51:07,269 cleverhans] Constructing new graph for attack CarliniWagnerL2\n",
      "[DEBUG 2018-10-25 00:51:07,626 cleverhans] Running CWL2 attack on instance 0 of 1000\n",
      "[DEBUG 2018-10-25 00:51:07,742 cleverhans]   Binary search step 0 of 10\n",
      "[DEBUG 2018-10-25 00:51:07,934 cleverhans]     Iteration 0 of 500: loss=503 l2=0\n",
      "[DEBUG 2018-10-25 00:51:09,129 cleverhans]     Iteration 50 of 500: loss=24.8 l2=17.9\n",
      "[DEBUG 2018-10-25 00:51:10,143 cleverhans]     Iteration 100 of 500: loss=12.1 l2=12\n",
      "[DEBUG 2018-10-25 00:51:11,574 cleverhans]     Iteration 150 of 500: loss=9.66 l2=9.62\n",
      "[DEBUG 2018-10-25 00:51:12,890 cleverhans]     Iteration 200 of 500: loss=8.79 l2=8.76\n",
      "[DEBUG 2018-10-25 00:51:14,079 cleverhans]     Iteration 250 of 500: loss=8.19 l2=8.15\n",
      "[DEBUG 2018-10-25 00:51:15,210 cleverhans]     Iteration 300 of 500: loss=7.76 l2=7.73\n",
      "[DEBUG 2018-10-25 00:51:16,280 cleverhans]     Iteration 350 of 500: loss=7.41 l2=7.35\n",
      "[DEBUG 2018-10-25 00:51:17,349 cleverhans]     Iteration 400 of 500: loss=7.01 l2=6.95\n",
      "[DEBUG 2018-10-25 00:51:18,407 cleverhans]     Iteration 450 of 500: loss=6.89 l2=6.84\n",
      "[DEBUG 2018-10-25 00:51:19,396 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 00:51:19,397 cleverhans]    Mean successful distortion: 2.083\n",
      "[DEBUG 2018-10-25 00:51:19,398 cleverhans]   Binary search step 1 of 10\n",
      "[DEBUG 2018-10-25 00:51:19,416 cleverhans]     Iteration 0 of 500: loss=252 l2=0\n",
      "[DEBUG 2018-10-25 00:51:20,531 cleverhans]     Iteration 50 of 500: loss=17.4 l2=13.9\n",
      "[DEBUG 2018-10-25 00:51:21,714 cleverhans]     Iteration 100 of 500: loss=9.04 l2=8.99\n",
      "[DEBUG 2018-10-25 00:51:22,876 cleverhans]     Iteration 150 of 500: loss=7.63 l2=7.58\n",
      "[DEBUG 2018-10-25 00:51:23,951 cleverhans]     Iteration 200 of 500: loss=6.91 l2=6.85\n",
      "[DEBUG 2018-10-25 00:51:24,990 cleverhans]     Iteration 250 of 500: loss=6.35 l2=6.29\n",
      "[DEBUG 2018-10-25 00:51:26,013 cleverhans]     Iteration 300 of 500: loss=5.94 l2=5.89\n",
      "[DEBUG 2018-10-25 00:51:27,035 cleverhans]     Iteration 350 of 500: loss=5.61 l2=5.54\n",
      "[DEBUG 2018-10-25 00:51:28,035 cleverhans]     Iteration 400 of 500: loss=5.41 l2=5.32\n",
      "[DEBUG 2018-10-25 00:51:29,019 cleverhans]     Iteration 450 of 500: loss=5.19 l2=5.13\n",
      "[DEBUG 2018-10-25 00:51:30,023 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 00:51:30,024 cleverhans]    Mean successful distortion: 1.809\n",
      "[DEBUG 2018-10-25 00:51:30,025 cleverhans]   Binary search step 2 of 10\n",
      "[DEBUG 2018-10-25 00:51:30,044 cleverhans]     Iteration 0 of 500: loss=126 l2=0\n",
      "[DEBUG 2018-10-25 00:51:31,201 cleverhans]     Iteration 50 of 500: loss=11.5 l2=9.69\n",
      "[DEBUG 2018-10-25 00:51:32,422 cleverhans]     Iteration 100 of 500: loss=7.06 l2=6.92\n",
      "[DEBUG 2018-10-25 00:51:33,503 cleverhans]     Iteration 150 of 500: loss=6.08 l2=6\n",
      "[DEBUG 2018-10-25 00:51:34,539 cleverhans]     Iteration 200 of 500: loss=5.48 l2=5.42\n",
      "[DEBUG 2018-10-25 00:51:35,567 cleverhans]     Iteration 250 of 500: loss=4.97 l2=4.89\n",
      "[DEBUG 2018-10-25 00:51:36,579 cleverhans]     Iteration 300 of 500: loss=4.59 l2=4.5\n",
      "[DEBUG 2018-10-25 00:51:37,598 cleverhans]     Iteration 350 of 500: loss=4.28 l2=4.2\n",
      "[DEBUG 2018-10-25 00:51:38,628 cleverhans]     Iteration 400 of 500: loss=4.06 l2=3.99\n",
      "[DEBUG 2018-10-25 00:51:39,622 cleverhans]     Iteration 450 of 500: loss=3.9 l2=3.81\n",
      "[DEBUG 2018-10-25 00:51:40,632 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 00:51:40,633 cleverhans]    Mean successful distortion: 1.628\n",
      "[DEBUG 2018-10-25 00:51:40,635 cleverhans]   Binary search step 3 of 10\n",
      "[DEBUG 2018-10-25 00:51:40,653 cleverhans]     Iteration 0 of 500: loss=62.9 l2=0\n",
      "[DEBUG 2018-10-25 00:51:41,925 cleverhans]     Iteration 50 of 500: loss=8.1 l2=7.12\n",
      "[DEBUG 2018-10-25 00:51:43,082 cleverhans]     Iteration 100 of 500: loss=6.05 l2=5.6\n",
      "[DEBUG 2018-10-25 00:51:44,154 cleverhans]     Iteration 150 of 500: loss=5.3 l2=5.23\n",
      "[DEBUG 2018-10-25 00:51:45,162 cleverhans]     Iteration 200 of 500: loss=4.77 l2=4.68\n",
      "[DEBUG 2018-10-25 00:51:46,208 cleverhans]     Iteration 250 of 500: loss=4.25 l2=4.18\n",
      "[DEBUG 2018-10-25 00:51:47,231 cleverhans]     Iteration 300 of 500: loss=3.84 l2=3.76\n",
      "[DEBUG 2018-10-25 00:51:48,246 cleverhans]     Iteration 350 of 500: loss=3.56 l2=3.46\n",
      "[DEBUG 2018-10-25 00:51:49,270 cleverhans]     Iteration 400 of 500: loss=3.35 l2=3.25\n",
      "[DEBUG 2018-10-25 00:51:50,319 cleverhans]     Iteration 450 of 500: loss=3.2 l2=3.11\n",
      "[DEBUG 2018-10-25 00:51:51,345 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 00:51:51,347 cleverhans]    Mean successful distortion: 1.539\n",
      "[DEBUG 2018-10-25 00:51:51,348 cleverhans]   Binary search step 4 of 10\n",
      "[DEBUG 2018-10-25 00:51:51,367 cleverhans]     Iteration 0 of 500: loss=31.5 l2=0\n",
      "[DEBUG 2018-10-25 00:51:52,664 cleverhans]     Iteration 50 of 500: loss=6.16 l2=5.55\n",
      "[DEBUG 2018-10-25 00:51:53,818 cleverhans]     Iteration 100 of 500: loss=5.58 l2=5\n",
      "[DEBUG 2018-10-25 00:51:54,901 cleverhans]     Iteration 150 of 500: loss=5 l2=4.83\n",
      "[DEBUG 2018-10-25 00:51:56,000 cleverhans]     Iteration 200 of 500: loss=4.4 l2=4.32\n",
      "[DEBUG 2018-10-25 00:51:57,042 cleverhans]     Iteration 250 of 500: loss=3.93 l2=3.86\n",
      "[DEBUG 2018-10-25 00:51:58,111 cleverhans]     Iteration 300 of 500: loss=3.56 l2=3.47\n",
      "[DEBUG 2018-10-25 00:51:59,183 cleverhans]     Iteration 350 of 500: loss=3.31 l2=3.23\n",
      "[DEBUG 2018-10-25 00:52:00,244 cleverhans]     Iteration 400 of 500: loss=3.11 l2=3.02\n",
      "[DEBUG 2018-10-25 00:52:01,306 cleverhans]     Iteration 450 of 500: loss=2.95 l2=2.87\n",
      "[DEBUG 2018-10-25 00:52:02,406 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 00:52:02,407 cleverhans]    Mean successful distortion: 1.504\n",
      "[DEBUG 2018-10-25 00:52:02,408 cleverhans]   Binary search step 5 of 10\n",
      "[DEBUG 2018-10-25 00:52:02,427 cleverhans]     Iteration 0 of 500: loss=15.7 l2=0\n",
      "[DEBUG 2018-10-25 00:52:03,774 cleverhans]     Iteration 50 of 500: loss=5.27 l2=4.54\n",
      "[DEBUG 2018-10-25 00:52:04,983 cleverhans]     Iteration 100 of 500: loss=5.1 l2=4.4\n",
      "[DEBUG 2018-10-25 00:52:06,127 cleverhans]     Iteration 150 of 500: loss=4.86 l2=4.32\n",
      "[DEBUG 2018-10-25 00:52:07,306 cleverhans]     Iteration 200 of 500: loss=4.29 l2=4\n",
      "[DEBUG 2018-10-25 00:52:08,456 cleverhans]     Iteration 250 of 500: loss=3.79 l2=3.62\n",
      "[DEBUG 2018-10-25 00:52:09,603 cleverhans]     Iteration 300 of 500: loss=3.4 l2=3.27\n",
      "[DEBUG 2018-10-25 00:52:10,724 cleverhans]     Iteration 350 of 500: loss=3.13 l2=3.01\n",
      "[DEBUG 2018-10-25 00:52:11,835 cleverhans]     Iteration 400 of 500: loss=2.94 l2=2.82\n",
      "[DEBUG 2018-10-25 00:52:12,975 cleverhans]     Iteration 450 of 500: loss=2.79 l2=2.71\n",
      "[DEBUG 2018-10-25 00:52:14,152 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 00:52:14,153 cleverhans]    Mean successful distortion: 1.486\n",
      "[DEBUG 2018-10-25 00:52:14,155 cleverhans]   Binary search step 6 of 10\n",
      "[DEBUG 2018-10-25 00:52:14,174 cleverhans]     Iteration 0 of 500: loss=7.86 l2=0\n",
      "[DEBUG 2018-10-25 00:52:15,613 cleverhans]     Iteration 50 of 500: loss=4.42 l2=2.78\n",
      "[DEBUG 2018-10-25 00:52:16,991 cleverhans]     Iteration 100 of 500: loss=4.39 l2=2.75\n",
      "[DEBUG 2018-10-25 00:52:18,380 cleverhans]     Iteration 150 of 500: loss=4.37 l2=2.74\n",
      "[DEBUG 2018-10-25 00:52:19,755 cleverhans]     Iteration 200 of 500: loss=4.15 l2=2.75\n",
      "[DEBUG 2018-10-25 00:52:21,095 cleverhans]     Iteration 250 of 500: loss=3.81 l2=2.7\n",
      "[DEBUG 2018-10-25 00:52:22,422 cleverhans]     Iteration 300 of 500: loss=3.46 l2=2.62\n",
      "[DEBUG 2018-10-25 00:52:23,732 cleverhans]     Iteration 350 of 500: loss=3.17 l2=2.55\n",
      "[DEBUG 2018-10-25 00:52:25,017 cleverhans]     Iteration 400 of 500: loss=2.95 l2=2.46\n",
      "[DEBUG 2018-10-25 00:52:26,338 cleverhans]     Iteration 450 of 500: loss=2.79 l2=2.4\n",
      "[DEBUG 2018-10-25 00:52:27,660 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 00:52:27,661 cleverhans]    Mean successful distortion: 1.479\n",
      "[DEBUG 2018-10-25 00:52:27,662 cleverhans]   Binary search step 7 of 10\n",
      "[DEBUG 2018-10-25 00:52:27,681 cleverhans]     Iteration 0 of 500: loss=4.76 l2=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DEBUG 2018-10-25 00:52:29,333 cleverhans]     Iteration 50 of 500: loss=3.48 l2=1.3\n",
      "[DEBUG 2018-10-25 00:52:30,965 cleverhans]     Iteration 100 of 500: loss=3.47 l2=1.3\n",
      "[DEBUG 2018-10-25 00:52:32,575 cleverhans]     Iteration 150 of 500: loss=3.46 l2=1.3\n",
      "[DEBUG 2018-10-25 00:52:34,183 cleverhans]     Iteration 200 of 500: loss=3.44 l2=1.32\n",
      "[DEBUG 2018-10-25 00:52:35,805 cleverhans]     Iteration 250 of 500: loss=3.33 l2=1.36\n",
      "[DEBUG 2018-10-25 00:52:37,405 cleverhans]     Iteration 300 of 500: loss=3.17 l2=1.43\n",
      "[DEBUG 2018-10-25 00:52:38,968 cleverhans]     Iteration 350 of 500: loss=3.01 l2=1.46\n",
      "[DEBUG 2018-10-25 00:52:40,515 cleverhans]     Iteration 400 of 500: loss=2.87 l2=1.5\n",
      "[DEBUG 2018-10-25 00:52:42,091 cleverhans]     Iteration 450 of 500: loss=2.74 l2=1.55\n",
      "[DEBUG 2018-10-25 00:52:43,699 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 00:52:43,700 cleverhans]    Mean successful distortion: 1.477\n",
      "[DEBUG 2018-10-25 00:52:43,702 cleverhans]   Binary search step 8 of 10\n",
      "[DEBUG 2018-10-25 00:52:43,720 cleverhans]     Iteration 0 of 500: loss=5.24 l2=0\n",
      "[DEBUG 2018-10-25 00:52:45,366 cleverhans]     Iteration 50 of 500: loss=3.78 l2=1.57\n",
      "[DEBUG 2018-10-25 00:52:47,006 cleverhans]     Iteration 100 of 500: loss=3.77 l2=1.56\n",
      "[DEBUG 2018-10-25 00:52:48,654 cleverhans]     Iteration 150 of 500: loss=3.76 l2=1.56\n",
      "[DEBUG 2018-10-25 00:52:50,275 cleverhans]     Iteration 200 of 500: loss=3.74 l2=1.59\n",
      "[DEBUG 2018-10-25 00:52:51,918 cleverhans]     Iteration 250 of 500: loss=3.61 l2=1.68\n",
      "[DEBUG 2018-10-25 00:52:53,575 cleverhans]     Iteration 300 of 500: loss=3.4 l2=1.8\n",
      "[DEBUG 2018-10-25 00:52:55,177 cleverhans]     Iteration 350 of 500: loss=3.17 l2=1.91\n",
      "[DEBUG 2018-10-25 00:52:56,746 cleverhans]     Iteration 400 of 500: loss=2.96 l2=1.97\n",
      "[DEBUG 2018-10-25 00:52:58,293 cleverhans]     Iteration 450 of 500: loss=2.79 l2=1.98\n",
      "[DEBUG 2018-10-25 00:52:59,821 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 00:52:59,822 cleverhans]    Mean successful distortion: 1.477\n",
      "[DEBUG 2018-10-25 00:52:59,824 cleverhans]   Binary search step 9 of 10\n",
      "[DEBUG 2018-10-25 00:52:59,844 cleverhans]     Iteration 0 of 500: loss=6.16 l2=0\n",
      "[DEBUG 2018-10-25 00:53:01,454 cleverhans]     Iteration 50 of 500: loss=4.2 l2=2.1\n",
      "[DEBUG 2018-10-25 00:53:03,022 cleverhans]     Iteration 100 of 500: loss=4.18 l2=2.1\n",
      "[DEBUG 2018-10-25 00:53:04,579 cleverhans]     Iteration 150 of 500: loss=4.18 l2=2.1\n",
      "[DEBUG 2018-10-25 00:53:06,133 cleverhans]     Iteration 200 of 500: loss=4.13 l2=2.14\n",
      "[DEBUG 2018-10-25 00:53:07,675 cleverhans]     Iteration 250 of 500: loss=3.93 l2=2.28\n",
      "[DEBUG 2018-10-25 00:53:09,196 cleverhans]     Iteration 300 of 500: loss=3.62 l2=2.44\n",
      "[DEBUG 2018-10-25 00:53:10,671 cleverhans]     Iteration 350 of 500: loss=3.29 l2=2.55\n",
      "[DEBUG 2018-10-25 00:53:12,102 cleverhans]     Iteration 400 of 500: loss=3.02 l2=2.57\n",
      "[DEBUG 2018-10-25 00:53:13,560 cleverhans]     Iteration 450 of 500: loss=2.81 l2=2.51\n",
      "[DEBUG 2018-10-25 00:53:14,981 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 00:53:14,982 cleverhans]    Mean successful distortion: 1.477\n"
     ]
    }
   ],
   "source": [
    "# Untargeted\n",
    "\n",
    "keras.backend.set_learning_phase(0)\n",
    "set_log_level(logging.DEBUG)\n",
    "\n",
    "# CarliniWagner attack\n",
    "from lib.my_cw import CarliniWagnerL2\n",
    "\n",
    "attack_iterations = 500\n",
    "cw_params = {'binary_search_steps': 10,\n",
    "             'max_iterations': attack_iterations,\n",
    "             'learning_rate': 0.1,\n",
    "             'batch_size': n_attack,\n",
    "             'initial_const': 1}\n",
    "cw = CarliniWagnerL2(hingenet, sess=sess)\n",
    "adv = cw.generate_np(X_atk, **cw_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.052413613\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAD/ZJREFUeJzt3X+sX3V9x/HnaxXRoBsw7pqubXaJ62bQxELuKgtmcRiVH2bFZCOwTIkhqUswwcxsK/6jJiPBZMpitpHUwSybExvR0AhzdkhiSAZ4i6VSKrPTEtpUehVBGjMW6nt/3E/1jrW933u/99uv99PnIzn5nvM5n3PO+6Th9T187jnnm6pCktSvXxp3AZKk0TLoJalzBr0kdc6gl6TOGfSS1DmDXpI6Z9BLUucMeknqnEEvSZ17xbgLADjvvPNqcnJy3GVI0rKyc+fOH1TVxHz9fiGCfnJykunp6XGXIUnLSpKnBunn0I0kdc6gl6TOGfSS1DmDXpI6Z9BLUucMeknqnEEvSZ0z6CWpcwa9JHXuF+LJWC3M5OZ7x3bs/bdcObZjS1ocr+glqXMGvSR1zqCXpM4Z9JLUOYNekjpn0EtS5wx6SeqcQS9JnTPoJalz8wZ9klcleSTJY0n2JPlYa/9Mku8l2dWm9a09ST6VZF+S3UkuGvVJSJJObJBXILwIXFpVR5KcATyY5F/buj+vqi+8rP/lwLo2vRm4rX1KksZg3iv6mnWkLZ7RpjrJJhuBO9t2DwFnJ1k1fKmSpMUYaIw+yYoku4DDwI6qeriturkNz9ya5MzWthp4es7mB1qbJGkMBgr6qjpaVeuBNcCGJG8EbgJeD/wOcC7wlws5cJJNSaaTTM/MzCywbEnSoBZ0101VPQc8AFxWVYfa8MyLwD8CG1q3g8DaOZutaW0v39eWqpqqqqmJiYnFVS9Jmtcgd91MJDm7zb8aeDvw7WPj7kkCXAU83jbZDry33X1zMfB8VR0aSfWSpHkNctfNKmBrkhXMfjFsq6ovJ/lakgkgwC7gT1v/+4ArgH3AT4D3LX3ZkqRBzRv0VbUbuPA47ZeeoH8BNwxfmiRpKfhkrCR1zqCXpM4Z9JLUOYNekjpn0EtS5wx6SeqcQS9JnTPoJalzBr0kdc6gl6TOGfSS1DmDXpI6Z9BLUucMeknqnEEvSZ0z6CWpcwa9JHXOoJekzg3y4+CvSvJIkseS7EnysdZ+fpKHk+xL8vkkr2ztZ7blfW395GhPQZJ0MoNc0b8IXFpVbwLWA5cluRj4OHBrVf0m8CPg+tb/euBHrf3W1k+SNCaD/Dh4AUfa4hltKuBS4I9b+1bgo8BtwMY2D/AF4G+TpO1Hy9zk5nvHctz9t1w5luNKPRhojD7JiiS7gMPADuC/gOeq6qXW5QCwus2vBp4GaOufB351KYuWJA1uoKCvqqNVtR5YA2wAXj/sgZNsSjKdZHpmZmbY3UmSTmBBd91U1XPAA8DvAmcnOTb0swY42OYPAmsB2vpfAX54nH1tqaqpqpqamJhYZPmSpPkMctfNRJKz2/yrgbcDe5kN/D9s3a4D7mnz29sybf3XHJ+XpPGZ94+xwCpga5IVzH4xbKuqLyd5ArgryV8B3wRub/1vB/4pyT7gWeCaEdQtSRrQIHfd7AYuPE77d5kdr395+38Df7Qk1UmShuaTsZLUOYNekjpn0EtS5wx6SeqcQS9JnTPoJalzBr0kdc6gl6TOGfSS1DmDXpI6Z9BLUucMeknqnEEvSZ0z6CWpcwa9JHXOoJekzhn0ktQ5g16SOmfQS1Ln5g36JGuTPJDkiSR7ktzY2j+a5GCSXW26Ys42NyXZl+TJJO8c5QlIkk5u3h8HB14CPlRVjyZ5LbAzyY627taq+uu5nZNcAFwDvAH4deDfk/xWVR1dysIlSYOZ94q+qg5V1aNt/gVgL7D6JJtsBO6qqher6nvAPmDDUhQrSVq4BY3RJ5kELgQebk0fSLI7yR1Jzmltq4Gn52x2gJN/MUiSRmjgoE/yGuBu4INV9WPgNuB1wHrgEPCJhRw4yaYk00mmZ2ZmFrKpJGkBBgr6JGcwG/KfraovAlTVM1V1tKp+Cnyanw/PHATWztl8TWv7P6pqS1VNVdXUxMTEMOcgSTqJQe66CXA7sLeqPjmnfdWcbu8GHm/z24FrkpyZ5HxgHfDI0pUsSVqIQe66uQR4D/CtJLta24eBa5OsBwrYD7wfoKr2JNkGPMHsHTs3eMeNJI3PvEFfVQ8COc6q+06yzc3AzUPUJUlaIj4ZK0mdM+glqXMGvSR1zqCXpM4Z9JLUOYNekjpn0EtS5wx6SeqcQS9JnTPoJalzBr0kdc6gl6TOGfSS1DmDXpI6Z9BLUucMeknqnEEvSZ0z6CWpcwa9JHVu3qBPsjbJA0meSLInyY2t/dwkO5J8p32e09qT5FNJ9iXZneSiUZ+EJOnEBrmifwn4UFVdAFwM3JDkAmAzcH9VrQPub8sAlwPr2rQJuG3Jq5YkDWzeoK+qQ1X1aJt/AdgLrAY2Altbt63AVW1+I3BnzXoIODvJqiWvXJI0kAWN0SeZBC4EHgZWVtWhtur7wMo2vxp4es5mB1rby/e1Kcl0kumZmZkFli1JGtTAQZ/kNcDdwAer6sdz11VVAbWQA1fVlqqaqqqpiYmJhWwqSVqAgYI+yRnMhvxnq+qLrfmZY0My7fNwaz8IrJ2z+ZrWJkkag0HuuglwO7C3qj45Z9V24Lo2fx1wz5z297a7by4Gnp8zxCNJOsVeMUCfS4D3AN9Ksqu1fRi4BdiW5HrgKeDqtu4+4ApgH/AT4H1LWrEkaUHmDfqqehDICVa/7Tj9C7hhyLokSUvEJ2MlqXMGvSR1zqCXpM4Z9JLUOYNekjpn0EtS5wx6SeqcQS9JnTPoJalzBr0kdc6gl6TOGfSS1DmDXpI6Z9BLUucMeknqnEEvSZ0z6CWpcwa9JHVukB8HvyPJ4SSPz2n7aJKDSXa16Yo5625Ksi/Jk0neOarCJUmDGeSK/jPAZcdpv7Wq1rfpPoAkFwDXAG9o2/x9khVLVawkaeHmDfqq+jrw7ID72wjcVVUvVtX3gH3AhiHqkyQNaZgx+g8k2d2Gds5pbauBp+f0OdDaJEljstigvw14HbAeOAR8YqE7SLIpyXSS6ZmZmUWWIUmaz6KCvqqeqaqjVfVT4NP8fHjmILB2Ttc1re14+9hSVVNVNTUxMbGYMiRJA1hU0CdZNWfx3cCxO3K2A9ckOTPJ+cA64JHhSpQkDeMV83VI8jngrcB5SQ4AHwHemmQ9UMB+4P0AVbUnyTbgCeAl4IaqOjqa0iVJg5g36Kvq2uM0336S/jcDNw9TlCRp6fhkrCR1zqCXpM4Z9JLUOYNekjpn0EtS5wx6SeqcQS9JnTPoJalzBr0kdW7eJ2N1YpOb7x13CZI0L6/oJalzXtFrWRjn/z3tv+XKsR1bWgpe0UtS5wx6SeqcQS9JnTPoJalzBr0kdc6gl6TOGfSS1Ll5gz7JHUkOJ3l8Ttu5SXYk+U77PKe1J8mnkuxLsjvJRaMsXpI0v0Gu6D8DXPayts3A/VW1Dri/LQNcDqxr0ybgtqUpU5K0WPMGfVV9HXj2Zc0bga1tfitw1Zz2O2vWQ8DZSVYtVbGSpIVb7Bj9yqo61Oa/D6xs86uBp+f0O9DaJEljMvQfY6uqgFrodkk2JZlOMj0zMzNsGZKkE1hs0D9zbEimfR5u7QeBtXP6rWlt/09VbamqqaqampiYWGQZkqT5LDbotwPXtfnrgHvmtL+33X1zMfD8nCEeSdIYzPua4iSfA94KnJfkAPAR4BZgW5LrgaeAq1v3+4ArgH3AT4D3jaBmSdICzBv0VXXtCVa97Th9C7hh2KIkSUvHJ2MlqXMGvSR1zqCXpM4Z9JLUOYNekjpn0EtS5wx6SeqcQS9JnTPoJalzBr0kdc6gl6TOGfSS1DmDXpI6Z9BLUucMeknqnEEvSZ0z6CWpcwa9JHXOoJekzs37m7Enk2Q/8AJwFHipqqaSnAt8HpgE9gNXV9WPhitTkrRYS3FF//tVtb6qptryZuD+qloH3N+WJUljMoqhm43A1ja/FbhqBMeQJA1o2KAv4KtJdibZ1NpWVtWhNv99YOXxNkyyKcl0kumZmZkhy5AknchQY/TAW6rqYJJfA3Yk+fbclVVVSep4G1bVFmALwNTU1HH7SJKGN9QVfVUdbJ+HgS8BG4BnkqwCaJ+Hhy1SkrR4iw76JGclee2xeeAdwOPAduC61u064J5hi5QkLd4wQzcrgS8lObaff6mqryT5BrAtyfXAU8DVw5cpSVqsRQd9VX0XeNNx2n8IvG2YohZicvO9p+pQkrQs+WSsJHXOoJekzhn0ktQ5g16SOmfQS1LnDHpJ6tywr0CQujeuW3j333LlWI6r/nhFL0mdM+glqXMGvSR1zqCXpM4Z9JLUOYNekjpn0EtS5wx6SeqcQS9JnTPoJalzBr0kdW5kQZ/ksiRPJtmXZPOojiNJOrmRBH2SFcDfAZcDFwDXJrlgFMeSJJ3cqN5euQHY135AnCR3ARuBJ0Z0PKk7vjVTS2VUQb8aeHrO8gHgzSM6lqQlNK4vGPBLZlTG9j76JJuATW3xSJInF7mr84AfLE1Vy4bnfHo47c45Hz/9zpnh/p1/Y5BOowr6g8DaOctrWtvPVNUWYMuwB0oyXVVTw+5nOfGcTw+e8+nhVJzzqO66+QawLsn5SV4JXANsH9GxJEknMZIr+qp6KckHgH8DVgB3VNWeURxLknRyIxujr6r7gPtGtf85hh7+WYY859OD53x6GPk5p6pGfQxJ0hj5CgRJ6tyyDvrT7TULSe5IcjjJ4+Ou5VRJsjbJA0meSLInyY3jrmnUkrwqySNJHmvn/LFx13QqJFmR5JtJvjzuWk6FJPuTfCvJriTTIz3Wch26aa9Z+E/g7cw+kPUN4Nqq6vbp2yS/BxwB7qyqN467nlMhySpgVVU9muS1wE7gqs7/nQOcVVVHkpwBPAjcWFUPjbm0kUryZ8AU8MtV9a5x1zNqSfYDU1U18ucGlvMV/c9es1BV/wMce81Ct6rq68Cz467jVKqqQ1X1aJt/AdjL7JPX3apZR9riGW1anldkA0qyBrgS+Idx19Kj5Rz0x3vNQtcBcLpLMglcCDw83kpGrw1j7AIOAzuqqvdz/hvgL4CfjruQU6iArybZ2d4UMDLLOeh1GknyGuBu4INV9eNx1zNqVXW0qtYz+1T5hiTdDtUleRdwuKp2jruWU+wtVXURs2/5vaENzY7Ecg76eV+zoD60ceq7gc9W1RfHXc+pVFXPAQ8Al427lhG6BPiDNmZ9F3Bpkn8eb0mjV1UH2+dh4EvMDkePxHIOel+zcBpof5i8HdhbVZ8cdz2nQpKJJGe3+Vcze8PBt8db1ehU1U1VtaaqJpn97/hrVfUnYy5rpJKc1W4uIMlZwDuAkd1Nt2yDvqpeAo69ZmEvsK331ywk+RzwH8BvJzmQ5Ppx13QKXAK8h9mrvF1tumLcRY3YKuCBJLuZvaDZUVWnxS2Hp5GVwINJHgMeAe6tqq+M6mDL9vZKSdJglu0VvSRpMAa9JHXOoJekzhn0ktQ5g16SOmfQS1LnDHpJ6pxBL0md+18iejww7Lh8nAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dist = np.sqrt(np.sum((X_atk - adv)**2, (1, 2, 3)))\n",
    "plt.hist(dist, bins=10, range=(0, 5))\n",
    "print(np.min(dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = hingenet.predict_model(sess, adv)\n",
    "y_pred = np.argmax(output, axis=1)\n",
    "max_out = np.max(output, axis=1)\n",
    "ind = []\n",
    "y_target = np.argmax(y_target, axis=1)\n",
    "for i in range(n_attack):\n",
    "    if y_pred[i] == y_target[i]:\n",
    "        ind.append(i)\n",
    "ind = np.array(ind)\n",
    "avg_out = np.mean(max_out[ind])\n",
    "dist = np.mean(np.sqrt(np.sum((adv[ind] - X_atk[ind])**2, (1, 2, 3))))\n",
    "print(avg_out)\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = hingenet.predict_model(sess, adv)\n",
    "\n",
    "for x, y in zip(adv[:10], y_pred[:10]):\n",
    "    print(np.argmax(y))\n",
    "    print(y)\n",
    "    plt.imshow(x[:, :, 0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= EPOCH: 0 =============\n",
      "STEP: 0 \tLoss: 209.0180\n",
      "STEP: 50 \tLoss: 101.9859\n",
      "STEP: 100 \tLoss: 100.0184\n",
      "STEP: 150 \tLoss: 100.0015\n",
      "STEP: 200 \tLoss: 100.0007\n",
      "STEP: 250 \tLoss: 100.0004\n",
      "STEP: 300 \tLoss: 100.0008\n",
      "STEP: 350 \tLoss: 100.0004\n",
      "STEP: 400 \tLoss: 100.0005\n",
      "STEP: 450 \tLoss: 100.0006\n",
      "Train Acc|Loss:\t0.0992|100.0007\n",
      "Val Acc|Loss:\t0.1009|100.0007\n",
      "============= EPOCH: 1 =============\n",
      "STEP: 0 \tLoss: 100.0007\n",
      "STEP: 50 \tLoss: 100.0005\n",
      "STEP: 100 \tLoss: 100.0005\n",
      "STEP: 150 \tLoss: 100.0007\n",
      "STEP: 200 \tLoss: 100.0006\n",
      "STEP: 250 \tLoss: 100.0004\n",
      "STEP: 300 \tLoss: 100.0004\n",
      "STEP: 350 \tLoss: 100.0004\n",
      "STEP: 400 \tLoss: 100.0003\n",
      "STEP: 450 \tLoss: 100.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method TF_Output.<lambda> of <tensorflow.python.pywrap_tensorflow_internal.TF_Output; proxy of <Swig Object of type 'TF_Output *' at 0x7fa4622c0f90> >>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 963, in <lambda>\n",
      "    __del__ = lambda self: None\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc|Loss:\t0.1124|100.0005\n",
      "Val Acc|Loss:\t0.1135|100.0005\n",
      "============= EPOCH: 2 =============\n",
      "STEP: 0 \tLoss: 100.0005\n",
      "STEP: 50 \tLoss: 100.0006\n",
      "STEP: 100 \tLoss: 100.0003\n",
      "STEP: 150 \tLoss: 100.0003\n",
      "STEP: 200 \tLoss: 100.0004\n",
      "STEP: 250 \tLoss: 100.0005\n",
      "STEP: 300 \tLoss: 100.0008\n",
      "STEP: 350 \tLoss: 100.0005\n",
      "STEP: 400 \tLoss: 100.0004\n",
      "STEP: 450 \tLoss: 100.0004\n",
      "Train Acc|Loss:\t0.0975|100.0006\n",
      "Val Acc|Loss:\t0.0974|100.0006\n",
      "============= EPOCH: 3 =============\n",
      "STEP: 0 \tLoss: 100.0006\n",
      "STEP: 50 \tLoss: 100.0006\n",
      "STEP: 100 \tLoss: 100.0007\n",
      "STEP: 150 \tLoss: 100.0005\n",
      "STEP: 200 \tLoss: 100.0005\n",
      "STEP: 250 \tLoss: 100.0007\n",
      "STEP: 300 \tLoss: 100.0002\n",
      "STEP: 350 \tLoss: 100.0005\n",
      "STEP: 400 \tLoss: 100.0005\n",
      "STEP: 450 \tLoss: 100.0008\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-249-092dafbb4544>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"hinge\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmargin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                     save_path=\"model/hingenet_v2.3.h5\")\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mhingenet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/research/nn_proof/hinge_net.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, sess, data, n_epoch, batch_size)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;31m# Print progress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m             \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mval_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train Acc|Loss:\\t{:.4f}|{:.4f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/research/nn_proof/hinge_net.py\u001b[0m in \u001b[0;36meval_model\u001b[0;34m(self, sess, data, batch_size)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/research/nn_proof/hinge_net.py\u001b[0m in \u001b[0;36mpredict_model\u001b[0;34m(self, sess, x, y, batch_size)\u001b[0m\n\u001b[1;32m    207\u001b[0m                 \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m                 output[start:end], l = sess.run([self.output, self.loss], \n\u001b[0;32m--> 209\u001b[0;31m                                                 feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m    210\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1276\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from hinge_net import HingeNet\n",
    "\n",
    "# v2: margin = 1e2\n",
    "hingenet = HingeNet(\"hingenet_v2.3\", [28, 28, 1], [10], learning_rate=1e-3, \n",
    "                    loss=\"hinge\", margin=1e2, load_model=False, reg=1e-1,\n",
    "                    save_path=\"model/hingenet_v2.3.h5\")\n",
    "hingenet.train_model(sess, data, n_epoch=20, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9911, 6.859127086639404)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hingenet.eval_model(sess, (X_test[:, :, :, np.newaxis], np.argmax(y_test, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Least likeley class\n",
    "n_attack = 1000\n",
    "X_atk = X_test[:, :, :, np.newaxis][:n_attack]\n",
    "y_atk = np.argmax(y_test[:n_attack], axis=1)\n",
    "\n",
    "y_pred = hingenet.predict_model(sess, X_atk)\n",
    "y_target = to_categorical(np.argmin(y_pred, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.989, 7.350222396850586)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hingenet.eval_model(sess, (X_atk, y_atk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2018-10-25 18:21:55,441 cleverhans] Constructing new graph for attack CarliniWagnerL2\n",
      "[DEBUG 2018-10-25 18:21:56,912 cleverhans] Running CWL2 attack on instance 0 of 1000\n",
      "[DEBUG 2018-10-25 18:21:57,314 cleverhans]   Binary search step 0 of 10\n",
      "[DEBUG 2018-10-25 18:21:58,066 cleverhans]     Iteration 0 of 500: loss=620 l2=0\n",
      "[DEBUG 2018-10-25 18:21:59,179 cleverhans]     Iteration 50 of 500: loss=60.8 l2=36.1\n",
      "[DEBUG 2018-10-25 18:22:00,212 cleverhans]     Iteration 100 of 500: loss=29.3 l2=28.8\n",
      "[DEBUG 2018-10-25 18:22:01,341 cleverhans]     Iteration 150 of 500: loss=24.6 l2=24.6\n",
      "[DEBUG 2018-10-25 18:22:02,259 cleverhans]     Iteration 200 of 500: loss=22.1 l2=22\n",
      "[DEBUG 2018-10-25 18:22:03,087 cleverhans]     Iteration 250 of 500: loss=20.1 l2=20\n",
      "[DEBUG 2018-10-25 18:22:03,850 cleverhans]     Iteration 300 of 500: loss=18.6 l2=18.5\n",
      "[DEBUG 2018-10-25 18:22:04,562 cleverhans]     Iteration 350 of 500: loss=17.5 l2=17.4\n",
      "[DEBUG 2018-10-25 18:22:05,227 cleverhans]     Iteration 400 of 500: loss=16.7 l2=16.6\n",
      "[DEBUG 2018-10-25 18:22:05,891 cleverhans]     Iteration 450 of 500: loss=16.2 l2=16\n",
      "[DEBUG 2018-10-25 18:22:06,528 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 18:22:06,529 cleverhans]    Mean successful distortion: 3.576\n",
      "[DEBUG 2018-10-25 18:22:06,531 cleverhans]   Binary search step 1 of 10\n",
      "[DEBUG 2018-10-25 18:22:06,541 cleverhans]     Iteration 0 of 500: loss=310 l2=0\n",
      "[DEBUG 2018-10-25 18:22:07,494 cleverhans]     Iteration 50 of 500: loss=42.5 l2=30.1\n",
      "[DEBUG 2018-10-25 18:22:08,373 cleverhans]     Iteration 100 of 500: loss=25.1 l2=23.2\n",
      "[DEBUG 2018-10-25 18:22:09,184 cleverhans]     Iteration 150 of 500: loss=20.5 l2=20.4\n",
      "[DEBUG 2018-10-25 18:22:09,924 cleverhans]     Iteration 200 of 500: loss=18.1 l2=17.9\n",
      "[DEBUG 2018-10-25 18:22:10,615 cleverhans]     Iteration 250 of 500: loss=16.3 l2=16.1\n",
      "[DEBUG 2018-10-25 18:22:11,264 cleverhans]     Iteration 300 of 500: loss=14.9 l2=14.7\n",
      "[DEBUG 2018-10-25 18:22:11,938 cleverhans]     Iteration 350 of 500: loss=14 l2=13.9\n",
      "[DEBUG 2018-10-25 18:22:12,632 cleverhans]     Iteration 400 of 500: loss=13.4 l2=13.2\n",
      "[DEBUG 2018-10-25 18:22:13,306 cleverhans]     Iteration 450 of 500: loss=13.1 l2=12.9\n",
      "[DEBUG 2018-10-25 18:22:13,950 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 18:22:13,952 cleverhans]    Mean successful distortion: 3.277\n",
      "[DEBUG 2018-10-25 18:22:13,953 cleverhans]   Binary search step 2 of 10\n",
      "[DEBUG 2018-10-25 18:22:13,964 cleverhans]     Iteration 0 of 500: loss=155 l2=0\n",
      "[DEBUG 2018-10-25 18:22:14,945 cleverhans]     Iteration 50 of 500: loss=29.6 l2=23\n",
      "[DEBUG 2018-10-25 18:22:15,795 cleverhans]     Iteration 100 of 500: loss=22.6 l2=19\n",
      "[DEBUG 2018-10-25 18:22:16,533 cleverhans]     Iteration 150 of 500: loss=18.2 l2=17.9\n",
      "[DEBUG 2018-10-25 18:22:17,243 cleverhans]     Iteration 200 of 500: loss=15.9 l2=15.7\n",
      "[DEBUG 2018-10-25 18:22:17,944 cleverhans]     Iteration 250 of 500: loss=14.1 l2=13.9\n",
      "[DEBUG 2018-10-25 18:22:18,617 cleverhans]     Iteration 300 of 500: loss=13 l2=12.8\n",
      "[DEBUG 2018-10-25 18:22:19,281 cleverhans]     Iteration 350 of 500: loss=12.3 l2=12.1\n",
      "[DEBUG 2018-10-25 18:22:19,916 cleverhans]     Iteration 400 of 500: loss=11.9 l2=11.6\n",
      "[DEBUG 2018-10-25 18:22:20,561 cleverhans]     Iteration 450 of 500: loss=11.5 l2=11.3\n",
      "[DEBUG 2018-10-25 18:22:21,230 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 18:22:21,231 cleverhans]    Mean successful distortion: 3.148\n",
      "[DEBUG 2018-10-25 18:22:21,233 cleverhans]   Binary search step 3 of 10\n",
      "[DEBUG 2018-10-25 18:22:21,243 cleverhans]     Iteration 0 of 500: loss=77.5 l2=0\n",
      "[DEBUG 2018-10-25 18:22:22,249 cleverhans]     Iteration 50 of 500: loss=22.1 l2=17.7\n",
      "[DEBUG 2018-10-25 18:22:23,136 cleverhans]     Iteration 100 of 500: loss=20 l2=16.4\n",
      "[DEBUG 2018-10-25 18:22:23,939 cleverhans]     Iteration 150 of 500: loss=17.6 l2=16.1\n",
      "[DEBUG 2018-10-25 18:22:24,732 cleverhans]     Iteration 200 of 500: loss=14.9 l2=14.5\n",
      "[DEBUG 2018-10-25 18:22:25,501 cleverhans]     Iteration 250 of 500: loss=13.2 l2=12.9\n",
      "[DEBUG 2018-10-25 18:22:26,213 cleverhans]     Iteration 300 of 500: loss=12.2 l2=11.9\n",
      "[DEBUG 2018-10-25 18:22:26,902 cleverhans]     Iteration 350 of 500: loss=11.6 l2=11.3\n",
      "[DEBUG 2018-10-25 18:22:27,596 cleverhans]     Iteration 400 of 500: loss=11.1 l2=10.9\n",
      "[DEBUG 2018-10-25 18:22:28,309 cleverhans]     Iteration 450 of 500: loss=10.9 l2=10.6\n",
      "[DEBUG 2018-10-25 18:22:29,062 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 18:22:29,063 cleverhans]    Mean successful distortion: 3.098\n",
      "[DEBUG 2018-10-25 18:22:29,064 cleverhans]   Binary search step 4 of 10\n",
      "[DEBUG 2018-10-25 18:22:29,074 cleverhans]     Iteration 0 of 500: loss=38.8 l2=0\n",
      "[DEBUG 2018-10-25 18:22:30,196 cleverhans]     Iteration 50 of 500: loss=17.7 l2=12.8\n",
      "[DEBUG 2018-10-25 18:22:31,185 cleverhans]     Iteration 100 of 500: loss=17.1 l2=12.6\n",
      "[DEBUG 2018-10-25 18:22:32,125 cleverhans]     Iteration 150 of 500: loss=16.7 l2=12.6\n",
      "[DEBUG 2018-10-25 18:22:33,050 cleverhans]     Iteration 200 of 500: loss=14.9 l2=12.2\n",
      "[DEBUG 2018-10-25 18:22:33,968 cleverhans]     Iteration 250 of 500: loss=13.1 l2=11.4\n",
      "[DEBUG 2018-10-25 18:22:34,833 cleverhans]     Iteration 300 of 500: loss=12 l2=10.7\n",
      "[DEBUG 2018-10-25 18:22:35,676 cleverhans]     Iteration 350 of 500: loss=11.2 l2=10.3\n",
      "[DEBUG 2018-10-25 18:22:36,525 cleverhans]     Iteration 400 of 500: loss=10.8 l2=10.1\n",
      "[DEBUG 2018-10-25 18:22:37,428 cleverhans]     Iteration 450 of 500: loss=10.5 l2=9.88\n",
      "[DEBUG 2018-10-25 18:22:38,367 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 18:22:38,368 cleverhans]    Mean successful distortion: 3.075\n",
      "[DEBUG 2018-10-25 18:22:38,369 cleverhans]   Binary search step 5 of 10\n",
      "[DEBUG 2018-10-25 18:22:38,379 cleverhans]     Iteration 0 of 500: loss=21.3 l2=0\n",
      "[DEBUG 2018-10-25 18:22:39,657 cleverhans]     Iteration 50 of 500: loss=14 l2=6.63\n",
      "[DEBUG 2018-10-25 18:22:40,883 cleverhans]     Iteration 100 of 500: loss=13.9 l2=6.59\n",
      "[DEBUG 2018-10-25 18:22:42,122 cleverhans]     Iteration 150 of 500: loss=13.8 l2=6.62\n",
      "[DEBUG 2018-10-25 18:22:43,389 cleverhans]     Iteration 200 of 500: loss=13.4 l2=6.72\n",
      "[DEBUG 2018-10-25 18:22:44,647 cleverhans]     Iteration 250 of 500: loss=12.6 l2=6.94\n",
      "[DEBUG 2018-10-25 18:22:45,882 cleverhans]     Iteration 300 of 500: loss=11.8 l2=7.14\n",
      "[DEBUG 2018-10-25 18:22:47,116 cleverhans]     Iteration 350 of 500: loss=11.1 l2=7.26\n",
      "[DEBUG 2018-10-25 18:22:48,317 cleverhans]     Iteration 400 of 500: loss=10.6 l2=7.34\n",
      "[DEBUG 2018-10-25 18:22:49,543 cleverhans]     Iteration 450 of 500: loss=10.3 l2=7.37\n",
      "[DEBUG 2018-10-25 18:22:50,799 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 18:22:50,799 cleverhans]    Mean successful distortion: 3.07\n",
      "[DEBUG 2018-10-25 18:22:50,801 cleverhans]   Binary search step 6 of 10\n",
      "[DEBUG 2018-10-25 18:22:50,811 cleverhans]     Iteration 0 of 500: loss=21.4 l2=0\n",
      "[DEBUG 2018-10-25 18:22:52,139 cleverhans]     Iteration 50 of 500: loss=14 l2=6.42\n",
      "[DEBUG 2018-10-25 18:22:53,429 cleverhans]     Iteration 100 of 500: loss=13.8 l2=6.43\n",
      "[DEBUG 2018-10-25 18:22:54,736 cleverhans]     Iteration 150 of 500: loss=13.7 l2=6.48\n",
      "[DEBUG 2018-10-25 18:22:56,027 cleverhans]     Iteration 200 of 500: loss=13.2 l2=6.63\n",
      "[DEBUG 2018-10-25 18:22:57,337 cleverhans]     Iteration 250 of 500: loss=12.3 l2=6.79\n",
      "[DEBUG 2018-10-25 18:22:58,614 cleverhans]     Iteration 300 of 500: loss=11.6 l2=6.89\n",
      "[DEBUG 2018-10-25 18:22:59,883 cleverhans]     Iteration 350 of 500: loss=10.9 l2=7.02\n",
      "[DEBUG 2018-10-25 18:23:01,138 cleverhans]     Iteration 400 of 500: loss=10.5 l2=7.11\n",
      "[DEBUG 2018-10-25 18:23:02,400 cleverhans]     Iteration 450 of 500: loss=10.2 l2=7.18\n",
      "[DEBUG 2018-10-25 18:23:03,679 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 18:23:03,680 cleverhans]    Mean successful distortion: 3.068\n",
      "[DEBUG 2018-10-25 18:23:03,682 cleverhans]   Binary search step 7 of 10\n",
      "[DEBUG 2018-10-25 18:23:03,692 cleverhans]     Iteration 0 of 500: loss=22.2 l2=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DEBUG 2018-10-25 18:23:05,016 cleverhans]     Iteration 50 of 500: loss=14.7 l2=6.85\n",
      "[DEBUG 2018-10-25 18:23:06,338 cleverhans]     Iteration 100 of 500: loss=14.6 l2=6.85\n",
      "[DEBUG 2018-10-25 18:23:07,646 cleverhans]     Iteration 150 of 500: loss=14.5 l2=6.88\n",
      "[DEBUG 2018-10-25 18:23:08,955 cleverhans]     Iteration 200 of 500: loss=14.1 l2=7.01\n",
      "[DEBUG 2018-10-25 18:23:10,249 cleverhans]     Iteration 250 of 500: loss=13.3 l2=7.4\n",
      "[DEBUG 2018-10-25 18:23:11,538 cleverhans]     Iteration 300 of 500: loss=12.4 l2=7.81\n",
      "[DEBUG 2018-10-25 18:23:12,795 cleverhans]     Iteration 350 of 500: loss=11.6 l2=8.11\n",
      "[DEBUG 2018-10-25 18:23:14,058 cleverhans]     Iteration 400 of 500: loss=11 l2=8.35\n",
      "[DEBUG 2018-10-25 18:23:15,312 cleverhans]     Iteration 450 of 500: loss=10.6 l2=8.5\n",
      "[DEBUG 2018-10-25 18:23:16,583 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 18:23:16,584 cleverhans]    Mean successful distortion: 3.067\n",
      "[DEBUG 2018-10-25 18:23:16,586 cleverhans]   Binary search step 8 of 10\n",
      "[DEBUG 2018-10-25 18:23:16,598 cleverhans]     Iteration 0 of 500: loss=22.2 l2=0\n",
      "[DEBUG 2018-10-25 18:23:17,975 cleverhans]     Iteration 50 of 500: loss=14.8 l2=6.81\n",
      "[DEBUG 2018-10-25 18:23:19,335 cleverhans]     Iteration 100 of 500: loss=14.7 l2=6.8\n",
      "[DEBUG 2018-10-25 18:23:20,670 cleverhans]     Iteration 150 of 500: loss=14.6 l2=6.83\n",
      "[DEBUG 2018-10-25 18:23:21,988 cleverhans]     Iteration 200 of 500: loss=14.3 l2=6.97\n",
      "[DEBUG 2018-10-25 18:23:23,316 cleverhans]     Iteration 250 of 500: loss=13.4 l2=7.37\n",
      "[DEBUG 2018-10-25 18:23:24,647 cleverhans]     Iteration 300 of 500: loss=12.5 l2=7.83\n",
      "[DEBUG 2018-10-25 18:23:25,941 cleverhans]     Iteration 350 of 500: loss=11.7 l2=8.3\n",
      "[DEBUG 2018-10-25 18:23:27,152 cleverhans]     Iteration 400 of 500: loss=11.1 l2=8.69\n",
      "[DEBUG 2018-10-25 18:23:28,449 cleverhans]     Iteration 450 of 500: loss=10.7 l2=8.88\n",
      "[DEBUG 2018-10-25 18:23:29,700 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 18:23:29,701 cleverhans]    Mean successful distortion: 3.067\n",
      "[DEBUG 2018-10-25 18:23:29,702 cleverhans]   Binary search step 9 of 10\n",
      "[DEBUG 2018-10-25 18:23:29,713 cleverhans]     Iteration 0 of 500: loss=23.4 l2=0\n",
      "[DEBUG 2018-10-25 18:23:31,045 cleverhans]     Iteration 50 of 500: loss=15.3 l2=7.48\n",
      "[DEBUG 2018-10-25 18:23:32,362 cleverhans]     Iteration 100 of 500: loss=15.1 l2=7.48\n",
      "[DEBUG 2018-10-25 18:23:33,679 cleverhans]     Iteration 150 of 500: loss=15.1 l2=7.53\n",
      "[DEBUG 2018-10-25 18:23:34,968 cleverhans]     Iteration 200 of 500: loss=14.6 l2=7.74\n",
      "[DEBUG 2018-10-25 18:23:36,249 cleverhans]     Iteration 250 of 500: loss=13.6 l2=8.18\n",
      "[DEBUG 2018-10-25 18:23:37,577 cleverhans]     Iteration 300 of 500: loss=12.6 l2=8.71\n",
      "[DEBUG 2018-10-25 18:23:38,822 cleverhans]     Iteration 350 of 500: loss=11.7 l2=9.17\n",
      "[DEBUG 2018-10-25 18:23:40,059 cleverhans]     Iteration 400 of 500: loss=11 l2=9.53\n",
      "[DEBUG 2018-10-25 18:23:41,239 cleverhans]     Iteration 450 of 500: loss=10.6 l2=9.59\n",
      "[DEBUG 2018-10-25 18:23:42,411 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 18:23:42,412 cleverhans]    Mean successful distortion: 3.067\n"
     ]
    }
   ],
   "source": [
    "keras.backend.set_learning_phase(0)\n",
    "set_log_level(logging.DEBUG)\n",
    "\n",
    "# CarliniWagner attack\n",
    "from lib.my_cw import CarliniWagnerL2\n",
    "\n",
    "attack_iterations = 500\n",
    "cw_params = {'binary_search_steps': 10,\n",
    "             'max_iterations': attack_iterations,\n",
    "             'learning_rate': 0.1,\n",
    "             'batch_size': n_attack,\n",
    "             'initial_const': 1,\n",
    "             'y_target': y_target}\n",
    "cw = CarliniWagnerL2(hingenet, sess=sess)\n",
    "adv = cw.generate_np(X_atk, **cw_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from hinge_net import HingeNet\n",
    "\n",
    "# v3: margin = 1e3\n",
    "hingenet = HingeNet(\"hingenet_v3\", [28, 28, 1], [10], learning_rate=1e-3, \n",
    "                    loss=\"hinge\", margin=1e3, load_model=True, \n",
    "                    save_path=\"model/hingenet_v3.h5\")\n",
    "# hingenet.train_model(sess, data, n_epoch=20, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9883, 29.553343701171876)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hingenet.eval_model(sess, (X_test[:, :, :, np.newaxis], np.argmax(y_test, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Least likeley class\n",
    "n_attack = 1000\n",
    "X_atk = X_test[:, :, :, np.newaxis][:n_attack]\n",
    "y_atk = np.argmax(y_test[:n_attack], axis=1)\n",
    "\n",
    "y_pred = hingenet.predict_model(sess, X_atk)\n",
    "y_target = to_categorical(np.argmin(y_pred, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.986, 33.34422201538086)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hingenet.eval_model(sess, (X_atk, y_atk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2018-10-25 03:59:54,236 cleverhans] Constructing new graph for attack CarliniWagnerL2\n",
      "[DEBUG 2018-10-25 03:59:54,651 cleverhans] Running CWL2 attack on instance 0 of 1000\n",
      "[DEBUG 2018-10-25 03:59:54,807 cleverhans]   Binary search step 0 of 10\n",
      "[DEBUG 2018-10-25 03:59:55,060 cleverhans]     Iteration 0 of 1000: loss=1.1e+04 l2=0\n",
      "[DEBUG 2018-10-25 03:59:57,457 cleverhans]     Iteration 100 of 1000: loss=47.8 l2=47.8\n",
      "[DEBUG 2018-10-25 03:59:59,345 cleverhans]     Iteration 200 of 1000: loss=42.8 l2=42.8\n",
      "[DEBUG 2018-10-25 04:00:01,328 cleverhans]     Iteration 300 of 1000: loss=38.6 l2=38.6\n",
      "[DEBUG 2018-10-25 04:00:03,656 cleverhans]     Iteration 400 of 1000: loss=35.1 l2=35.1\n",
      "[DEBUG 2018-10-25 04:00:06,409 cleverhans]     Iteration 500 of 1000: loss=32.6 l2=32.6\n",
      "[DEBUG 2018-10-25 04:00:09,404 cleverhans]     Iteration 600 of 1000: loss=31.4 l2=31.4\n",
      "[DEBUG 2018-10-25 04:00:12,246 cleverhans]     Iteration 700 of 1000: loss=30.4 l2=30.4\n",
      "[DEBUG 2018-10-25 04:00:14,936 cleverhans]     Iteration 800 of 1000: loss=29.8 l2=29.8\n",
      "[DEBUG 2018-10-25 04:00:17,512 cleverhans]     Iteration 900 of 1000: loss=28.9 l2=28.9\n",
      "[DEBUG 2018-10-25 04:00:19,982 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 04:00:19,983 cleverhans]    Mean successful distortion: 4.887\n",
      "[DEBUG 2018-10-25 04:00:19,984 cleverhans]   Binary search step 1 of 10\n",
      "[DEBUG 2018-10-25 04:00:20,003 cleverhans]     Iteration 0 of 1000: loss=5.5e+03 l2=0\n",
      "[DEBUG 2018-10-25 04:00:22,300 cleverhans]     Iteration 100 of 1000: loss=45.1 l2=45.1\n",
      "[DEBUG 2018-10-25 04:00:24,226 cleverhans]     Iteration 200 of 1000: loss=38.2 l2=38.2\n",
      "[DEBUG 2018-10-25 04:00:26,407 cleverhans]     Iteration 300 of 1000: loss=33.1 l2=33.1\n",
      "[DEBUG 2018-10-25 04:00:28,824 cleverhans]     Iteration 400 of 1000: loss=30.2 l2=30.2\n",
      "[DEBUG 2018-10-25 04:00:31,206 cleverhans]     Iteration 500 of 1000: loss=28.6 l2=28.6\n",
      "[DEBUG 2018-10-25 04:00:33,497 cleverhans]     Iteration 600 of 1000: loss=27.5 l2=27.5\n",
      "[DEBUG 2018-10-25 04:00:35,944 cleverhans]     Iteration 700 of 1000: loss=26.4 l2=26.3\n",
      "[DEBUG 2018-10-25 04:00:38,372 cleverhans]     Iteration 800 of 1000: loss=25.8 l2=25.8\n",
      "[DEBUG 2018-10-25 04:00:40,711 cleverhans]     Iteration 900 of 1000: loss=25.1 l2=25.1\n",
      "[DEBUG 2018-10-25 04:00:43,026 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 04:00:43,027 cleverhans]    Mean successful distortion: 4.436\n",
      "[DEBUG 2018-10-25 04:00:43,029 cleverhans]   Binary search step 2 of 10\n",
      "[DEBUG 2018-10-25 04:00:43,048 cleverhans]     Iteration 0 of 1000: loss=2.75e+03 l2=0\n",
      "[DEBUG 2018-10-25 04:00:45,344 cleverhans]     Iteration 100 of 1000: loss=41.2 l2=41.2\n",
      "[DEBUG 2018-10-25 04:00:47,463 cleverhans]     Iteration 200 of 1000: loss=32.5 l2=32.5\n",
      "[DEBUG 2018-10-25 04:00:49,854 cleverhans]     Iteration 300 of 1000: loss=28.2 l2=28.2\n",
      "[DEBUG 2018-10-25 04:00:52,102 cleverhans]     Iteration 400 of 1000: loss=25.9 l2=25.9\n",
      "[DEBUG 2018-10-25 04:00:54,205 cleverhans]     Iteration 500 of 1000: loss=24.3 l2=24.3\n",
      "[DEBUG 2018-10-25 04:00:56,316 cleverhans]     Iteration 600 of 1000: loss=23.2 l2=23.1\n",
      "[DEBUG 2018-10-25 04:00:58,532 cleverhans]     Iteration 700 of 1000: loss=22.2 l2=22.2\n",
      "[DEBUG 2018-10-25 04:01:00,768 cleverhans]     Iteration 800 of 1000: loss=21.7 l2=21.6\n",
      "[DEBUG 2018-10-25 04:01:02,900 cleverhans]     Iteration 900 of 1000: loss=21 l2=20.9\n",
      "[DEBUG 2018-10-25 04:01:04,977 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 04:01:04,978 cleverhans]    Mean successful distortion: 3.929\n",
      "[DEBUG 2018-10-25 04:01:04,979 cleverhans]   Binary search step 3 of 10\n",
      "[DEBUG 2018-10-25 04:01:04,998 cleverhans]     Iteration 0 of 1000: loss=1.37e+03 l2=0\n",
      "[DEBUG 2018-10-25 04:01:07,350 cleverhans]     Iteration 100 of 1000: loss=35.8 l2=35.8\n",
      "[DEBUG 2018-10-25 04:01:09,738 cleverhans]     Iteration 200 of 1000: loss=27.1 l2=27\n",
      "[DEBUG 2018-10-25 04:01:11,995 cleverhans]     Iteration 300 of 1000: loss=23.6 l2=23.6\n",
      "[DEBUG 2018-10-25 04:01:14,159 cleverhans]     Iteration 400 of 1000: loss=21.3 l2=21.2\n",
      "[DEBUG 2018-10-25 04:01:16,254 cleverhans]     Iteration 500 of 1000: loss=19.7 l2=19.6\n",
      "[DEBUG 2018-10-25 04:01:18,351 cleverhans]     Iteration 600 of 1000: loss=18.7 l2=18.5\n",
      "[DEBUG 2018-10-25 04:01:20,403 cleverhans]     Iteration 700 of 1000: loss=17.9 l2=17.8\n",
      "[DEBUG 2018-10-25 04:01:22,427 cleverhans]     Iteration 800 of 1000: loss=17.1 l2=17\n",
      "[DEBUG 2018-10-25 04:01:24,451 cleverhans]     Iteration 900 of 1000: loss=16.9 l2=16.8\n",
      "[DEBUG 2018-10-25 04:01:26,431 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 04:01:26,432 cleverhans]    Mean successful distortion: 3.454\n",
      "[DEBUG 2018-10-25 04:01:26,433 cleverhans]   Binary search step 4 of 10\n",
      "[DEBUG 2018-10-25 04:01:26,452 cleverhans]     Iteration 0 of 1000: loss=687 l2=0\n",
      "[DEBUG 2018-10-25 04:01:28,930 cleverhans]     Iteration 100 of 1000: loss=29.4 l2=29.2\n",
      "[DEBUG 2018-10-25 04:01:31,329 cleverhans]     Iteration 200 of 1000: loss=22.4 l2=22.3\n",
      "[DEBUG 2018-10-25 04:01:33,507 cleverhans]     Iteration 300 of 1000: loss=18.9 l2=18.8\n",
      "[DEBUG 2018-10-25 04:01:35,548 cleverhans]     Iteration 400 of 1000: loss=16.7 l2=16.5\n",
      "[DEBUG 2018-10-25 04:01:37,523 cleverhans]     Iteration 500 of 1000: loss=15.3 l2=15.2\n",
      "[DEBUG 2018-10-25 04:01:39,495 cleverhans]     Iteration 600 of 1000: loss=14.7 l2=14.5\n",
      "[DEBUG 2018-10-25 04:01:41,492 cleverhans]     Iteration 700 of 1000: loss=14.1 l2=13.9\n",
      "[DEBUG 2018-10-25 04:01:43,468 cleverhans]     Iteration 800 of 1000: loss=13.8 l2=13.7\n",
      "[DEBUG 2018-10-25 04:01:45,439 cleverhans]     Iteration 900 of 1000: loss=13.5 l2=13.3\n",
      "[DEBUG 2018-10-25 04:01:47,351 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 04:01:47,352 cleverhans]    Mean successful distortion: 3.082\n",
      "[DEBUG 2018-10-25 04:01:47,353 cleverhans]   Binary search step 5 of 10\n",
      "[DEBUG 2018-10-25 04:01:47,372 cleverhans]     Iteration 0 of 1000: loss=344 l2=0\n",
      "[DEBUG 2018-10-25 04:01:49,938 cleverhans]     Iteration 100 of 1000: loss=24.2 l2=23.5\n",
      "[DEBUG 2018-10-25 04:01:52,265 cleverhans]     Iteration 200 of 1000: loss=18.4 l2=18.3\n",
      "[DEBUG 2018-10-25 04:01:54,432 cleverhans]     Iteration 300 of 1000: loss=15.1 l2=14.9\n",
      "[DEBUG 2018-10-25 04:01:56,460 cleverhans]     Iteration 400 of 1000: loss=13.3 l2=13.1\n",
      "[DEBUG 2018-10-25 04:01:58,416 cleverhans]     Iteration 500 of 1000: loss=12.3 l2=12.1\n",
      "[DEBUG 2018-10-25 04:02:00,389 cleverhans]     Iteration 600 of 1000: loss=11.7 l2=11.5\n",
      "[DEBUG 2018-10-25 04:02:02,398 cleverhans]     Iteration 700 of 1000: loss=11.3 l2=11.1\n",
      "[DEBUG 2018-10-25 04:02:04,357 cleverhans]     Iteration 800 of 1000: loss=10.9 l2=10.7\n",
      "[DEBUG 2018-10-25 04:02:06,314 cleverhans]     Iteration 900 of 1000: loss=10.7 l2=10.5\n",
      "[DEBUG 2018-10-25 04:02:08,279 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 04:02:08,280 cleverhans]    Mean successful distortion: 2.849\n",
      "[DEBUG 2018-10-25 04:02:08,281 cleverhans]   Binary search step 6 of 10\n",
      "[DEBUG 2018-10-25 04:02:08,301 cleverhans]     Iteration 0 of 1000: loss=172 l2=0\n",
      "[DEBUG 2018-10-25 04:02:10,956 cleverhans]     Iteration 100 of 1000: loss=22.1 l2=19.1\n",
      "[DEBUG 2018-10-25 04:02:13,268 cleverhans]     Iteration 200 of 1000: loss=16.1 l2=15.9\n",
      "[DEBUG 2018-10-25 04:02:15,444 cleverhans]     Iteration 300 of 1000: loss=13 l2=12.9\n",
      "[DEBUG 2018-10-25 04:02:17,452 cleverhans]     Iteration 400 of 1000: loss=11.5 l2=11.3\n",
      "[DEBUG 2018-10-25 04:02:19,503 cleverhans]     Iteration 500 of 1000: loss=10.6 l2=10.4\n",
      "[DEBUG 2018-10-25 04:02:21,522 cleverhans]     Iteration 600 of 1000: loss=10 l2=9.82\n",
      "[DEBUG 2018-10-25 04:02:23,563 cleverhans]     Iteration 700 of 1000: loss=9.61 l2=9.42\n",
      "[DEBUG 2018-10-25 04:02:25,570 cleverhans]     Iteration 800 of 1000: loss=9.34 l2=9.15\n",
      "[DEBUG 2018-10-25 04:02:27,553 cleverhans]     Iteration 900 of 1000: loss=9.11 l2=8.93\n",
      "[DEBUG 2018-10-25 04:02:29,575 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 04:02:29,576 cleverhans]    Mean successful distortion: 2.735\n",
      "[DEBUG 2018-10-25 04:02:29,578 cleverhans]   Binary search step 7 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DEBUG 2018-10-25 04:02:29,597 cleverhans]     Iteration 0 of 1000: loss=85.9 l2=0\n",
      "[DEBUG 2018-10-25 04:02:32,298 cleverhans]     Iteration 100 of 1000: loss=19.9 l2=16.6\n",
      "[DEBUG 2018-10-25 04:02:34,696 cleverhans]     Iteration 200 of 1000: loss=15 l2=14.7\n",
      "[DEBUG 2018-10-25 04:02:37,005 cleverhans]     Iteration 300 of 1000: loss=12.1 l2=11.9\n",
      "[DEBUG 2018-10-25 04:02:39,158 cleverhans]     Iteration 400 of 1000: loss=10.6 l2=10.4\n",
      "[DEBUG 2018-10-25 04:02:41,270 cleverhans]     Iteration 500 of 1000: loss=9.84 l2=9.63\n",
      "[DEBUG 2018-10-25 04:02:43,347 cleverhans]     Iteration 600 of 1000: loss=9.3 l2=9.06\n",
      "[DEBUG 2018-10-25 04:02:45,421 cleverhans]     Iteration 700 of 1000: loss=8.88 l2=8.66\n",
      "[DEBUG 2018-10-25 04:02:47,540 cleverhans]     Iteration 800 of 1000: loss=8.63 l2=8.44\n",
      "[DEBUG 2018-10-25 04:02:49,682 cleverhans]     Iteration 900 of 1000: loss=8.44 l2=8.26\n",
      "[DEBUG 2018-10-25 04:02:51,822 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 04:02:51,824 cleverhans]    Mean successful distortion: 2.687\n",
      "[DEBUG 2018-10-25 04:02:51,825 cleverhans]   Binary search step 8 of 10\n",
      "[DEBUG 2018-10-25 04:02:51,844 cleverhans]     Iteration 0 of 1000: loss=42.9 l2=0\n",
      "[DEBUG 2018-10-25 04:02:54,665 cleverhans]     Iteration 100 of 1000: loss=17.4 l2=13.8\n",
      "[DEBUG 2018-10-25 04:02:57,245 cleverhans]     Iteration 200 of 1000: loss=14.8 l2=13.2\n",
      "[DEBUG 2018-10-25 04:02:59,746 cleverhans]     Iteration 300 of 1000: loss=11.7 l2=11\n",
      "[DEBUG 2018-10-25 04:03:02,158 cleverhans]     Iteration 400 of 1000: loss=10.3 l2=9.83\n",
      "[DEBUG 2018-10-25 04:03:04,477 cleverhans]     Iteration 500 of 1000: loss=9.38 l2=9.05\n",
      "[DEBUG 2018-10-25 04:03:06,739 cleverhans]     Iteration 600 of 1000: loss=8.82 l2=8.56\n",
      "[DEBUG 2018-10-25 04:03:08,989 cleverhans]     Iteration 700 of 1000: loss=8.46 l2=8.22\n",
      "[DEBUG 2018-10-25 04:03:11,245 cleverhans]     Iteration 800 of 1000: loss=8.21 l2=7.98\n",
      "[DEBUG 2018-10-25 04:03:13,569 cleverhans]     Iteration 900 of 1000: loss=8.06 l2=7.83\n",
      "[DEBUG 2018-10-25 04:03:15,954 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 04:03:15,956 cleverhans]    Mean successful distortion: 2.665\n",
      "[DEBUG 2018-10-25 04:03:15,957 cleverhans]   Binary search step 9 of 10\n",
      "[DEBUG 2018-10-25 04:03:15,977 cleverhans]     Iteration 0 of 1000: loss=43 l2=0\n",
      "[DEBUG 2018-10-25 04:03:18,823 cleverhans]     Iteration 100 of 1000: loss=17.4 l2=13.8\n",
      "[DEBUG 2018-10-25 04:03:21,440 cleverhans]     Iteration 200 of 1000: loss=14.8 l2=13.3\n",
      "[DEBUG 2018-10-25 04:03:23,933 cleverhans]     Iteration 300 of 1000: loss=11.7 l2=11\n",
      "[DEBUG 2018-10-25 04:03:26,308 cleverhans]     Iteration 400 of 1000: loss=10.3 l2=9.83\n",
      "[DEBUG 2018-10-25 04:03:28,534 cleverhans]     Iteration 500 of 1000: loss=9.38 l2=9.06\n",
      "[DEBUG 2018-10-25 04:03:30,819 cleverhans]     Iteration 600 of 1000: loss=8.82 l2=8.56\n",
      "[DEBUG 2018-10-25 04:03:33,033 cleverhans]     Iteration 700 of 1000: loss=8.46 l2=8.21\n",
      "[DEBUG 2018-10-25 04:03:35,260 cleverhans]     Iteration 800 of 1000: loss=8.22 l2=7.98\n",
      "[DEBUG 2018-10-25 04:03:37,520 cleverhans]     Iteration 900 of 1000: loss=8.06 l2=7.84\n",
      "[DEBUG 2018-10-25 04:03:39,843 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 04:03:39,844 cleverhans]    Mean successful distortion: 2.665\n"
     ]
    }
   ],
   "source": [
    "keras.backend.set_learning_phase(0)\n",
    "set_log_level(logging.DEBUG)\n",
    "\n",
    "# CarliniWagner attack\n",
    "from lib.my_cw import CarliniWagnerL2\n",
    "\n",
    "attack_iterations = 1000\n",
    "cw_params = {'binary_search_steps': 10,\n",
    "             'max_iterations': attack_iterations,\n",
    "             'learning_rate': 0.1,\n",
    "             'batch_size': n_attack,\n",
    "             'initial_const': 1,\n",
    "             'y_target': y_target}\n",
    "cw = CarliniWagnerL2(hingenet, sess=sess)\n",
    "adv = cw.generate_np(X_atk, **cw_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1131817\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dist = np.sqrt(np.sum((X_atk - adv)**2, (1, 2, 3)))\n",
    "plt.hist(dist, bins=10, range=(1, 5))\n",
    "print(np.min(dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2018-10-25 04:04:07,861 cleverhans] Constructing new graph for attack CarliniWagnerL2\n",
      "[DEBUG 2018-10-25 04:04:08,525 cleverhans] Running CWL2 attack on instance 0 of 1000\n",
      "[DEBUG 2018-10-25 04:04:08,663 cleverhans]   Binary search step 0 of 10\n",
      "[DEBUG 2018-10-25 04:04:08,942 cleverhans]     Iteration 0 of 500: loss=4.11e+03 l2=0\n",
      "[DEBUG 2018-10-25 04:04:10,104 cleverhans]     Iteration 50 of 500: loss=67.1 l2=24.6\n",
      "[DEBUG 2018-10-25 04:04:11,029 cleverhans]     Iteration 100 of 500: loss=22.4 l2=22.4\n",
      "[DEBUG 2018-10-25 04:04:11,916 cleverhans]     Iteration 150 of 500: loss=19.6 l2=19.6\n",
      "[DEBUG 2018-10-25 04:04:12,810 cleverhans]     Iteration 200 of 500: loss=17.4 l2=17.4\n",
      "[DEBUG 2018-10-25 04:04:13,704 cleverhans]     Iteration 250 of 500: loss=15.7 l2=15.7\n",
      "[DEBUG 2018-10-25 04:04:14,664 cleverhans]     Iteration 300 of 500: loss=14.2 l2=14.2\n",
      "[DEBUG 2018-10-25 04:04:15,665 cleverhans]     Iteration 350 of 500: loss=13 l2=13\n",
      "[DEBUG 2018-10-25 04:04:16,804 cleverhans]     Iteration 400 of 500: loss=12.2 l2=12.2\n",
      "[DEBUG 2018-10-25 04:04:18,090 cleverhans]     Iteration 450 of 500: loss=11.5 l2=11.5\n",
      "[DEBUG 2018-10-25 04:04:19,511 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 04:04:19,513 cleverhans]    Mean successful distortion: 3\n",
      "[DEBUG 2018-10-25 04:04:19,515 cleverhans]   Binary search step 1 of 10\n",
      "[DEBUG 2018-10-25 04:04:19,533 cleverhans]     Iteration 0 of 500: loss=2.06e+03 l2=0\n",
      "[DEBUG 2018-10-25 04:04:20,669 cleverhans]     Iteration 50 of 500: loss=47.8 l2=23.2\n",
      "[DEBUG 2018-10-25 04:04:21,589 cleverhans]     Iteration 100 of 500: loss=19.5 l2=19.5\n",
      "[DEBUG 2018-10-25 04:04:22,515 cleverhans]     Iteration 150 of 500: loss=16.2 l2=16.2\n",
      "[DEBUG 2018-10-25 04:04:23,442 cleverhans]     Iteration 200 of 500: loss=13.9 l2=13.9\n",
      "[DEBUG 2018-10-25 04:04:24,450 cleverhans]     Iteration 250 of 500: loss=12.2 l2=12.2\n",
      "[DEBUG 2018-10-25 04:04:25,580 cleverhans]     Iteration 300 of 500: loss=11.1 l2=11.1\n",
      "[DEBUG 2018-10-25 04:04:26,936 cleverhans]     Iteration 350 of 500: loss=10.8 l2=10.8\n",
      "[DEBUG 2018-10-25 04:04:28,325 cleverhans]     Iteration 400 of 500: loss=10.6 l2=10.6\n",
      "[DEBUG 2018-10-25 04:04:29,651 cleverhans]     Iteration 450 of 500: loss=10.4 l2=10.4\n",
      "[DEBUG 2018-10-25 04:04:30,881 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 04:04:30,882 cleverhans]    Mean successful distortion: 2.689\n",
      "[DEBUG 2018-10-25 04:04:30,884 cleverhans]   Binary search step 2 of 10\n",
      "[DEBUG 2018-10-25 04:04:30,903 cleverhans]     Iteration 0 of 500: loss=1.03e+03 l2=0\n",
      "[DEBUG 2018-10-25 04:04:32,035 cleverhans]     Iteration 50 of 500: loss=34.5 l2=21\n",
      "[DEBUG 2018-10-25 04:04:32,950 cleverhans]     Iteration 100 of 500: loss=16 l2=16\n",
      "[DEBUG 2018-10-25 04:04:33,862 cleverhans]     Iteration 150 of 500: loss=12.6 l2=12.6\n",
      "[DEBUG 2018-10-25 04:04:34,997 cleverhans]     Iteration 200 of 500: loss=10.7 l2=10.6\n",
      "[DEBUG 2018-10-25 04:04:36,219 cleverhans]     Iteration 250 of 500: loss=9.98 l2=9.96\n",
      "[DEBUG 2018-10-25 04:04:37,349 cleverhans]     Iteration 300 of 500: loss=9.6 l2=9.59\n",
      "[DEBUG 2018-10-25 04:04:38,543 cleverhans]     Iteration 350 of 500: loss=9.28 l2=9.26\n",
      "[DEBUG 2018-10-25 04:04:39,726 cleverhans]     Iteration 400 of 500: loss=9.08 l2=9.05\n",
      "[DEBUG 2018-10-25 04:04:40,856 cleverhans]     Iteration 450 of 500: loss=8.69 l2=8.66\n",
      "[DEBUG 2018-10-25 04:04:41,969 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 04:04:41,970 cleverhans]    Mean successful distortion: 2.396\n",
      "[DEBUG 2018-10-25 04:04:41,972 cleverhans]   Binary search step 3 of 10\n",
      "[DEBUG 2018-10-25 04:04:41,991 cleverhans]     Iteration 0 of 500: loss=514 l2=0\n",
      "[DEBUG 2018-10-25 04:04:43,115 cleverhans]     Iteration 50 of 500: loss=24.9 l2=17.9\n",
      "[DEBUG 2018-10-25 04:04:44,085 cleverhans]     Iteration 100 of 500: loss=12.1 l2=12.1\n",
      "[DEBUG 2018-10-25 04:04:45,253 cleverhans]     Iteration 150 of 500: loss=9.67 l2=9.64\n",
      "[DEBUG 2018-10-25 04:04:46,403 cleverhans]     Iteration 200 of 500: loss=8.81 l2=8.75\n",
      "[DEBUG 2018-10-25 04:04:47,495 cleverhans]     Iteration 250 of 500: loss=8.25 l2=8.21\n",
      "[DEBUG 2018-10-25 04:04:48,532 cleverhans]     Iteration 300 of 500: loss=7.77 l2=7.74\n",
      "[DEBUG 2018-10-25 04:04:49,645 cleverhans]     Iteration 350 of 500: loss=7.4 l2=7.34\n",
      "[DEBUG 2018-10-25 04:04:50,764 cleverhans]     Iteration 400 of 500: loss=7.05 l2=7.01\n",
      "[DEBUG 2018-10-25 04:04:51,846 cleverhans]     Iteration 450 of 500: loss=6.82 l2=6.79\n",
      "[DEBUG 2018-10-25 04:04:52,898 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 04:04:52,899 cleverhans]    Mean successful distortion: 2.082\n",
      "[DEBUG 2018-10-25 04:04:52,900 cleverhans]   Binary search step 4 of 10\n",
      "[DEBUG 2018-10-25 04:04:52,919 cleverhans]     Iteration 0 of 500: loss=257 l2=0\n",
      "[DEBUG 2018-10-25 04:04:54,062 cleverhans]     Iteration 50 of 500: loss=17.5 l2=14\n",
      "[DEBUG 2018-10-25 04:04:55,214 cleverhans]     Iteration 100 of 500: loss=9.05 l2=9.02\n",
      "[DEBUG 2018-10-25 04:04:56,367 cleverhans]     Iteration 150 of 500: loss=7.66 l2=7.62\n",
      "[DEBUG 2018-10-25 04:04:57,443 cleverhans]     Iteration 200 of 500: loss=6.95 l2=6.87\n",
      "[DEBUG 2018-10-25 04:04:58,471 cleverhans]     Iteration 250 of 500: loss=6.37 l2=6.31\n",
      "[DEBUG 2018-10-25 04:04:59,478 cleverhans]     Iteration 300 of 500: loss=5.91 l2=5.85\n",
      "[DEBUG 2018-10-25 04:05:00,505 cleverhans]     Iteration 350 of 500: loss=5.6 l2=5.52\n",
      "[DEBUG 2018-10-25 04:05:01,542 cleverhans]     Iteration 400 of 500: loss=5.33 l2=5.28\n",
      "[DEBUG 2018-10-25 04:05:02,570 cleverhans]     Iteration 450 of 500: loss=5.25 l2=5.15\n",
      "[DEBUG 2018-10-25 04:05:03,544 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 04:05:03,545 cleverhans]    Mean successful distortion: 1.816\n",
      "[DEBUG 2018-10-25 04:05:03,547 cleverhans]   Binary search step 5 of 10\n",
      "[DEBUG 2018-10-25 04:05:03,567 cleverhans]     Iteration 0 of 500: loss=129 l2=0\n",
      "[DEBUG 2018-10-25 04:05:04,719 cleverhans]     Iteration 50 of 500: loss=11.6 l2=9.77\n",
      "[DEBUG 2018-10-25 04:05:05,958 cleverhans]     Iteration 100 of 500: loss=7.07 l2=6.93\n",
      "[DEBUG 2018-10-25 04:05:07,055 cleverhans]     Iteration 150 of 500: loss=6.07 l2=5.99\n",
      "[DEBUG 2018-10-25 04:05:08,046 cleverhans]     Iteration 200 of 500: loss=5.49 l2=5.43\n",
      "[DEBUG 2018-10-25 04:05:09,050 cleverhans]     Iteration 250 of 500: loss=5 l2=4.92\n",
      "[DEBUG 2018-10-25 04:05:10,040 cleverhans]     Iteration 300 of 500: loss=4.63 l2=4.55\n",
      "[DEBUG 2018-10-25 04:05:11,056 cleverhans]     Iteration 350 of 500: loss=4.3 l2=4.24\n",
      "[DEBUG 2018-10-25 04:05:12,092 cleverhans]     Iteration 400 of 500: loss=4.1 l2=4.03\n",
      "[DEBUG 2018-10-25 04:05:13,111 cleverhans]     Iteration 450 of 500: loss=3.95 l2=3.85\n",
      "[DEBUG 2018-10-25 04:05:14,110 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 04:05:14,111 cleverhans]    Mean successful distortion: 1.639\n",
      "[DEBUG 2018-10-25 04:05:14,112 cleverhans]   Binary search step 6 of 10\n",
      "[DEBUG 2018-10-25 04:05:14,130 cleverhans]     Iteration 0 of 500: loss=64.3 l2=0\n",
      "[DEBUG 2018-10-25 04:05:15,401 cleverhans]     Iteration 50 of 500: loss=8.14 l2=7.17\n",
      "[DEBUG 2018-10-25 04:05:16,597 cleverhans]     Iteration 100 of 500: loss=6 l2=5.58\n",
      "[DEBUG 2018-10-25 04:05:17,655 cleverhans]     Iteration 150 of 500: loss=5.29 l2=5.2\n",
      "[DEBUG 2018-10-25 04:05:18,691 cleverhans]     Iteration 200 of 500: loss=4.77 l2=4.7\n",
      "[DEBUG 2018-10-25 04:05:19,732 cleverhans]     Iteration 250 of 500: loss=4.29 l2=4.21\n",
      "[DEBUG 2018-10-25 04:05:20,778 cleverhans]     Iteration 300 of 500: loss=3.91 l2=3.82\n",
      "[DEBUG 2018-10-25 04:05:21,818 cleverhans]     Iteration 350 of 500: loss=3.62 l2=3.52\n",
      "[DEBUG 2018-10-25 04:05:22,828 cleverhans]     Iteration 400 of 500: loss=3.39 l2=3.31\n",
      "[DEBUG 2018-10-25 04:05:23,883 cleverhans]     Iteration 450 of 500: loss=3.23 l2=3.13\n",
      "[DEBUG 2018-10-25 04:05:24,923 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 04:05:24,925 cleverhans]    Mean successful distortion: 1.548\n",
      "[DEBUG 2018-10-25 04:05:24,926 cleverhans]   Binary search step 7 of 10\n",
      "[DEBUG 2018-10-25 04:05:24,945 cleverhans]     Iteration 0 of 500: loss=32.1 l2=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DEBUG 2018-10-25 04:05:26,243 cleverhans]     Iteration 50 of 500: loss=6.16 l2=5.52\n",
      "[DEBUG 2018-10-25 04:05:27,397 cleverhans]     Iteration 100 of 500: loss=5.57 l2=4.98\n",
      "[DEBUG 2018-10-25 04:05:28,490 cleverhans]     Iteration 150 of 500: loss=4.98 l2=4.82\n",
      "[DEBUG 2018-10-25 04:05:29,578 cleverhans]     Iteration 200 of 500: loss=4.45 l2=4.35\n",
      "[DEBUG 2018-10-25 04:05:30,651 cleverhans]     Iteration 250 of 500: loss=4 l2=3.92\n",
      "[DEBUG 2018-10-25 04:05:31,707 cleverhans]     Iteration 300 of 500: loss=3.66 l2=3.56\n",
      "[DEBUG 2018-10-25 04:05:32,762 cleverhans]     Iteration 350 of 500: loss=3.35 l2=3.27\n",
      "[DEBUG 2018-10-25 04:05:33,817 cleverhans]     Iteration 400 of 500: loss=3.16 l2=3.06\n",
      "[DEBUG 2018-10-25 04:05:34,882 cleverhans]     Iteration 450 of 500: loss=2.96 l2=2.88\n",
      "[DEBUG 2018-10-25 04:05:35,973 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 04:05:35,974 cleverhans]    Mean successful distortion: 1.51\n",
      "[DEBUG 2018-10-25 04:05:35,976 cleverhans]   Binary search step 8 of 10\n",
      "[DEBUG 2018-10-25 04:05:35,994 cleverhans]     Iteration 0 of 500: loss=16.1 l2=0\n",
      "[DEBUG 2018-10-25 04:05:37,355 cleverhans]     Iteration 50 of 500: loss=5.23 l2=4.5\n",
      "[DEBUG 2018-10-25 04:05:38,556 cleverhans]     Iteration 100 of 500: loss=5.07 l2=4.34\n",
      "[DEBUG 2018-10-25 04:05:39,707 cleverhans]     Iteration 150 of 500: loss=4.9 l2=4.3\n",
      "[DEBUG 2018-10-25 04:05:40,882 cleverhans]     Iteration 200 of 500: loss=4.35 l2=4.09\n",
      "[DEBUG 2018-10-25 04:05:42,027 cleverhans]     Iteration 250 of 500: loss=3.85 l2=3.69\n",
      "[DEBUG 2018-10-25 04:05:43,173 cleverhans]     Iteration 300 of 500: loss=3.48 l2=3.34\n",
      "[DEBUG 2018-10-25 04:05:44,293 cleverhans]     Iteration 350 of 500: loss=3.2 l2=3.08\n",
      "[DEBUG 2018-10-25 04:05:45,411 cleverhans]     Iteration 400 of 500: loss=2.98 l2=2.88\n",
      "[DEBUG 2018-10-25 04:05:46,544 cleverhans]     Iteration 450 of 500: loss=2.81 l2=2.72\n",
      "[DEBUG 2018-10-25 04:05:47,745 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 04:05:47,746 cleverhans]    Mean successful distortion: 1.491\n",
      "[DEBUG 2018-10-25 04:05:47,747 cleverhans]   Binary search step 9 of 10\n",
      "[DEBUG 2018-10-25 04:05:47,766 cleverhans]     Iteration 0 of 500: loss=16.1 l2=0\n",
      "[DEBUG 2018-10-25 04:05:49,124 cleverhans]     Iteration 50 of 500: loss=5.23 l2=4.5\n",
      "[DEBUG 2018-10-25 04:05:50,335 cleverhans]     Iteration 100 of 500: loss=5.07 l2=4.34\n",
      "[DEBUG 2018-10-25 04:05:51,505 cleverhans]     Iteration 150 of 500: loss=4.9 l2=4.3\n",
      "[DEBUG 2018-10-25 04:05:52,671 cleverhans]     Iteration 200 of 500: loss=4.35 l2=4.09\n",
      "[DEBUG 2018-10-25 04:05:53,838 cleverhans]     Iteration 250 of 500: loss=3.85 l2=3.69\n",
      "[DEBUG 2018-10-25 04:05:54,989 cleverhans]     Iteration 300 of 500: loss=3.48 l2=3.34\n",
      "[DEBUG 2018-10-25 04:05:56,098 cleverhans]     Iteration 350 of 500: loss=3.2 l2=3.08\n",
      "[DEBUG 2018-10-25 04:05:57,213 cleverhans]     Iteration 400 of 500: loss=2.98 l2=2.88\n",
      "[DEBUG 2018-10-25 04:05:58,338 cleverhans]     Iteration 450 of 500: loss=2.81 l2=2.72\n",
      "[DEBUG 2018-10-25 04:05:59,499 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 04:05:59,500 cleverhans]    Mean successful distortion: 1.491\n"
     ]
    }
   ],
   "source": [
    "# Untargeted\n",
    "\n",
    "keras.backend.set_learning_phase(0)\n",
    "set_log_level(logging.DEBUG)\n",
    "\n",
    "# CarliniWagner attack\n",
    "from lib.my_cw import CarliniWagnerL2\n",
    "\n",
    "attack_iterations = 500\n",
    "cw_params = {'binary_search_steps': 10,\n",
    "             'max_iterations': attack_iterations,\n",
    "             'learning_rate': 0.1,\n",
    "             'batch_size': n_attack,\n",
    "             'initial_const': 1}\n",
    "cw = CarliniWagnerL2(hingenet, sess=sess)\n",
    "adv = cw.generate_np(X_atk, **cw_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = hingenet.predict_model(sess, adv)\n",
    "\n",
    "for x, y in zip(adv[:10], y_pred[:10]):\n",
    "    print(np.argmax(y))\n",
    "    print(y)\n",
    "    plt.imshow(x[:, :, 0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hinge\n",
    "\n",
    "keras.backend.set_learning_phase(0)\n",
    "set_log_level(logging.DEBUG)\n",
    "\n",
    "from lib.my_pgd import ProjectedGradientDescent\n",
    "\n",
    "pgd_params = {'eps': 0.3,\n",
    "              'eps_iter': 0.05,\n",
    "              'clip_min': 0.,\n",
    "              'clip_max': 1.,\n",
    "              'ord': np.inf, \n",
    "              'nb_iter': 10,\n",
    "              'rand_init': True,\n",
    "              'batch_size': 100,\n",
    "              'y_target': y_target}\n",
    "pgd = ProjectedGradientDescent(hingenet, sess=sess)\n",
    "\n",
    "y_tar = np.argmax(y_target, axis=1)\n",
    "best_adv = np.zeros_like(X_atk)\n",
    "best_dist = np.zeros([n_attack]) + 1e5\n",
    "for i in range(10):\n",
    "    adv = pgd.generate_np(X_atk, **pgd_params)\n",
    "    print(hingenet.eval_model(sess, (adv, y_tar)))\n",
    "    dist = np.sqrt(np.sum((adv - X_atk)**2, (1, 2, 3)))\n",
    "    print(np.mean(dist))\n",
    "    pred = hingenet.predict_model(sess, adv)\n",
    "    y_pred = np.argmax(pred, axis=1)\n",
    "    for j in range(n_attack):\n",
    "        if y_pred[j] == y_tar[j] and dist[j] < best_dist[j]:\n",
    "            best_adv[j] = adv[j]\n",
    "            best_dist[j] = dist[j]\n",
    "print(np.mean(best_dist < 1e5))\n",
    "print(np.mean(best_dist[best_dist < 1e5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# V4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from hinge_net import HingeNet\n",
    "\n",
    "# v4: margin = 1e4\n",
    "hingenet = HingeNet(\"hingenet_v4\", [28, 28, 1], [10], learning_rate=1e-3, \n",
    "                    load_model=False, save_path=\"model/hingenet_v4.h5\")\n",
    "hingenet.train_model(sess, data, n_epoch=20, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Least likeley class\n",
    "n_attack = 1000\n",
    "X_atk = X_test[:, :, :, np.newaxis][:n_attack]\n",
    "y_atk = np.argmax(y_test[:n_attack], axis=1)\n",
    "\n",
    "y_pred = hingenet.predict_model(sess, X_atk)\n",
    "y_target = to_categorical(np.argmin(y_pred, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hingenet.eval_model(sess, (X_atk, y_atk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "keras.backend.set_learning_phase(0)\n",
    "set_log_level(logging.DEBUG)\n",
    "\n",
    "# CarliniWagner attack\n",
    "from lib.my_cw import CarliniWagnerL2\n",
    "\n",
    "attack_iterations = 200\n",
    "cw_params = {'binary_search_steps': 3,\n",
    "             'max_iterations': attack_iterations,\n",
    "             'learning_rate': 0.1,\n",
    "             'batch_size': n_attack,\n",
    "             'initial_const': 10,\n",
    "             'y_target': y_target}\n",
    "cw = CarliniWagnerL2(hingenet, sess=sess)\n",
    "adv = cw.generate_np(X_atk, **cw_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = hingenet.model.get_weights()\n",
    "\n",
    "print(np.sum(np.square(w[0])))\n",
    "print(np.sum(np.square(w[2])))\n",
    "print(np.sum(np.square(w[4])))\n",
    "print(np.sum(np.square(w[6])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Untargeted\n",
    "\n",
    "keras.backend.set_learning_phase(0)\n",
    "set_log_level(logging.DEBUG)\n",
    "\n",
    "# CarliniWagner attack\n",
    "from lib.my_cw import CarliniWagnerL2\n",
    "\n",
    "attack_iterations = 500\n",
    "cw_params = {'binary_search_steps': 10,\n",
    "             'max_iterations': attack_iterations,\n",
    "             'learning_rate': 0.1,\n",
    "             'batch_size': n_attack,\n",
    "             'initial_const': 1}\n",
    "cw = CarliniWagnerL2(hingenet, sess=sess)\n",
    "adv = cw.generate_np(X_atk, **cw_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(adv[0, :, :, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# V5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= EPOCH: 0 =============\n",
      "STEP: 0 \tLoss: 10031.5703\n",
      "STEP: 50 \tLoss: 10001.4043\n",
      "STEP: 100 \tLoss: 9969.8730\n",
      "STEP: 150 \tLoss: 7612.9800\n",
      "STEP: 200 \tLoss: 4472.9331\n",
      "STEP: 250 \tLoss: 4255.9438\n",
      "STEP: 300 \tLoss: 3731.2759\n",
      "STEP: 350 \tLoss: 2836.6436\n",
      "STEP: 400 \tLoss: 2508.3191\n",
      "STEP: 450 \tLoss: 2331.2664\n",
      "Train Acc|Loss:\t0.9145|2714.2508\n",
      "Val Acc|Loss:\t0.9151|2662.6128\n",
      "============= EPOCH: 1 =============\n",
      "STEP: 0 \tLoss: 2292.3208\n",
      "STEP: 50 \tLoss: 2896.3645\n",
      "STEP: 100 \tLoss: 2383.5132\n",
      "STEP: 150 \tLoss: 2436.2559\n",
      "STEP: 200 \tLoss: 1670.5460\n",
      "STEP: 250 \tLoss: 1703.5331\n",
      "STEP: 300 \tLoss: 1677.0099\n",
      "STEP: 350 \tLoss: 1989.6921\n",
      "STEP: 400 \tLoss: 2093.4607\n",
      "STEP: 450 \tLoss: 1463.8815\n",
      "Train Acc|Loss:\t0.9415|1990.9160\n",
      "Val Acc|Loss:\t0.9453|1920.4313\n",
      "============= EPOCH: 2 =============\n",
      "STEP: 0 \tLoss: 2012.2522\n",
      "STEP: 50 \tLoss: 2409.0957\n",
      "STEP: 100 \tLoss: 1434.1931\n",
      "STEP: 150 \tLoss: 2145.7148\n",
      "STEP: 200 \tLoss: 1398.4541\n",
      "STEP: 250 \tLoss: 1898.4948\n",
      "STEP: 300 \tLoss: 1257.0391\n",
      "STEP: 350 \tLoss: 1776.1799\n",
      "STEP: 400 \tLoss: 1588.3503\n",
      "STEP: 450 \tLoss: 1071.5225\n",
      "Train Acc|Loss:\t0.9554|1620.1676\n",
      "Val Acc|Loss:\t0.9577|1575.9251\n",
      "============= EPOCH: 3 =============\n",
      "STEP: 0 \tLoss: 1468.0327\n",
      "STEP: 50 \tLoss: 938.0179\n",
      "STEP: 100 \tLoss: 1548.2125\n",
      "STEP: 150 \tLoss: 1738.9104\n",
      "STEP: 200 \tLoss: 1856.0898\n",
      "STEP: 250 \tLoss: 1531.7000\n",
      "STEP: 300 \tLoss: 1430.5051\n",
      "STEP: 350 \tLoss: 1578.8958\n",
      "STEP: 400 \tLoss: 1315.5708\n",
      "STEP: 450 \tLoss: 1250.3059\n",
      "Train Acc|Loss:\t0.9628|1431.5592\n",
      "Val Acc|Loss:\t0.9619|1456.9353\n",
      "============= EPOCH: 4 =============\n",
      "STEP: 0 \tLoss: 1602.4292\n",
      "STEP: 50 \tLoss: 1414.2101\n",
      "STEP: 100 \tLoss: 926.5704\n",
      "STEP: 150 \tLoss: 1068.5610\n",
      "STEP: 200 \tLoss: 1146.4706\n",
      "STEP: 250 \tLoss: 1607.5425\n",
      "STEP: 300 \tLoss: 1866.7778\n",
      "STEP: 350 \tLoss: 1297.3901\n",
      "STEP: 400 \tLoss: 1029.2545\n",
      "STEP: 450 \tLoss: 1142.0421\n",
      "Train Acc|Loss:\t0.9646|1368.4966\n",
      "Val Acc|Loss:\t0.9646|1350.1690\n",
      "============= EPOCH: 5 =============\n",
      "STEP: 0 \tLoss: 1178.9119\n",
      "STEP: 50 \tLoss: 1538.6110\n",
      "STEP: 100 \tLoss: 977.4541\n",
      "STEP: 150 \tLoss: 1363.5176\n",
      "STEP: 200 \tLoss: 1040.0708\n",
      "STEP: 250 \tLoss: 1842.6465\n",
      "STEP: 300 \tLoss: 1877.7753\n",
      "STEP: 350 \tLoss: 1064.8096\n",
      "STEP: 400 \tLoss: 2052.6104\n",
      "STEP: 450 \tLoss: 1596.0750\n",
      "Train Acc|Loss:\t0.9677|1273.9669\n",
      "Val Acc|Loss:\t0.9663|1304.1214\n",
      "============= EPOCH: 6 =============\n",
      "STEP: 0 \tLoss: 930.8188\n",
      "STEP: 50 \tLoss: 1594.1095\n",
      "STEP: 100 \tLoss: 1360.5208\n",
      "STEP: 150 \tLoss: 1225.8124\n",
      "STEP: 200 \tLoss: 1711.8550\n",
      "STEP: 250 \tLoss: 1514.1753\n",
      "STEP: 300 \tLoss: 1218.2889\n",
      "STEP: 350 \tLoss: 1535.2179\n",
      "STEP: 400 \tLoss: 954.1191\n",
      "STEP: 450 \tLoss: 1093.5569\n",
      "Train Acc|Loss:\t0.9720|1153.5672\n",
      "Val Acc|Loss:\t0.9713|1177.7054\n",
      "============= EPOCH: 7 =============\n",
      "STEP: 0 \tLoss: 1152.4812\n",
      "STEP: 50 \tLoss: 1026.7358\n",
      "STEP: 100 \tLoss: 1249.3127\n",
      "STEP: 150 \tLoss: 1398.0845\n",
      "STEP: 200 \tLoss: 1196.4056\n",
      "STEP: 250 \tLoss: 1189.8313\n",
      "STEP: 300 \tLoss: 892.6995\n",
      "STEP: 350 \tLoss: 1626.3499\n",
      "STEP: 400 \tLoss: 844.7225\n",
      "STEP: 450 \tLoss: 972.5034\n",
      "Train Acc|Loss:\t0.9739|1093.8459\n",
      "Val Acc|Loss:\t0.9726|1155.6712\n",
      "============= EPOCH: 8 =============\n",
      "STEP: 0 \tLoss: 1129.7969\n",
      "STEP: 50 \tLoss: 695.5035\n",
      "STEP: 100 \tLoss: 1234.0210\n",
      "STEP: 150 \tLoss: 859.5700\n",
      "STEP: 200 \tLoss: 1349.3052\n",
      "STEP: 250 \tLoss: 1574.3384\n",
      "STEP: 300 \tLoss: 1263.5212\n",
      "STEP: 350 \tLoss: 1169.5939\n",
      "STEP: 400 \tLoss: 763.7765\n",
      "STEP: 450 \tLoss: 872.6921\n",
      "Train Acc|Loss:\t0.9756|1052.0838\n",
      "Val Acc|Loss:\t0.9744|1071.1824\n",
      "============= EPOCH: 9 =============\n",
      "STEP: 0 \tLoss: 1267.9979\n",
      "STEP: 50 \tLoss: 932.1801\n",
      "STEP: 100 \tLoss: 644.3110\n",
      "STEP: 150 \tLoss: 1116.6957\n",
      "STEP: 200 \tLoss: 751.6893\n",
      "STEP: 250 \tLoss: 1278.7056\n",
      "STEP: 300 \tLoss: 1602.6072\n",
      "STEP: 350 \tLoss: 1254.4244\n",
      "STEP: 400 \tLoss: 1015.8141\n",
      "STEP: 450 \tLoss: 1166.1251\n",
      "Train Acc|Loss:\t0.9770|999.0663\n",
      "Val Acc|Loss:\t0.9756|1053.3691\n",
      "============= EPOCH: 10 =============\n",
      "STEP: 0 \tLoss: 869.4417\n",
      "STEP: 50 \tLoss: 893.8515\n",
      "STEP: 100 \tLoss: 1073.6633\n",
      "STEP: 150 \tLoss: 1452.9492\n",
      "STEP: 200 \tLoss: 1237.9985\n",
      "STEP: 250 \tLoss: 863.1382\n",
      "STEP: 300 \tLoss: 801.7809\n",
      "STEP: 350 \tLoss: 1218.0620\n",
      "STEP: 400 \tLoss: 792.9867\n",
      "STEP: 450 \tLoss: 593.3111\n",
      "Train Acc|Loss:\t0.9782|979.6959\n",
      "Val Acc|Loss:\t0.9762|1024.2505\n",
      "============= EPOCH: 11 =============\n",
      "STEP: 0 \tLoss: 1192.0140\n",
      "STEP: 50 \tLoss: 1001.8904\n",
      "STEP: 100 \tLoss: 756.0902\n",
      "STEP: 150 \tLoss: 818.5026\n",
      "STEP: 200 \tLoss: 1281.1621\n",
      "STEP: 250 \tLoss: 1908.7816\n",
      "STEP: 300 \tLoss: 1261.9702\n",
      "STEP: 350 \tLoss: 819.0330\n",
      "STEP: 400 \tLoss: 638.2277\n",
      "STEP: 450 \tLoss: 543.3900\n",
      "Train Acc|Loss:\t0.9786|950.4358\n",
      "Val Acc|Loss:\t0.9750|1034.6362\n",
      "============= EPOCH: 12 =============\n",
      "STEP: 0 \tLoss: 1621.6067\n",
      "STEP: 50 \tLoss: 1140.6852\n",
      "STEP: 100 \tLoss: 774.5699\n",
      "STEP: 150 \tLoss: 1166.7937\n",
      "STEP: 200 \tLoss: 934.4058\n",
      "STEP: 250 \tLoss: 1300.2617\n",
      "STEP: 300 \tLoss: 902.6942\n",
      "STEP: 350 \tLoss: 1260.0199\n",
      "STEP: 400 \tLoss: 1039.6426\n",
      "STEP: 450 \tLoss: 803.0597\n",
      "Train Acc|Loss:\t0.9768|1046.7512\n",
      "Val Acc|Loss:\t0.9716|1132.3080\n",
      "============= EPOCH: 13 =============\n",
      "STEP: 0 \tLoss: 1151.3834\n",
      "STEP: 50 \tLoss: 477.1156\n",
      "STEP: 100 \tLoss: 897.5257\n",
      "STEP: 150 \tLoss: 489.3696\n",
      "STEP: 200 \tLoss: 1112.8281\n",
      "STEP: 250 \tLoss: 941.2768\n",
      "STEP: 300 \tLoss: 904.2130\n",
      "STEP: 350 \tLoss: 820.1254\n",
      "STEP: 400 \tLoss: 987.0374\n",
      "STEP: 450 \tLoss: 1070.1672\n",
      "Train Acc|Loss:\t0.9796|962.8877\n",
      "Val Acc|Loss:\t0.9724|1074.0115\n",
      "============= EPOCH: 14 =============\n",
      "STEP: 0 \tLoss: 835.4688\n",
      "STEP: 50 \tLoss: 711.1931\n",
      "STEP: 100 \tLoss: 719.3459\n",
      "STEP: 150 \tLoss: 615.1816\n",
      "STEP: 200 \tLoss: 1403.9380\n",
      "STEP: 250 \tLoss: 1015.2933\n",
      "STEP: 300 \tLoss: 1699.1389\n",
      "STEP: 350 \tLoss: 882.9304\n",
      "STEP: 400 \tLoss: 1141.1455\n",
      "STEP: 450 \tLoss: 561.1597\n",
      "Train Acc|Loss:\t0.9833|841.7451\n",
      "Val Acc|Loss:\t0.9797|930.7734\n",
      "============= EPOCH: 15 =============\n",
      "STEP: 0 \tLoss: 958.0762\n",
      "STEP: 50 \tLoss: 566.1245\n",
      "STEP: 100 \tLoss: 817.5946\n",
      "STEP: 150 \tLoss: 803.7012\n",
      "STEP: 200 \tLoss: 1231.1682\n",
      "STEP: 250 \tLoss: 855.3706\n",
      "STEP: 300 \tLoss: 735.2983\n",
      "STEP: 350 \tLoss: 1073.9935\n",
      "STEP: 400 \tLoss: 1117.8220\n",
      "STEP: 450 \tLoss: 692.6453\n",
      "Train Acc|Loss:\t0.9837|835.4205\n",
      "Val Acc|Loss:\t0.9797|935.9158\n",
      "============= EPOCH: 16 =============\n",
      "STEP: 0 \tLoss: 849.6631\n",
      "STEP: 50 \tLoss: 802.4783\n",
      "STEP: 100 \tLoss: 614.4728\n",
      "STEP: 150 \tLoss: 513.6801\n",
      "STEP: 200 \tLoss: 946.0138\n",
      "STEP: 250 \tLoss: 1358.2256\n",
      "STEP: 300 \tLoss: 944.9512\n",
      "STEP: 350 \tLoss: 626.9426\n",
      "STEP: 400 \tLoss: 869.8047\n",
      "STEP: 450 \tLoss: 1159.1090\n",
      "Train Acc|Loss:\t0.9828|871.8023\n",
      "Val Acc|Loss:\t0.9775|970.5770\n",
      "============= EPOCH: 17 =============\n",
      "STEP: 0 \tLoss: 809.2869\n",
      "STEP: 50 \tLoss: 933.9985\n",
      "STEP: 100 \tLoss: 984.7002\n",
      "STEP: 150 \tLoss: 760.0073\n",
      "STEP: 200 \tLoss: 1083.5607\n",
      "STEP: 250 \tLoss: 765.4185\n",
      "STEP: 300 \tLoss: 583.6959\n",
      "STEP: 350 \tLoss: 1083.6379\n",
      "STEP: 400 \tLoss: 1112.6919\n",
      "STEP: 450 \tLoss: 1441.8352\n",
      "Train Acc|Loss:\t0.9845|820.5553\n",
      "Val Acc|Loss:\t0.9789|956.1068\n",
      "============= EPOCH: 18 =============\n",
      "STEP: 0 \tLoss: 1051.7852\n",
      "STEP: 50 \tLoss: 738.2339\n",
      "STEP: 100 \tLoss: 599.6427\n",
      "STEP: 150 \tLoss: 619.4537\n",
      "STEP: 200 \tLoss: 1154.5419\n",
      "STEP: 250 \tLoss: 1058.6069\n",
      "STEP: 300 \tLoss: 706.1885\n",
      "STEP: 350 \tLoss: 1134.0938\n",
      "STEP: 400 \tLoss: 625.3752\n",
      "STEP: 450 \tLoss: 642.5242\n",
      "Train Acc|Loss:\t0.9836|845.5143\n",
      "Val Acc|Loss:\t0.9771|976.9801\n",
      "============= EPOCH: 19 =============\n",
      "STEP: 0 \tLoss: 677.1483\n",
      "STEP: 50 \tLoss: 1050.4502\n",
      "STEP: 100 \tLoss: 822.9222\n",
      "STEP: 150 \tLoss: 1138.8002\n",
      "STEP: 200 \tLoss: 904.2875\n",
      "STEP: 250 \tLoss: 962.9873\n",
      "STEP: 300 \tLoss: 581.6615\n",
      "STEP: 350 \tLoss: 556.4096\n",
      "STEP: 400 \tLoss: 705.5275\n",
      "STEP: 450 \tLoss: 1123.4493\n",
      "Train Acc|Loss:\t0.9826|880.7195\n",
      "Val Acc|Loss:\t0.9765|993.6028\n",
      "============= EPOCH: 20 =============\n",
      "STEP: 0 \tLoss: 565.1027\n",
      "STEP: 50 \tLoss: 697.4634\n",
      "STEP: 100 \tLoss: 700.0323\n",
      "STEP: 150 \tLoss: 756.8176\n",
      "STEP: 200 \tLoss: 518.4348\n",
      "STEP: 250 \tLoss: 670.1228\n",
      "STEP: 300 \tLoss: 582.9426\n",
      "STEP: 350 \tLoss: 1171.1427\n",
      "STEP: 400 \tLoss: 650.1816\n",
      "STEP: 450 \tLoss: 545.2822\n",
      "Train Acc|Loss:\t0.9861|791.3363\n",
      "Val Acc|Loss:\t0.9822|893.9950\n",
      "============= EPOCH: 21 =============\n",
      "STEP: 0 \tLoss: 922.0625\n",
      "STEP: 50 \tLoss: 844.0756\n",
      "STEP: 100 \tLoss: 614.8286\n",
      "STEP: 150 \tLoss: 1547.8900\n",
      "STEP: 200 \tLoss: 896.4469\n",
      "STEP: 250 \tLoss: 663.9360\n",
      "STEP: 300 \tLoss: 709.5616\n",
      "STEP: 350 \tLoss: 877.0127\n",
      "STEP: 400 \tLoss: 546.2665\n",
      "STEP: 450 \tLoss: 503.4876\n",
      "Train Acc|Loss:\t0.9834|855.3762\n",
      "Val Acc|Loss:\t0.9777|976.0596\n",
      "============= EPOCH: 22 =============\n",
      "STEP: 0 \tLoss: 953.0677\n",
      "STEP: 50 \tLoss: 594.6967\n",
      "STEP: 100 \tLoss: 948.2751\n",
      "STEP: 150 \tLoss: 700.7410\n",
      "STEP: 200 \tLoss: 869.7214\n",
      "STEP: 250 \tLoss: 727.4192\n",
      "STEP: 300 \tLoss: 516.7838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP: 350 \tLoss: 657.1849\n",
      "STEP: 400 \tLoss: 725.9612\n",
      "STEP: 450 \tLoss: 1031.5901\n",
      "Train Acc|Loss:\t0.9871|778.5040\n",
      "Val Acc|Loss:\t0.9799|924.9560\n",
      "============= EPOCH: 23 =============\n",
      "STEP: 0 \tLoss: 804.8555\n",
      "STEP: 50 \tLoss: 803.9576\n",
      "STEP: 100 \tLoss: 1076.4960\n",
      "STEP: 150 \tLoss: 1090.1317\n",
      "STEP: 200 \tLoss: 750.8539\n",
      "STEP: 250 \tLoss: 676.6818\n",
      "STEP: 300 \tLoss: 542.9648\n",
      "STEP: 350 \tLoss: 807.2509\n",
      "STEP: 400 \tLoss: 803.5764\n",
      "STEP: 450 \tLoss: 783.8573\n",
      "Train Acc|Loss:\t0.9862|771.5240\n",
      "Val Acc|Loss:\t0.9807|898.1437\n",
      "============= EPOCH: 24 =============\n",
      "STEP: 0 \tLoss: 793.9789\n",
      "STEP: 50 \tLoss: 923.0577\n",
      "STEP: 100 \tLoss: 771.3162\n",
      "STEP: 150 \tLoss: 816.7993\n",
      "STEP: 200 \tLoss: 877.8324\n",
      "STEP: 250 \tLoss: 643.0286\n",
      "STEP: 300 \tLoss: 812.8512\n",
      "STEP: 350 \tLoss: 735.9905\n",
      "STEP: 400 \tLoss: 1014.7610\n",
      "STEP: 450 \tLoss: 587.5442\n",
      "Train Acc|Loss:\t0.9864|779.3913\n",
      "Val Acc|Loss:\t0.9804|918.5250\n",
      "============= EPOCH: 25 =============\n",
      "STEP: 0 \tLoss: 783.9938\n",
      "STEP: 50 \tLoss: 1178.1173\n",
      "STEP: 100 \tLoss: 689.4994\n",
      "STEP: 150 \tLoss: 582.1693\n",
      "STEP: 200 \tLoss: 845.7188\n",
      "STEP: 250 \tLoss: 893.5212\n",
      "STEP: 300 \tLoss: 862.4897\n",
      "STEP: 350 \tLoss: 408.2740\n",
      "STEP: 400 \tLoss: 843.9608\n",
      "STEP: 450 \tLoss: 480.1456\n",
      "Train Acc|Loss:\t0.9873|741.3025\n",
      "Val Acc|Loss:\t0.9802|911.2271\n",
      "============= EPOCH: 26 =============\n",
      "STEP: 0 \tLoss: 875.4803\n",
      "STEP: 50 \tLoss: 757.3154\n",
      "STEP: 100 \tLoss: 773.6182\n",
      "STEP: 150 \tLoss: 790.3071\n",
      "STEP: 200 \tLoss: 1001.5110\n",
      "STEP: 250 \tLoss: 510.5658\n",
      "STEP: 300 \tLoss: 553.7588\n",
      "STEP: 350 \tLoss: 814.8304\n",
      "STEP: 400 \tLoss: 735.1483\n",
      "STEP: 450 \tLoss: 739.2706\n",
      "Train Acc|Loss:\t0.9883|730.4248\n",
      "Val Acc|Loss:\t0.9825|880.0726\n",
      "============= EPOCH: 27 =============\n",
      "STEP: 0 \tLoss: 527.1962\n",
      "STEP: 50 \tLoss: 811.3865\n",
      "STEP: 100 \tLoss: 507.4232\n",
      "STEP: 150 \tLoss: 608.1186\n",
      "STEP: 200 \tLoss: 1903.0659\n",
      "STEP: 250 \tLoss: 730.4312\n",
      "STEP: 300 \tLoss: 1271.6223\n",
      "STEP: 350 \tLoss: 464.0742\n",
      "STEP: 400 \tLoss: 526.5604\n",
      "STEP: 450 \tLoss: 868.9904\n",
      "Train Acc|Loss:\t0.9885|743.8046\n",
      "Val Acc|Loss:\t0.9803|913.7514\n",
      "============= EPOCH: 28 =============\n",
      "STEP: 0 \tLoss: 559.5812\n",
      "STEP: 50 \tLoss: 552.0032\n",
      "STEP: 100 \tLoss: 834.4117\n",
      "STEP: 150 \tLoss: 772.0641\n",
      "STEP: 200 \tLoss: 724.8528\n",
      "STEP: 250 \tLoss: 713.8256\n",
      "STEP: 300 \tLoss: 779.0177\n",
      "STEP: 350 \tLoss: 471.3181\n",
      "STEP: 400 \tLoss: 818.1849\n",
      "STEP: 450 \tLoss: 557.6179\n",
      "Train Acc|Loss:\t0.9875|748.8969\n",
      "Val Acc|Loss:\t0.9809|898.4003\n",
      "============= EPOCH: 29 =============\n",
      "STEP: 0 \tLoss: 463.4323\n",
      "STEP: 50 \tLoss: 874.4966\n",
      "STEP: 100 \tLoss: 503.1361\n",
      "STEP: 150 \tLoss: 792.6992\n",
      "STEP: 200 \tLoss: 481.4635\n",
      "STEP: 250 \tLoss: 683.1482\n",
      "STEP: 300 \tLoss: 607.9598\n",
      "STEP: 350 \tLoss: 812.7473\n",
      "STEP: 400 \tLoss: 511.6695\n",
      "STEP: 450 \tLoss: 793.8091\n",
      "Train Acc|Loss:\t0.9896|678.1166\n",
      "Val Acc|Loss:\t0.9848|799.0538\n",
      "============= EPOCH: 30 =============\n",
      "STEP: 0 \tLoss: 816.7653\n",
      "STEP: 50 \tLoss: 1162.9520\n",
      "STEP: 100 \tLoss: 514.9514\n",
      "STEP: 150 \tLoss: 827.7926\n",
      "STEP: 200 \tLoss: 627.1982\n",
      "STEP: 250 \tLoss: 403.5839\n",
      "STEP: 300 \tLoss: 952.0347\n",
      "STEP: 350 \tLoss: 554.8234\n",
      "STEP: 400 \tLoss: 389.0136\n",
      "STEP: 450 \tLoss: 854.1827\n",
      "Train Acc|Loss:\t0.9903|668.6691\n",
      "Val Acc|Loss:\t0.9818|835.4188\n",
      "============= EPOCH: 31 =============\n",
      "STEP: 0 \tLoss: 513.2938\n",
      "STEP: 50 \tLoss: 687.9003\n",
      "STEP: 100 \tLoss: 435.3506\n",
      "STEP: 150 \tLoss: 857.3386\n",
      "STEP: 200 \tLoss: 835.4379\n",
      "STEP: 250 \tLoss: 752.4942\n",
      "STEP: 300 \tLoss: 942.8068\n",
      "STEP: 350 \tLoss: 769.6653\n",
      "STEP: 400 \tLoss: 783.8344\n",
      "STEP: 450 \tLoss: 933.1096\n",
      "Train Acc|Loss:\t0.9842|828.6033\n",
      "Val Acc|Loss:\t0.9787|942.6984\n",
      "============= EPOCH: 32 =============\n",
      "STEP: 0 \tLoss: 588.5913\n",
      "STEP: 50 \tLoss: 945.4833\n",
      "STEP: 100 \tLoss: 653.2721\n",
      "STEP: 150 \tLoss: 644.5792\n",
      "STEP: 200 \tLoss: 531.3064\n",
      "STEP: 250 \tLoss: 678.8434\n",
      "STEP: 300 \tLoss: 702.4032\n",
      "STEP: 350 \tLoss: 1234.8816\n",
      "STEP: 400 \tLoss: 803.7697\n",
      "STEP: 450 \tLoss: 640.1865\n",
      "Train Acc|Loss:\t0.9902|661.2063\n",
      "Val Acc|Loss:\t0.9837|807.4875\n",
      "============= EPOCH: 33 =============\n",
      "STEP: 0 \tLoss: 596.9050\n",
      "STEP: 50 \tLoss: 919.4912\n",
      "STEP: 100 \tLoss: 757.6555\n",
      "STEP: 150 \tLoss: 548.7065\n",
      "STEP: 200 \tLoss: 674.4987\n",
      "STEP: 250 \tLoss: 987.1345\n",
      "STEP: 300 \tLoss: 657.3286\n",
      "STEP: 350 \tLoss: 852.9954\n",
      "STEP: 400 \tLoss: 987.7915\n",
      "STEP: 450 \tLoss: 562.7446\n",
      "Train Acc|Loss:\t0.9902|671.5128\n",
      "Val Acc|Loss:\t0.9843|819.6444\n",
      "============= EPOCH: 34 =============\n",
      "STEP: 0 \tLoss: 570.9691\n",
      "STEP: 50 \tLoss: 376.6276\n",
      "STEP: 100 \tLoss: 884.8785\n",
      "STEP: 150 \tLoss: 850.5946\n",
      "STEP: 200 \tLoss: 649.8604\n",
      "STEP: 250 \tLoss: 483.0500\n",
      "STEP: 300 \tLoss: 573.7596\n",
      "STEP: 350 \tLoss: 517.6532\n",
      "STEP: 400 \tLoss: 848.8902\n",
      "STEP: 450 \tLoss: 528.8411\n",
      "Train Acc|Loss:\t0.9906|657.1124\n",
      "Val Acc|Loss:\t0.9849|796.2801\n",
      "============= EPOCH: 35 =============\n",
      "STEP: 0 \tLoss: 535.2664\n",
      "STEP: 50 \tLoss: 850.0206\n",
      "STEP: 100 \tLoss: 644.0343\n",
      "STEP: 150 \tLoss: 520.7936\n",
      "STEP: 200 \tLoss: 597.4203\n",
      "STEP: 250 \tLoss: 832.1879\n",
      "STEP: 300 \tLoss: 450.1675\n",
      "STEP: 350 \tLoss: 757.7146\n",
      "STEP: 400 \tLoss: 1133.6396\n",
      "STEP: 450 \tLoss: 609.0580\n",
      "Train Acc|Loss:\t0.9901|661.8927\n",
      "Val Acc|Loss:\t0.9851|792.9282\n",
      "============= EPOCH: 36 =============\n",
      "STEP: 0 \tLoss: 522.1989\n",
      "STEP: 50 \tLoss: 920.4602\n",
      "STEP: 100 \tLoss: 658.0854\n",
      "STEP: 150 \tLoss: 397.2728\n",
      "STEP: 200 \tLoss: 678.9230\n",
      "STEP: 250 \tLoss: 894.3137\n",
      "STEP: 300 \tLoss: 545.0021\n",
      "STEP: 350 \tLoss: 695.3182\n",
      "STEP: 400 \tLoss: 766.2956\n",
      "STEP: 450 \tLoss: 670.4149\n",
      "Train Acc|Loss:\t0.9899|676.0676\n",
      "Val Acc|Loss:\t0.9831|841.1168\n",
      "============= EPOCH: 37 =============\n",
      "STEP: 0 \tLoss: 736.9770\n",
      "STEP: 50 \tLoss: 762.6354\n",
      "STEP: 100 \tLoss: 572.1184\n",
      "STEP: 150 \tLoss: 982.2151\n",
      "STEP: 200 \tLoss: 491.5555\n",
      "STEP: 250 \tLoss: 518.6926\n",
      "STEP: 300 \tLoss: 647.4303\n",
      "STEP: 350 \tLoss: 629.7908\n",
      "STEP: 400 \tLoss: 451.7224\n",
      "STEP: 450 \tLoss: 525.0439\n",
      "Train Acc|Loss:\t0.9911|624.4410\n",
      "Val Acc|Loss:\t0.9854|792.8443\n",
      "============= EPOCH: 38 =============\n",
      "STEP: 0 \tLoss: 576.0803\n",
      "STEP: 50 \tLoss: 554.1763\n",
      "STEP: 100 \tLoss: 658.3175\n",
      "STEP: 150 \tLoss: 760.0641\n",
      "STEP: 200 \tLoss: 606.3384\n",
      "STEP: 250 \tLoss: 930.0431\n",
      "STEP: 300 \tLoss: 749.3561\n",
      "STEP: 350 \tLoss: 658.9471\n",
      "STEP: 400 \tLoss: 493.9474\n",
      "STEP: 450 \tLoss: 614.2963\n",
      "Train Acc|Loss:\t0.9917|622.2952\n",
      "Val Acc|Loss:\t0.9835|788.5178\n",
      "============= EPOCH: 39 =============\n",
      "STEP: 0 \tLoss: 585.6967\n",
      "STEP: 50 \tLoss: 397.5591\n",
      "STEP: 100 \tLoss: 357.5123\n",
      "STEP: 150 \tLoss: 1105.7546\n",
      "STEP: 200 \tLoss: 548.6313\n",
      "STEP: 250 \tLoss: 615.3169\n",
      "STEP: 300 \tLoss: 618.4966\n",
      "STEP: 350 \tLoss: 627.6400\n",
      "STEP: 400 \tLoss: 776.6892\n",
      "STEP: 450 \tLoss: 623.3649\n",
      "Train Acc|Loss:\t0.9920|605.6006\n",
      "Val Acc|Loss:\t0.9846|768.3679\n",
      "============= EPOCH: 40 =============\n",
      "STEP: 0 \tLoss: 458.2169\n",
      "STEP: 50 \tLoss: 624.7113\n",
      "STEP: 100 \tLoss: 784.9839\n",
      "STEP: 150 \tLoss: 672.0016\n",
      "STEP: 200 \tLoss: 687.8566\n",
      "STEP: 250 \tLoss: 479.7088\n",
      "STEP: 300 \tLoss: 490.6940\n",
      "STEP: 350 \tLoss: 614.9213\n",
      "STEP: 400 \tLoss: 1032.6138\n",
      "STEP: 450 \tLoss: 594.9714\n",
      "Train Acc|Loss:\t0.9909|628.1617\n",
      "Val Acc|Loss:\t0.9842|777.6648\n",
      "============= EPOCH: 41 =============\n",
      "STEP: 0 \tLoss: 497.7945\n",
      "STEP: 50 \tLoss: 914.2563\n",
      "STEP: 100 \tLoss: 733.6273\n",
      "STEP: 150 \tLoss: 655.0646\n",
      "STEP: 200 \tLoss: 920.1376\n",
      "STEP: 250 \tLoss: 1215.2825\n",
      "STEP: 300 \tLoss: 503.6642\n",
      "STEP: 350 \tLoss: 543.7969\n",
      "STEP: 400 \tLoss: 453.6324\n",
      "STEP: 450 \tLoss: 768.5317\n",
      "Train Acc|Loss:\t0.9924|600.6452\n",
      "Val Acc|Loss:\t0.9845|753.3095\n",
      "============= EPOCH: 42 =============\n",
      "STEP: 0 \tLoss: 665.5912\n",
      "STEP: 50 \tLoss: 668.9371\n",
      "STEP: 100 \tLoss: 623.1681\n",
      "STEP: 150 \tLoss: 647.2279\n",
      "STEP: 200 \tLoss: 766.8500\n",
      "STEP: 250 \tLoss: 471.4355\n",
      "STEP: 300 \tLoss: 584.9897\n",
      "STEP: 350 \tLoss: 585.8752\n",
      "STEP: 400 \tLoss: 400.2627\n",
      "STEP: 450 \tLoss: 771.0227\n",
      "Train Acc|Loss:\t0.9907|636.7627\n",
      "Val Acc|Loss:\t0.9843|763.5988\n",
      "============= EPOCH: 43 =============\n",
      "STEP: 0 \tLoss: 773.8668\n",
      "STEP: 50 \tLoss: 541.6576\n",
      "STEP: 100 \tLoss: 537.1285\n",
      "STEP: 150 \tLoss: 470.9386\n",
      "STEP: 200 \tLoss: 700.3236\n",
      "STEP: 250 \tLoss: 476.0253\n",
      "STEP: 300 \tLoss: 802.3568\n",
      "STEP: 350 \tLoss: 594.9479\n",
      "STEP: 400 \tLoss: 488.7060\n",
      "STEP: 450 \tLoss: 671.5134\n",
      "Train Acc|Loss:\t0.9906|628.2330\n",
      "Val Acc|Loss:\t0.9835|780.6830\n",
      "============= EPOCH: 44 =============\n",
      "STEP: 0 \tLoss: 848.8958\n",
      "STEP: 50 \tLoss: 446.9510\n",
      "STEP: 100 \tLoss: 724.1604\n",
      "STEP: 150 \tLoss: 849.7175\n",
      "STEP: 200 \tLoss: 421.9113\n",
      "STEP: 250 \tLoss: 651.1443\n",
      "STEP: 300 \tLoss: 491.1707\n",
      "STEP: 350 \tLoss: 530.8636\n",
      "STEP: 400 \tLoss: 520.5097\n",
      "STEP: 450 \tLoss: 886.2729\n",
      "Train Acc|Loss:\t0.9919|610.8609\n",
      "Val Acc|Loss:\t0.9843|775.2212\n",
      "============= EPOCH: 45 =============\n",
      "STEP: 0 \tLoss: 806.5240\n",
      "STEP: 50 \tLoss: 468.8016\n",
      "STEP: 100 \tLoss: 568.8373\n",
      "STEP: 150 \tLoss: 762.1849\n",
      "STEP: 200 \tLoss: 572.1420\n",
      "STEP: 250 \tLoss: 935.1577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP: 300 \tLoss: 717.8231\n",
      "STEP: 350 \tLoss: 723.5996\n",
      "STEP: 400 \tLoss: 414.5781\n",
      "STEP: 450 \tLoss: 787.6606\n",
      "Train Acc|Loss:\t0.9933|561.4125\n",
      "Val Acc|Loss:\t0.9860|731.6640\n",
      "============= EPOCH: 46 =============\n",
      "STEP: 0 \tLoss: 757.5205\n",
      "STEP: 50 \tLoss: 614.4608\n",
      "STEP: 100 \tLoss: 883.1051\n",
      "STEP: 150 \tLoss: 464.9293\n",
      "STEP: 200 \tLoss: 899.2601\n",
      "STEP: 250 \tLoss: 483.2147\n",
      "STEP: 300 \tLoss: 443.1342\n",
      "STEP: 350 \tLoss: 565.9550\n",
      "STEP: 400 \tLoss: 979.5234\n",
      "STEP: 450 \tLoss: 489.1190\n",
      "Train Acc|Loss:\t0.9932|549.2773\n",
      "Val Acc|Loss:\t0.9852|718.9295\n",
      "============= EPOCH: 47 =============\n",
      "STEP: 0 \tLoss: 596.2688\n",
      "STEP: 50 \tLoss: 440.9027\n",
      "STEP: 100 \tLoss: 489.1025\n",
      "STEP: 150 \tLoss: 479.1650\n",
      "STEP: 200 \tLoss: 734.0414\n",
      "STEP: 250 \tLoss: 672.0727\n",
      "STEP: 300 \tLoss: 440.2168\n",
      "STEP: 350 \tLoss: 750.8029\n",
      "STEP: 400 \tLoss: 457.6168\n",
      "STEP: 450 \tLoss: 537.2766\n",
      "Train Acc|Loss:\t0.9928|578.9889\n",
      "Val Acc|Loss:\t0.9854|730.4372\n",
      "============= EPOCH: 48 =============\n",
      "STEP: 0 \tLoss: 559.2588\n",
      "STEP: 50 \tLoss: 593.9353\n",
      "STEP: 100 \tLoss: 688.8085\n",
      "STEP: 150 \tLoss: 669.0834\n",
      "STEP: 200 \tLoss: 506.3550\n",
      "STEP: 250 \tLoss: 361.1086\n",
      "STEP: 300 \tLoss: 342.5017\n",
      "STEP: 350 \tLoss: 924.6350\n",
      "STEP: 400 \tLoss: 546.6816\n",
      "STEP: 450 \tLoss: 620.1182\n",
      "Train Acc|Loss:\t0.9939|542.1690\n",
      "Val Acc|Loss:\t0.9854|731.3966\n",
      "============= EPOCH: 49 =============\n",
      "STEP: 0 \tLoss: 350.0222\n",
      "STEP: 50 \tLoss: 556.9355\n",
      "STEP: 100 \tLoss: 436.5456\n",
      "STEP: 150 \tLoss: 600.0417\n",
      "STEP: 200 \tLoss: 611.3729\n",
      "STEP: 250 \tLoss: 561.1250\n",
      "STEP: 300 \tLoss: 414.5233\n",
      "STEP: 350 \tLoss: 687.9067\n",
      "STEP: 400 \tLoss: 550.9406\n",
      "STEP: 450 \tLoss: 611.1023\n",
      "Train Acc|Loss:\t0.9940|537.2169\n",
      "Val Acc|Loss:\t0.9855|715.4267\n"
     ]
    }
   ],
   "source": [
    "from hinge_net import HingeNet\n",
    "\n",
    "# v5: margin = 1e2 + reg\n",
    "hingenet = HingeNet(\"hingenet_v5-1\", [28, 28, 1], [10], learning_rate=1e-3, \n",
    "                    loss=\"hinge\", margin=1e4, reg=1e-1, load_model=False, \n",
    "                    save_path=\"model/hingenet_v5-1.h5\")\n",
    "hingenet.train_model(sess, data, n_epoch=50, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9855, 715.4266571289063)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hingenet.eval_model(sess, (X_test[:, :, :, np.newaxis], np.argmax(y_test, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "796.31085\n",
      "702.4912\n",
      "1592.8695\n",
      "246.33667\n"
     ]
    }
   ],
   "source": [
    "w = hingenet.model.get_weights()\n",
    "for i, w in enumerate(w):\n",
    "    if i % 2 == 0:\n",
    "        print(np.sum(np.square(w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Least likeley class\n",
    "n_attack = 1000\n",
    "X_atk = X_test[:, :, :, np.newaxis][:n_attack]\n",
    "y_atk = np.argmax(y_test[:n_attack], axis=1)\n",
    "\n",
    "y_pred = hingenet.predict_model(sess, X_atk)\n",
    "y_target = to_categorical(np.argmin(y_pred, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.984, 824.484859375)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hingenet.eval_model(sess, (X_atk, y_atk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2018-10-25 05:33:40,661 cleverhans] Constructing new graph for attack CarliniWagnerL2\n",
      "[DEBUG 2018-10-25 05:33:41,298 cleverhans] Running CWL2 attack on instance 0 of 1000\n",
      "[DEBUG 2018-10-25 05:33:41,497 cleverhans]   Binary search step 0 of 10\n",
      "[DEBUG 2018-10-25 05:33:41,868 cleverhans]     Iteration 0 of 500: loss=7.92e+04 l2=0\n",
      "[DEBUG 2018-10-25 05:33:43,360 cleverhans]     Iteration 50 of 500: loss=2.49e+03 l2=43.7\n",
      "[DEBUG 2018-10-25 05:33:44,288 cleverhans]     Iteration 100 of 500: loss=48.5 l2=48.5\n",
      "[DEBUG 2018-10-25 05:33:45,191 cleverhans]     Iteration 150 of 500: loss=48 l2=48\n",
      "[DEBUG 2018-10-25 05:33:46,099 cleverhans]     Iteration 200 of 500: loss=47.6 l2=47.6\n",
      "[DEBUG 2018-10-25 05:33:47,034 cleverhans]     Iteration 250 of 500: loss=47.1 l2=47.1\n",
      "[DEBUG 2018-10-25 05:33:47,938 cleverhans]     Iteration 300 of 500: loss=46.6 l2=46.6\n",
      "[DEBUG 2018-10-25 05:33:48,867 cleverhans]     Iteration 350 of 500: loss=46.1 l2=46.1\n",
      "[DEBUG 2018-10-25 05:33:49,795 cleverhans]     Iteration 400 of 500: loss=45.6 l2=45.6\n",
      "[DEBUG 2018-10-25 05:33:50,721 cleverhans]     Iteration 450 of 500: loss=45 l2=45\n",
      "[DEBUG 2018-10-25 05:33:51,630 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 05:33:51,632 cleverhans]    Mean successful distortion: 5.709\n",
      "[DEBUG 2018-10-25 05:33:51,633 cleverhans]   Binary search step 1 of 10\n",
      "[DEBUG 2018-10-25 05:33:51,654 cleverhans]     Iteration 0 of 500: loss=3.96e+04 l2=0\n",
      "[DEBUG 2018-10-25 05:33:53,085 cleverhans]     Iteration 50 of 500: loss=1.3e+03 l2=43.7\n",
      "[DEBUG 2018-10-25 05:33:54,034 cleverhans]     Iteration 100 of 500: loss=47.9 l2=47.9\n",
      "[DEBUG 2018-10-25 05:33:54,923 cleverhans]     Iteration 150 of 500: loss=47.2 l2=47.2\n",
      "[DEBUG 2018-10-25 05:33:55,852 cleverhans]     Iteration 200 of 500: loss=46.4 l2=46.4\n",
      "[DEBUG 2018-10-25 05:33:56,748 cleverhans]     Iteration 250 of 500: loss=45.6 l2=45.6\n",
      "[DEBUG 2018-10-25 05:33:57,669 cleverhans]     Iteration 300 of 500: loss=44.8 l2=44.8\n",
      "[DEBUG 2018-10-25 05:33:58,633 cleverhans]     Iteration 350 of 500: loss=44 l2=44\n",
      "[DEBUG 2018-10-25 05:33:59,612 cleverhans]     Iteration 400 of 500: loss=43.1 l2=43.1\n",
      "[DEBUG 2018-10-25 05:34:00,599 cleverhans]     Iteration 450 of 500: loss=42.3 l2=42.3\n",
      "[DEBUG 2018-10-25 05:34:01,588 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 05:34:01,589 cleverhans]    Mean successful distortion: 5.695\n",
      "[DEBUG 2018-10-25 05:34:01,591 cleverhans]   Binary search step 2 of 10\n",
      "[DEBUG 2018-10-25 05:34:01,609 cleverhans]     Iteration 0 of 500: loss=1.98e+04 l2=0\n",
      "[DEBUG 2018-10-25 05:34:03,057 cleverhans]     Iteration 50 of 500: loss=690 l2=43.5\n",
      "[DEBUG 2018-10-25 05:34:03,998 cleverhans]     Iteration 100 of 500: loss=47 l2=47\n",
      "[DEBUG 2018-10-25 05:34:04,896 cleverhans]     Iteration 150 of 500: loss=45.8 l2=45.8\n",
      "[DEBUG 2018-10-25 05:34:05,824 cleverhans]     Iteration 200 of 500: loss=44.5 l2=44.5\n",
      "[DEBUG 2018-10-25 05:34:06,756 cleverhans]     Iteration 250 of 500: loss=43.2 l2=43.2\n",
      "[DEBUG 2018-10-25 05:34:07,706 cleverhans]     Iteration 300 of 500: loss=42 l2=42\n",
      "[DEBUG 2018-10-25 05:34:08,698 cleverhans]     Iteration 350 of 500: loss=40.7 l2=40.7\n",
      "[DEBUG 2018-10-25 05:34:09,791 cleverhans]     Iteration 400 of 500: loss=39.6 l2=39.6\n",
      "[DEBUG 2018-10-25 05:34:10,896 cleverhans]     Iteration 450 of 500: loss=38.5 l2=38.5\n",
      "[DEBUG 2018-10-25 05:34:12,060 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 05:34:12,061 cleverhans]    Mean successful distortion: 5.652\n",
      "[DEBUG 2018-10-25 05:34:12,062 cleverhans]   Binary search step 3 of 10\n",
      "[DEBUG 2018-10-25 05:34:12,080 cleverhans]     Iteration 0 of 500: loss=9.9e+03 l2=0\n",
      "[DEBUG 2018-10-25 05:34:13,543 cleverhans]     Iteration 50 of 500: loss=379 l2=43.2\n",
      "[DEBUG 2018-10-25 05:34:14,492 cleverhans]     Iteration 100 of 500: loss=45.6 l2=45.6\n",
      "[DEBUG 2018-10-25 05:34:15,415 cleverhans]     Iteration 150 of 500: loss=43.5 l2=43.5\n",
      "[DEBUG 2018-10-25 05:34:16,326 cleverhans]     Iteration 200 of 500: loss=41.6 l2=41.6\n",
      "[DEBUG 2018-10-25 05:34:17,310 cleverhans]     Iteration 250 of 500: loss=39.7 l2=39.7\n",
      "[DEBUG 2018-10-25 05:34:18,338 cleverhans]     Iteration 300 of 500: loss=38 l2=38\n",
      "[DEBUG 2018-10-25 05:34:19,462 cleverhans]     Iteration 350 of 500: loss=36.3 l2=36.3\n",
      "[DEBUG 2018-10-25 05:34:20,740 cleverhans]     Iteration 400 of 500: loss=34.9 l2=34.9\n",
      "[DEBUG 2018-10-25 05:34:22,097 cleverhans]     Iteration 450 of 500: loss=33.7 l2=33.7\n",
      "[DEBUG 2018-10-25 05:34:23,508 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 05:34:23,509 cleverhans]    Mean successful distortion: 5.459\n",
      "[DEBUG 2018-10-25 05:34:23,510 cleverhans]   Binary search step 4 of 10\n",
      "[DEBUG 2018-10-25 05:34:23,528 cleverhans]     Iteration 0 of 500: loss=4.95e+03 l2=0\n",
      "[DEBUG 2018-10-25 05:34:24,948 cleverhans]     Iteration 50 of 500: loss=217 l2=42.7\n",
      "[DEBUG 2018-10-25 05:34:25,914 cleverhans]     Iteration 100 of 500: loss=43.4 l2=43.4\n",
      "[DEBUG 2018-10-25 05:34:26,877 cleverhans]     Iteration 150 of 500: loss=40.2 l2=40.2\n",
      "[DEBUG 2018-10-25 05:34:27,896 cleverhans]     Iteration 200 of 500: loss=37.4 l2=37.4\n",
      "[DEBUG 2018-10-25 05:34:28,966 cleverhans]     Iteration 250 of 500: loss=35 l2=35\n",
      "[DEBUG 2018-10-25 05:34:30,125 cleverhans]     Iteration 300 of 500: loss=33 l2=32.9\n",
      "[DEBUG 2018-10-25 05:34:31,481 cleverhans]     Iteration 350 of 500: loss=31.5 l2=31.5\n",
      "[DEBUG 2018-10-25 05:34:32,921 cleverhans]     Iteration 400 of 500: loss=30.4 l2=30.4\n",
      "[DEBUG 2018-10-25 05:34:34,327 cleverhans]     Iteration 450 of 500: loss=29.7 l2=29.6\n",
      "[DEBUG 2018-10-25 05:34:35,657 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 05:34:35,658 cleverhans]    Mean successful distortion: 5.082\n",
      "[DEBUG 2018-10-25 05:34:35,659 cleverhans]   Binary search step 5 of 10\n",
      "[DEBUG 2018-10-25 05:34:35,678 cleverhans]     Iteration 0 of 500: loss=2.48e+03 l2=0\n",
      "[DEBUG 2018-10-25 05:34:37,079 cleverhans]     Iteration 50 of 500: loss=131 l2=41.7\n",
      "[DEBUG 2018-10-25 05:34:38,067 cleverhans]     Iteration 100 of 500: loss=40 l2=40\n",
      "[DEBUG 2018-10-25 05:34:39,108 cleverhans]     Iteration 150 of 500: loss=35.6 l2=35.5\n",
      "[DEBUG 2018-10-25 05:34:40,259 cleverhans]     Iteration 200 of 500: loss=32.1 l2=32.1\n",
      "[DEBUG 2018-10-25 05:34:41,458 cleverhans]     Iteration 250 of 500: loss=29.9 l2=29.9\n",
      "[DEBUG 2018-10-25 05:34:42,642 cleverhans]     Iteration 300 of 500: loss=28.5 l2=28.4\n",
      "[DEBUG 2018-10-25 05:34:43,878 cleverhans]     Iteration 350 of 500: loss=27.4 l2=27.4\n",
      "[DEBUG 2018-10-25 05:34:45,108 cleverhans]     Iteration 400 of 500: loss=26.5 l2=26.4\n",
      "[DEBUG 2018-10-25 05:34:46,318 cleverhans]     Iteration 450 of 500: loss=25.7 l2=25.7\n",
      "[DEBUG 2018-10-25 05:34:47,459 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 05:34:47,460 cleverhans]    Mean successful distortion: 4.652\n",
      "[DEBUG 2018-10-25 05:34:47,462 cleverhans]   Binary search step 6 of 10\n",
      "[DEBUG 2018-10-25 05:34:47,480 cleverhans]     Iteration 0 of 500: loss=1.24e+03 l2=0\n",
      "[DEBUG 2018-10-25 05:34:48,872 cleverhans]     Iteration 50 of 500: loss=85 l2=39.8\n",
      "[DEBUG 2018-10-25 05:34:49,913 cleverhans]     Iteration 100 of 500: loss=35.1 l2=35\n",
      "[DEBUG 2018-10-25 05:34:51,099 cleverhans]     Iteration 150 of 500: loss=29.9 l2=29.9\n",
      "[DEBUG 2018-10-25 05:34:52,320 cleverhans]     Iteration 200 of 500: loss=27.2 l2=27.2\n",
      "[DEBUG 2018-10-25 05:34:53,461 cleverhans]     Iteration 250 of 500: loss=25.4 l2=25.3\n",
      "[DEBUG 2018-10-25 05:34:54,541 cleverhans]     Iteration 300 of 500: loss=24 l2=23.9\n",
      "[DEBUG 2018-10-25 05:34:55,675 cleverhans]     Iteration 350 of 500: loss=22.8 l2=22.7\n",
      "[DEBUG 2018-10-25 05:34:56,807 cleverhans]     Iteration 400 of 500: loss=21.7 l2=21.6\n",
      "[DEBUG 2018-10-25 05:34:57,896 cleverhans]     Iteration 450 of 500: loss=21 l2=20.9\n",
      "[DEBUG 2018-10-25 05:34:58,962 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 05:34:58,963 cleverhans]    Mean successful distortion: 4.144\n",
      "[DEBUG 2018-10-25 05:34:58,964 cleverhans]   Binary search step 7 of 10\n",
      "[DEBUG 2018-10-25 05:34:58,982 cleverhans]     Iteration 0 of 500: loss=619 l2=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DEBUG 2018-10-25 05:35:00,370 cleverhans]     Iteration 50 of 500: loss=58.9 l2=36.2\n",
      "[DEBUG 2018-10-25 05:35:01,551 cleverhans]     Iteration 100 of 500: loss=29.3 l2=28.8\n",
      "[DEBUG 2018-10-25 05:35:02,805 cleverhans]     Iteration 150 of 500: loss=25 l2=25\n",
      "[DEBUG 2018-10-25 05:35:03,959 cleverhans]     Iteration 200 of 500: loss=22.7 l2=22.6\n",
      "[DEBUG 2018-10-25 05:35:05,051 cleverhans]     Iteration 250 of 500: loss=20.8 l2=20.7\n",
      "[DEBUG 2018-10-25 05:35:06,128 cleverhans]     Iteration 300 of 500: loss=19.5 l2=19.3\n",
      "[DEBUG 2018-10-25 05:35:07,194 cleverhans]     Iteration 350 of 500: loss=18.4 l2=18.2\n",
      "[DEBUG 2018-10-25 05:35:08,268 cleverhans]     Iteration 400 of 500: loss=17.5 l2=17.3\n",
      "[DEBUG 2018-10-25 05:35:09,319 cleverhans]     Iteration 450 of 500: loss=16.8 l2=16.6\n",
      "[DEBUG 2018-10-25 05:35:10,365 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 05:35:10,367 cleverhans]    Mean successful distortion: 3.709\n",
      "[DEBUG 2018-10-25 05:35:10,368 cleverhans]   Binary search step 8 of 10\n",
      "[DEBUG 2018-10-25 05:35:10,386 cleverhans]     Iteration 0 of 500: loss=309 l2=0\n",
      "[DEBUG 2018-10-25 05:35:11,777 cleverhans]     Iteration 50 of 500: loss=41.6 l2=30.2\n",
      "[DEBUG 2018-10-25 05:35:13,087 cleverhans]     Iteration 100 of 500: loss=25 l2=23.5\n",
      "[DEBUG 2018-10-25 05:35:14,285 cleverhans]     Iteration 150 of 500: loss=21.2 l2=21.1\n",
      "[DEBUG 2018-10-25 05:35:15,402 cleverhans]     Iteration 200 of 500: loss=19.2 l2=19\n",
      "[DEBUG 2018-10-25 05:35:16,480 cleverhans]     Iteration 250 of 500: loss=17.6 l2=17.4\n",
      "[DEBUG 2018-10-25 05:35:17,539 cleverhans]     Iteration 300 of 500: loss=16.4 l2=16.2\n",
      "[DEBUG 2018-10-25 05:35:18,607 cleverhans]     Iteration 350 of 500: loss=15.4 l2=15.2\n",
      "[DEBUG 2018-10-25 05:35:19,686 cleverhans]     Iteration 400 of 500: loss=14.7 l2=14.5\n",
      "[DEBUG 2018-10-25 05:35:20,773 cleverhans]     Iteration 450 of 500: loss=14.2 l2=14\n",
      "[DEBUG 2018-10-25 05:35:21,828 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 05:35:21,829 cleverhans]    Mean successful distortion: 3.458\n",
      "[DEBUG 2018-10-25 05:35:21,831 cleverhans]   Binary search step 9 of 10\n",
      "[DEBUG 2018-10-25 05:35:21,849 cleverhans]     Iteration 0 of 500: loss=309 l2=0\n",
      "[DEBUG 2018-10-25 05:35:23,198 cleverhans]     Iteration 50 of 500: loss=41.6 l2=30.2\n",
      "[DEBUG 2018-10-25 05:35:24,512 cleverhans]     Iteration 100 of 500: loss=25 l2=23.5\n",
      "[DEBUG 2018-10-25 05:35:25,661 cleverhans]     Iteration 150 of 500: loss=21.2 l2=21.1\n",
      "[DEBUG 2018-10-25 05:35:26,790 cleverhans]     Iteration 200 of 500: loss=19.2 l2=19\n",
      "[DEBUG 2018-10-25 05:35:27,901 cleverhans]     Iteration 250 of 500: loss=17.6 l2=17.4\n",
      "[DEBUG 2018-10-25 05:35:28,945 cleverhans]     Iteration 300 of 500: loss=16.4 l2=16.2\n",
      "[DEBUG 2018-10-25 05:35:30,008 cleverhans]     Iteration 350 of 500: loss=15.4 l2=15.2\n",
      "[DEBUG 2018-10-25 05:35:31,044 cleverhans]     Iteration 400 of 500: loss=14.7 l2=14.5\n",
      "[DEBUG 2018-10-25 05:35:32,010 cleverhans]     Iteration 450 of 500: loss=14.2 l2=14\n",
      "[DEBUG 2018-10-25 05:35:33,015 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 05:35:33,015 cleverhans]    Mean successful distortion: 3.458\n"
     ]
    }
   ],
   "source": [
    "keras.backend.set_learning_phase(0)\n",
    "set_log_level(logging.DEBUG)\n",
    "\n",
    "# CarliniWagner attack\n",
    "from lib.my_cw import CarliniWagnerL2\n",
    "\n",
    "attack_iterations = 500\n",
    "cw_params = {'binary_search_steps': 10,\n",
    "             'max_iterations': attack_iterations,\n",
    "             'learning_rate': 0.1,\n",
    "             'batch_size': n_attack,\n",
    "             'initial_const': 1,\n",
    "             'y_target': y_target}\n",
    "cw = CarliniWagnerL2(hingenet, sess=sess)\n",
    "adv = cw.generate_np(X_atk, **cw_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2018-10-25 05:35:33,062 cleverhans] Constructing new graph for attack CarliniWagnerL2\n",
      "[DEBUG 2018-10-25 05:35:33,760 cleverhans] Running CWL2 attack on instance 0 of 1000\n",
      "[DEBUG 2018-10-25 05:35:33,964 cleverhans]   Binary search step 0 of 10\n",
      "[DEBUG 2018-10-25 05:35:34,330 cleverhans]     Iteration 0 of 2000: loss=7.92e+04 l2=0\n",
      "[DEBUG 2018-10-25 05:35:38,534 cleverhans]     Iteration 200 of 2000: loss=47.6 l2=47.6\n",
      "[DEBUG 2018-10-25 05:35:42,151 cleverhans]     Iteration 400 of 2000: loss=45.6 l2=45.6\n",
      "[DEBUG 2018-10-25 05:35:45,950 cleverhans]     Iteration 600 of 2000: loss=43.4 l2=43.4\n",
      "[DEBUG 2018-10-25 05:35:49,916 cleverhans]     Iteration 800 of 2000: loss=41.3 l2=41.3\n",
      "[DEBUG 2018-10-25 05:35:54,212 cleverhans]     Iteration 1000 of 2000: loss=39.4 l2=39.4\n",
      "[DEBUG 2018-10-25 05:35:58,782 cleverhans]     Iteration 1200 of 2000: loss=37.7 l2=37.7\n",
      "[DEBUG 2018-10-25 05:36:03,704 cleverhans]     Iteration 1400 of 2000: loss=36.5 l2=36.5\n",
      "[DEBUG 2018-10-25 05:36:08,892 cleverhans]     Iteration 1600 of 2000: loss=36 l2=36\n",
      "[DEBUG 2018-10-25 05:36:14,300 cleverhans]     Iteration 1800 of 2000: loss=36.2 l2=36.1\n",
      "[DEBUG 2018-10-25 05:36:14,300 cleverhans]     Failed to make progress; stop early\n",
      "[DEBUG 2018-10-25 05:36:14,313 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 05:36:14,314 cleverhans]    Mean successful distortion: 5.457\n",
      "[DEBUG 2018-10-25 05:36:14,315 cleverhans]   Binary search step 1 of 10\n",
      "[DEBUG 2018-10-25 05:36:14,334 cleverhans]     Iteration 0 of 2000: loss=3.96e+04 l2=0\n",
      "[DEBUG 2018-10-25 05:36:18,475 cleverhans]     Iteration 200 of 2000: loss=46.4 l2=46.4\n",
      "[DEBUG 2018-10-25 05:36:22,188 cleverhans]     Iteration 400 of 2000: loss=43.1 l2=43.1\n",
      "[DEBUG 2018-10-25 05:36:26,046 cleverhans]     Iteration 600 of 2000: loss=40 l2=40\n",
      "[DEBUG 2018-10-25 05:36:30,231 cleverhans]     Iteration 800 of 2000: loss=37.3 l2=37.3\n",
      "[DEBUG 2018-10-25 05:36:34,546 cleverhans]     Iteration 1000 of 2000: loss=35.3 l2=35.3\n",
      "[DEBUG 2018-10-25 05:36:39,203 cleverhans]     Iteration 1200 of 2000: loss=34.5 l2=34.4\n",
      "[DEBUG 2018-10-25 05:36:44,616 cleverhans]     Iteration 1400 of 2000: loss=34.9 l2=34.9\n",
      "[DEBUG 2018-10-25 05:36:44,617 cleverhans]     Failed to make progress; stop early\n",
      "[DEBUG 2018-10-25 05:36:44,631 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 05:36:44,632 cleverhans]    Mean successful distortion: 5.332\n",
      "[DEBUG 2018-10-25 05:36:44,633 cleverhans]   Binary search step 2 of 10\n",
      "[DEBUG 2018-10-25 05:36:44,651 cleverhans]     Iteration 0 of 2000: loss=1.98e+04 l2=0\n",
      "[DEBUG 2018-10-25 05:36:48,754 cleverhans]     Iteration 200 of 2000: loss=44.5 l2=44.5\n",
      "[DEBUG 2018-10-25 05:36:52,636 cleverhans]     Iteration 400 of 2000: loss=39.6 l2=39.6\n",
      "[DEBUG 2018-10-25 05:36:56,778 cleverhans]     Iteration 600 of 2000: loss=35.5 l2=35.5\n",
      "[DEBUG 2018-10-25 05:37:01,343 cleverhans]     Iteration 800 of 2000: loss=33.2 l2=33.2\n",
      "[DEBUG 2018-10-25 05:37:06,305 cleverhans]     Iteration 1000 of 2000: loss=32.9 l2=32.9\n",
      "[DEBUG 2018-10-25 05:37:11,291 cleverhans]     Iteration 1200 of 2000: loss=32.3 l2=32.3\n",
      "[DEBUG 2018-10-25 05:37:15,981 cleverhans]     Iteration 1400 of 2000: loss=31.5 l2=31.4\n",
      "[DEBUG 2018-10-25 05:37:20,447 cleverhans]     Iteration 1600 of 2000: loss=31.5 l2=31.5\n",
      "[DEBUG 2018-10-25 05:37:20,448 cleverhans]     Failed to make progress; stop early\n",
      "[DEBUG 2018-10-25 05:37:20,460 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 05:37:20,461 cleverhans]    Mean successful distortion: 4.95\n",
      "[DEBUG 2018-10-25 05:37:20,462 cleverhans]   Binary search step 3 of 10\n",
      "[DEBUG 2018-10-25 05:37:20,481 cleverhans]     Iteration 0 of 2000: loss=9.9e+03 l2=0\n",
      "[DEBUG 2018-10-25 05:37:24,665 cleverhans]     Iteration 200 of 2000: loss=41.6 l2=41.6\n",
      "[DEBUG 2018-10-25 05:37:28,856 cleverhans]     Iteration 400 of 2000: loss=34.9 l2=34.9\n",
      "[DEBUG 2018-10-25 05:37:33,518 cleverhans]     Iteration 600 of 2000: loss=31.6 l2=31.6\n",
      "[DEBUG 2018-10-25 05:37:38,125 cleverhans]     Iteration 800 of 2000: loss=30.3 l2=30.2\n",
      "[DEBUG 2018-10-25 05:37:42,523 cleverhans]     Iteration 1000 of 2000: loss=29.4 l2=29.3\n",
      "[DEBUG 2018-10-25 05:37:47,118 cleverhans]     Iteration 1200 of 2000: loss=28.7 l2=28.7\n",
      "[DEBUG 2018-10-25 05:37:51,495 cleverhans]     Iteration 1400 of 2000: loss=28 l2=28\n",
      "[DEBUG 2018-10-25 05:37:55,769 cleverhans]     Iteration 1600 of 2000: loss=27.5 l2=27.5\n",
      "[DEBUG 2018-10-25 05:37:59,897 cleverhans]     Iteration 1800 of 2000: loss=27.2 l2=27.1\n",
      "[DEBUG 2018-10-25 05:38:03,871 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 05:38:03,872 cleverhans]    Mean successful distortion: 4.471\n",
      "[DEBUG 2018-10-25 05:38:03,873 cleverhans]   Binary search step 4 of 10\n",
      "[DEBUG 2018-10-25 05:38:03,891 cleverhans]     Iteration 0 of 2000: loss=4.95e+03 l2=0\n",
      "[DEBUG 2018-10-25 05:38:08,161 cleverhans]     Iteration 200 of 2000: loss=37.4 l2=37.4\n",
      "[DEBUG 2018-10-25 05:38:12,775 cleverhans]     Iteration 400 of 2000: loss=30.4 l2=30.4\n",
      "[DEBUG 2018-10-25 05:38:17,188 cleverhans]     Iteration 600 of 2000: loss=28.1 l2=28\n",
      "[DEBUG 2018-10-25 05:38:21,391 cleverhans]     Iteration 800 of 2000: loss=26.7 l2=26.6\n",
      "[DEBUG 2018-10-25 05:38:25,468 cleverhans]     Iteration 1000 of 2000: loss=25.4 l2=25.4\n",
      "[DEBUG 2018-10-25 05:38:29,529 cleverhans]     Iteration 1200 of 2000: loss=24.7 l2=24.7\n",
      "[DEBUG 2018-10-25 05:38:33,558 cleverhans]     Iteration 1400 of 2000: loss=24.1 l2=24.1\n",
      "[DEBUG 2018-10-25 05:38:37,474 cleverhans]     Iteration 1600 of 2000: loss=23.5 l2=23.5\n",
      "[DEBUG 2018-10-25 05:38:41,389 cleverhans]     Iteration 1800 of 2000: loss=23.2 l2=23.2\n",
      "[DEBUG 2018-10-25 05:38:45,285 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 05:38:45,286 cleverhans]    Mean successful distortion: 4.103\n",
      "[DEBUG 2018-10-25 05:38:45,288 cleverhans]   Binary search step 5 of 10\n",
      "[DEBUG 2018-10-25 05:38:45,309 cleverhans]     Iteration 0 of 2000: loss=2.48e+03 l2=0\n",
      "[DEBUG 2018-10-25 05:38:49,860 cleverhans]     Iteration 200 of 2000: loss=32.1 l2=32.1\n",
      "[DEBUG 2018-10-25 05:38:54,475 cleverhans]     Iteration 400 of 2000: loss=26.5 l2=26.4\n",
      "[DEBUG 2018-10-25 05:38:58,618 cleverhans]     Iteration 600 of 2000: loss=24 l2=23.9\n",
      "[DEBUG 2018-10-25 05:39:02,625 cleverhans]     Iteration 800 of 2000: loss=22.3 l2=22.2\n",
      "[DEBUG 2018-10-25 05:39:06,597 cleverhans]     Iteration 1000 of 2000: loss=21.3 l2=21.2\n",
      "[DEBUG 2018-10-25 05:39:10,544 cleverhans]     Iteration 1200 of 2000: loss=20.6 l2=20.6\n",
      "[DEBUG 2018-10-25 05:39:14,458 cleverhans]     Iteration 1400 of 2000: loss=20.4 l2=20.3\n",
      "[DEBUG 2018-10-25 05:39:18,271 cleverhans]     Iteration 1600 of 2000: loss=19.9 l2=19.9\n",
      "[DEBUG 2018-10-25 05:39:22,057 cleverhans]     Iteration 1800 of 2000: loss=19.9 l2=19.8\n",
      "[DEBUG 2018-10-25 05:39:25,778 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 05:39:25,779 cleverhans]    Mean successful distortion: 3.749\n",
      "[DEBUG 2018-10-25 05:39:25,781 cleverhans]   Binary search step 6 of 10\n",
      "[DEBUG 2018-10-25 05:39:25,802 cleverhans]     Iteration 0 of 2000: loss=1.24e+03 l2=0\n",
      "[DEBUG 2018-10-25 05:39:30,554 cleverhans]     Iteration 200 of 2000: loss=27.2 l2=27.2\n",
      "[DEBUG 2018-10-25 05:39:34,854 cleverhans]     Iteration 400 of 2000: loss=21.7 l2=21.6\n",
      "[DEBUG 2018-10-25 05:39:38,848 cleverhans]     Iteration 600 of 2000: loss=19.4 l2=19.3\n",
      "[DEBUG 2018-10-25 05:39:42,729 cleverhans]     Iteration 800 of 2000: loss=18.1 l2=18\n",
      "[DEBUG 2018-10-25 05:39:46,608 cleverhans]     Iteration 1000 of 2000: loss=17.6 l2=17.4\n",
      "[DEBUG 2018-10-25 05:39:50,437 cleverhans]     Iteration 1200 of 2000: loss=17.1 l2=16.9\n",
      "[DEBUG 2018-10-25 05:39:54,202 cleverhans]     Iteration 1400 of 2000: loss=16.8 l2=16.6\n",
      "[DEBUG 2018-10-25 05:39:57,989 cleverhans]     Iteration 1600 of 2000: loss=16.7 l2=16.6\n",
      "[DEBUG 2018-10-25 05:40:01,728 cleverhans]     Iteration 1800 of 2000: loss=16.6 l2=16.5\n",
      "[DEBUG 2018-10-25 05:40:05,470 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 05:40:05,471 cleverhans]    Mean successful distortion: 3.404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DEBUG 2018-10-25 05:40:05,474 cleverhans]   Binary search step 7 of 10\n",
      "[DEBUG 2018-10-25 05:40:05,493 cleverhans]     Iteration 0 of 2000: loss=619 l2=0\n",
      "[DEBUG 2018-10-25 05:40:10,372 cleverhans]     Iteration 200 of 2000: loss=22.7 l2=22.6\n",
      "[DEBUG 2018-10-25 05:40:14,568 cleverhans]     Iteration 400 of 2000: loss=17.5 l2=17.3\n",
      "[DEBUG 2018-10-25 05:40:18,495 cleverhans]     Iteration 600 of 2000: loss=15.5 l2=15.3\n",
      "[DEBUG 2018-10-25 05:40:22,382 cleverhans]     Iteration 800 of 2000: loss=14.7 l2=14.6\n",
      "[DEBUG 2018-10-25 05:40:26,271 cleverhans]     Iteration 1000 of 2000: loss=14.2 l2=14\n",
      "[DEBUG 2018-10-25 05:40:29,956 cleverhans]     Iteration 1200 of 2000: loss=13.9 l2=13.7\n",
      "[DEBUG 2018-10-25 05:40:33,771 cleverhans]     Iteration 1400 of 2000: loss=13.7 l2=13.5\n",
      "[DEBUG 2018-10-25 05:40:37,574 cleverhans]     Iteration 1600 of 2000: loss=13.5 l2=13.4\n",
      "[DEBUG 2018-10-25 05:40:41,351 cleverhans]     Iteration 1800 of 2000: loss=13.4 l2=13.2\n",
      "[DEBUG 2018-10-25 05:40:45,187 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 05:40:45,188 cleverhans]    Mean successful distortion: 3.147\n",
      "[DEBUG 2018-10-25 05:40:45,190 cleverhans]   Binary search step 8 of 10\n",
      "[DEBUG 2018-10-25 05:40:45,209 cleverhans]     Iteration 0 of 2000: loss=309 l2=0\n",
      "[DEBUG 2018-10-25 05:40:50,116 cleverhans]     Iteration 200 of 2000: loss=19.2 l2=19\n",
      "[DEBUG 2018-10-25 05:40:54,299 cleverhans]     Iteration 400 of 2000: loss=14.7 l2=14.5\n",
      "[DEBUG 2018-10-25 05:40:58,174 cleverhans]     Iteration 600 of 2000: loss=13.1 l2=12.9\n",
      "[DEBUG 2018-10-25 05:41:02,052 cleverhans]     Iteration 800 of 2000: loss=12.4 l2=12.2\n",
      "[DEBUG 2018-10-25 05:41:05,937 cleverhans]     Iteration 1000 of 2000: loss=11.9 l2=11.7\n",
      "[DEBUG 2018-10-25 05:41:09,883 cleverhans]     Iteration 1200 of 2000: loss=11.8 l2=11.6\n",
      "[DEBUG 2018-10-25 05:41:13,745 cleverhans]     Iteration 1400 of 2000: loss=11.5 l2=11.3\n",
      "[DEBUG 2018-10-25 05:41:17,584 cleverhans]     Iteration 1600 of 2000: loss=11.4 l2=11.2\n",
      "[DEBUG 2018-10-25 05:41:21,423 cleverhans]     Iteration 1800 of 2000: loss=11.3 l2=11.1\n",
      "[DEBUG 2018-10-25 05:41:25,189 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 05:41:25,190 cleverhans]    Mean successful distortion: 3.015\n",
      "[DEBUG 2018-10-25 05:41:25,192 cleverhans]   Binary search step 9 of 10\n",
      "[DEBUG 2018-10-25 05:41:25,210 cleverhans]     Iteration 0 of 2000: loss=309 l2=0\n",
      "[DEBUG 2018-10-25 05:41:30,161 cleverhans]     Iteration 200 of 2000: loss=19.2 l2=19\n",
      "[DEBUG 2018-10-25 05:41:34,252 cleverhans]     Iteration 400 of 2000: loss=14.7 l2=14.5\n",
      "[DEBUG 2018-10-25 05:41:38,159 cleverhans]     Iteration 600 of 2000: loss=13.1 l2=12.9\n",
      "[DEBUG 2018-10-25 05:41:41,996 cleverhans]     Iteration 800 of 2000: loss=12.4 l2=12.2\n",
      "[DEBUG 2018-10-25 05:41:45,797 cleverhans]     Iteration 1000 of 2000: loss=11.9 l2=11.7\n",
      "[DEBUG 2018-10-25 05:41:49,637 cleverhans]     Iteration 1200 of 2000: loss=11.8 l2=11.6\n",
      "[DEBUG 2018-10-25 05:41:53,501 cleverhans]     Iteration 1400 of 2000: loss=11.5 l2=11.3\n",
      "[DEBUG 2018-10-25 05:41:57,280 cleverhans]     Iteration 1600 of 2000: loss=11.4 l2=11.2\n",
      "[DEBUG 2018-10-25 05:42:01,096 cleverhans]     Iteration 1800 of 2000: loss=11.3 l2=11.1\n",
      "[DEBUG 2018-10-25 05:42:04,903 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 05:42:04,905 cleverhans]    Mean successful distortion: 3.015\n"
     ]
    }
   ],
   "source": [
    "keras.backend.set_learning_phase(0)\n",
    "set_log_level(logging.DEBUG)\n",
    "\n",
    "# CarliniWagner attack\n",
    "from lib.my_cw import CarliniWagnerL2\n",
    "\n",
    "attack_iterations = 2000\n",
    "cw_params = {'binary_search_steps': 10,\n",
    "             'max_iterations': attack_iterations,\n",
    "             'learning_rate': 0.1,\n",
    "             'batch_size': n_attack,\n",
    "             'initial_const': 1,\n",
    "             'y_target': y_target}\n",
    "cw = CarliniWagnerL2(hingenet, sess=sess)\n",
    "adv = cw.generate_np(X_atk, **cw_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/research/nn_proof/lib/my_pgd.py:698: UserWarning: Supplied extra keyword arguments that are not used in the graph computation. They have been ignored.\n",
      "  warnings.warn(\"Supplied extra keyword arguments that are not \"\n",
      "[INFO 2018-10-25 05:42:04,950 cleverhans] Constructing new graph for attack ProjectedGradientDescent\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.852, 8575.4627890625)\n",
      "4.996571\n",
      "(0.854, 8602.3351015625)\n",
      "4.995203\n",
      "(0.847, 8742.850703125)\n",
      "4.987829\n",
      "(0.855, 8622.7979375)\n",
      "4.99593\n",
      "(0.856, 8661.4553671875)\n",
      "4.9922166\n",
      "(0.843, 8607.681859375)\n",
      "4.9951134\n",
      "(0.844, 8871.4310234375)\n",
      "4.9795127\n",
      "(0.852, 8736.270046875)\n",
      "4.9977117\n",
      "(0.85, 8627.972046875)\n",
      "4.987301\n",
      "(0.851, 8656.137828125)\n",
      "4.987476\n",
      "0.902\n",
      "4.727993566551124\n"
     ]
    }
   ],
   "source": [
    "keras.backend.set_learning_phase(0)\n",
    "set_log_level(logging.DEBUG)\n",
    "\n",
    "from lib.my_pgd import ProjectedGradientDescent\n",
    "\n",
    "pgd_params = {'eps': 0.3,\n",
    "              'eps_iter': 0.05,\n",
    "              'clip_min': 0.,\n",
    "              'clip_max': 1.,\n",
    "              'ord': np.inf, \n",
    "              'nb_iter': 10,\n",
    "              'rand_init': True,\n",
    "              'batch_size': 100,\n",
    "              'y_target': y_target}\n",
    "pgd = ProjectedGradientDescent(hingenet, sess=sess)\n",
    "\n",
    "y_tar = np.argmax(y_target, axis=1)\n",
    "best_adv = np.zeros_like(X_atk)\n",
    "best_dist = np.zeros([n_attack]) + 1e5\n",
    "for i in range(10):\n",
    "    adv = pgd.generate_np(X_atk, **pgd_params)\n",
    "    print(hingenet.eval_model(sess, (adv, y_tar)))\n",
    "    dist = np.sqrt(np.sum((adv - X_atk)**2, (1, 2, 3)))\n",
    "    print(np.mean(dist))\n",
    "    pred = hingenet.predict_model(sess, adv)\n",
    "    y_pred = np.argmax(pred, axis=1)\n",
    "    for j in range(n_attack):\n",
    "        if y_pred[j] == y_tar[j] and dist[j] < best_dist[j]:\n",
    "            best_adv[j] = adv[j]\n",
    "            best_dist[j] = dist[j]\n",
    "print(np.mean(best_dist < 1e5))\n",
    "print(np.mean(best_dist[best_dist < 1e5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/research/nn_proof/lib/my_pgd.py:698: UserWarning: Supplied extra keyword arguments that are not used in the graph computation. They have been ignored.\n",
      "  warnings.warn(\"Supplied extra keyword arguments that are not \"\n",
      "[INFO 2018-10-25 07:15:20,471 cleverhans] Constructing new graph for attack ProjectedGradientDescent\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.706, 11446.4891953125)\n",
      "3.9313452\n",
      "(0.705, 11498.8334296875)\n",
      "3.9284532\n",
      "(0.699, 11483.4040078125)\n",
      "3.9299545\n",
      "(0.702, 11503.5681484375)\n",
      "3.9287148\n",
      "(0.698, 11493.701046875)\n",
      "3.9295492\n",
      "(0.702, 11593.9844453125)\n",
      "3.930929\n",
      "(0.7, 11458.988046875)\n",
      "3.9293478\n",
      "(0.702, 11476.2232421875)\n",
      "3.9324434\n",
      "(0.701, 11409.6427890625)\n",
      "3.9278166\n",
      "(0.693, 11494.297859375)\n",
      "3.928375\n",
      "0.76\n",
      "3.852000637117185\n"
     ]
    }
   ],
   "source": [
    "keras.backend.set_learning_phase(0)\n",
    "set_log_level(logging.DEBUG)\n",
    "\n",
    "from lib.my_pgd import ProjectedGradientDescent\n",
    "\n",
    "pgd_params = {'eps': 4,\n",
    "              'eps_iter': 0.5,\n",
    "              'clip_min': 0.,\n",
    "              'clip_max': 1.,\n",
    "              'ord': 2, \n",
    "              'nb_iter': 10,\n",
    "              'rand_init': True,\n",
    "              'batch_size': 100,\n",
    "              'y_target': y_target}\n",
    "pgd = ProjectedGradientDescent(hingenet, sess=sess)\n",
    "\n",
    "y_tar = np.argmax(y_target, axis=1)\n",
    "best_adv = np.zeros_like(X_atk)\n",
    "best_dist = np.zeros([n_attack]) + 1e5\n",
    "for i in range(10):\n",
    "    adv = pgd.generate_np(X_atk, **pgd_params)\n",
    "    print(hingenet.eval_model(sess, (adv, y_tar)))\n",
    "    dist = np.sqrt(np.sum((adv - X_atk)**2, (1, 2, 3)))\n",
    "    print(np.mean(dist))\n",
    "    pred = hingenet.predict_model(sess, adv)\n",
    "    y_pred = np.argmax(pred, axis=1)\n",
    "    for j in range(n_attack):\n",
    "        if y_pred[j] == y_tar[j] and dist[j] < best_dist[j]:\n",
    "            best_adv[j] = adv[j]\n",
    "            best_dist[j] = dist[j]\n",
    "print(np.mean(best_dist < 1e5))\n",
    "print(np.mean(best_dist[best_dist < 1e5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa677df3ef0>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(adv[0, :, :, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# V6\n",
    "\n",
    "margin: 1e2, reg: 1e-2 only last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from hinge_net import HingeNet\n",
    "\n",
    "# v6: margin = 1e2\n",
    "hingenet = HingeNet(\"hingenet_v6\", [28, 28, 1], [10], learning_rate=1e-3, \n",
    "                    load_model=True, save_path=\"model/hingenet_v6.h5\")\n",
    "# hingenet.train_model(sess, data, n_epoch=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = hingenet.model.get_weights()\n",
    "for i, w in enumerate(w):\n",
    "    if i % 2 == 0:\n",
    "        print(np.sum(np.square(w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Least likeley class\n",
    "n_attack = 1000\n",
    "X_atk = X_test[:, :, :, np.newaxis][:n_attack]\n",
    "y_atk = np.argmax(y_test[:n_attack], axis=1)\n",
    "\n",
    "y_pred = hingenet.predict_model(sess, X_atk)\n",
    "y_target = to_categorical(np.argmin(y_pred, axis=1))\n",
    "\n",
    "print(hingenet.eval_model(sess, (X_atk, y_atk)))\n",
    "\n",
    "keras.backend.set_learning_phase(0)\n",
    "set_log_level(logging.DEBUG)\n",
    "\n",
    "# CarliniWagner attack\n",
    "from lib.my_cw import CarliniWagnerL2\n",
    "\n",
    "attack_iterations = 200\n",
    "cw_params = {'binary_search_steps': 3,\n",
    "             'max_iterations': attack_iterations,\n",
    "             'learning_rate': 0.1,\n",
    "             'batch_size': 100,\n",
    "             'initial_const': 10,\n",
    "             'y_target': y_target}\n",
    "cw = CarliniWagnerL2(hingenet, sess=sess)\n",
    "adv = cw.generate_np(X_atk, **cw_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hingenet.eval_model(sess, (adv, np.argmax(y_target, axis=1))))\n",
    "print(np.sqrt(np.mean(np.sum((adv - X_atk)**2, (1, 2, 3)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V6-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from hinge_net import HingeNet\n",
    "\n",
    "# v6: margin = 1e2\n",
    "hingenet = HingeNet(\"hingenet_v6-1\", [28, 28, 1], [10], learning_rate=1e-3, \n",
    "                    load_model=True, save_path=\"model/hingenet_v6-1.h5\")\n",
    "# hingenet.train_model(sess, data, n_epoch=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = hingenet.model.get_weights()\n",
    "for i, w in enumerate(w):\n",
    "    if i % 2 == 0:\n",
    "        print(np.sum(np.square(w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Least likeley class\n",
    "n_attack = 1000\n",
    "X_atk = X_test[:, :, :, np.newaxis][:n_attack]\n",
    "y_atk = np.argmax(y_test[:n_attack], axis=1)\n",
    "\n",
    "y_pred = hingenet.predict_model(sess, X_atk)\n",
    "y_target = to_categorical(np.argmin(y_pred, axis=1))\n",
    "\n",
    "print(hingenet.eval_model(sess, (X_atk, y_atk)))\n",
    "\n",
    "keras.backend.set_learning_phase(0)\n",
    "set_log_level(logging.DEBUG)\n",
    "\n",
    "# CarliniWagner attack\n",
    "from lib.my_cw import CarliniWagnerL2\n",
    "\n",
    "attack_iterations = 200\n",
    "cw_params = {'binary_search_steps': 3,\n",
    "             'max_iterations': attack_iterations,\n",
    "             'learning_rate': 0.1,\n",
    "             'batch_size': 100,\n",
    "             'initial_const': 10,\n",
    "             'y_target': y_target}\n",
    "cw = CarliniWagnerL2(hingenet, sess=sess)\n",
    "adv = cw.generate_np(X_atk, **cw_params)\n",
    "\n",
    "print(hingenet.eval_model(sess, (adv, np.argmax(y_target, axis=1))))\n",
    "print(np.sqrt(np.mean(np.sum((adv - X_atk)**2, (1, 2, 3)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# V7\n",
    "\n",
    "margin: 1, last layer is sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from hinge_net import HingeNet\n",
    "\n",
    "hingenet = HingeNet(\"hingenet_v7\", [28, 28, 1], [10], learning_rate=1e-3, \n",
    "                    load_model=True, save_path=\"model/hingenet_v7.h5\")\n",
    "hingenet.train_model(sess, data, n_epoch=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = hingenet.model.get_weights()\n",
    "for i, w in enumerate(w):\n",
    "    if i % 2 == 0:\n",
    "        print(np.sum(np.square(w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Least likeley class\n",
    "n_attack = 1000\n",
    "X_atk = X_test[:, :, :, np.newaxis][:n_attack]\n",
    "y_atk = np.argmax(y_test[:n_attack], axis=1)\n",
    "\n",
    "y_pred = hingenet.predict_model(sess, X_atk)\n",
    "y_target = to_categorical(np.argmin(y_pred, axis=1))\n",
    "\n",
    "print(hingenet.eval_model(sess, (X_atk, y_atk)))\n",
    "\n",
    "keras.backend.set_learning_phase(0)\n",
    "set_log_level(logging.DEBUG)\n",
    "\n",
    "# CarliniWagner attack\n",
    "from lib.my_cw import CarliniWagnerL2\n",
    "\n",
    "attack_iterations = 200\n",
    "cw_params = {'binary_search_steps': 3,\n",
    "             'max_iterations': attack_iterations,\n",
    "             'learning_rate': 0.1,\n",
    "             'batch_size': 100,\n",
    "             'initial_const': 10,\n",
    "             'y_target': y_target}\n",
    "cw = CarliniWagnerL2(hingenet, sess=sess)\n",
    "adv = cw.generate_np(X_atk, **cw_params)\n",
    "\n",
    "print(hingenet.eval_model(sess, (adv, np.argmax(y_target, axis=1))))\n",
    "print(np.sqrt(np.mean(np.sum((adv - X_atk)**2, (1, 2, 3)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### attack at layer before sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hinge_net import HingeNet\n",
    "\n",
    "hingenet = HingeNet(\"hingenet_v7\", [28, 28, 1], [10], learning_rate=1e-3, \n",
    "                    load_model=True, save_path=\"model/hingenet_v7.h5\")\n",
    "# hingenet.train_model(sess, data, n_epoch=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = hingenet.model.get_weights()\n",
    "for i, w in enumerate(w):\n",
    "    if i % 2 == 0:\n",
    "        print(np.sum(np.square(w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Least likeley class\n",
    "n_attack = 1000\n",
    "X_atk = X_test[:, :, :, np.newaxis][:n_attack]\n",
    "y_atk = np.argmax(y_test[:n_attack], axis=1)\n",
    "\n",
    "y_pred = hingenet.predict_model(sess, X_atk)\n",
    "y_target = to_categorical(np.argmin(y_pred, axis=1))\n",
    "\n",
    "print(hingenet.eval_model(sess, (X_atk, y_atk)))\n",
    "\n",
    "keras.backend.set_learning_phase(0)\n",
    "set_log_level(logging.DEBUG)\n",
    "\n",
    "# CarliniWagner attack\n",
    "from lib.my_cw import CarliniWagnerL2\n",
    "\n",
    "attack_iterations = 200\n",
    "cw_params = {'binary_search_steps': 3,\n",
    "             'max_iterations': attack_iterations,\n",
    "             'learning_rate': 0.1,\n",
    "             'batch_size': 100,\n",
    "             'initial_const': 10,\n",
    "             'y_target': y_target}\n",
    "cw = CarliniWagnerL2(hingenet, sess=sess)\n",
    "adv = cw.generate_np(X_atk, **cw_params)\n",
    "\n",
    "print(hingenet.eval_model(sess, (adv, np.argmax(y_target, axis=1))))\n",
    "print(np.sqrt(np.mean(np.sum((adv - X_atk)**2, (1, 2, 3)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = hingenet.predict_model(sess, adv)\n",
    "\n",
    "for x, y in zip(adv[:10], y_pred[:10]):\n",
    "    print(np.argmax(y))\n",
    "    print(y)\n",
    "    plt.imshow(x[:, :, 0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = hingenet.predict_model(sess, X_test[:10, :, :, np.newaxis])\n",
    "\n",
    "for x, y in zip(X_test[:10], y_pred):\n",
    "    print(np.argmax(y))\n",
    "    print(y)\n",
    "    plt.imshow(x)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = hingenet.predict_model(sess, X_test[:, :, :, np.newaxis])\n",
    "y_sort = np.argsort(y_pred, axis=1)[:, ::-1]\n",
    "y_final = np.zeros(len(y_pred)) - 1\n",
    "for i in range(len(y_pred)):\n",
    "    d = y_pred[i, y_sort[i, 0]] - y_pred[i, y_sort[i, 1]]\n",
    "    if d >= 0.75:\n",
    "        y_final[i] = y_sort[i, 0]\n",
    "np.mean(y_final == np.argmax(y_test, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Least likeley class\n",
    "n_attack = 1000\n",
    "X_atk = X_test[:, :, :, np.newaxis][:n_attack]\n",
    "y_atk = np.argmax(y_test[:n_attack], axis=1)\n",
    "\n",
    "y_pred = hingenet.predict_model(sess, X_atk)\n",
    "y_target = to_categorical(np.argmin(y_pred, axis=1))\n",
    "\n",
    "print(hingenet.eval_model(sess, (X_atk, y_atk)))\n",
    "\n",
    "keras.backend.set_learning_phase(0)\n",
    "set_log_level(logging.DEBUG)\n",
    "\n",
    "# CarliniWagner attack\n",
    "from lib.my_cw import CarliniWagnerL2\n",
    "\n",
    "attack_iterations = 200\n",
    "cw_params = {'binary_search_steps': 3,\n",
    "             'max_iterations': attack_iterations,\n",
    "             'learning_rate': 0.1,\n",
    "             'batch_size': 100,\n",
    "             'initial_const': 10,\n",
    "             'y_target': y_target,\n",
    "             'confidence': 0.75}\n",
    "cw = CarliniWagnerL2(hingenet, sess=sess)\n",
    "adv = cw.generate_np(X_atk, **cw_params)\n",
    "\n",
    "# print(hingenet.eval_model(sess, (adv, np.argmax(y_target, axis=1))))\n",
    "print(np.sqrt(np.mean(np.sum((adv - X_atk)**2, (1, 2, 3)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = hingenet.predict_model(sess, adv)\n",
    "y_sort = np.argsort(y_pred, axis=1)[:, ::-1]\n",
    "y_final = np.zeros(len(y_pred)) - 1\n",
    "for i in range(len(y_pred)):\n",
    "    d = y_pred[i, y_sort[i, 0]] - y_pred[i, y_sort[i, 1]]\n",
    "    if d >= 0.75:\n",
    "        y_final[i] = y_sort[i, 0]\n",
    "np.mean(y_final == np.argmax(y_target, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = hingenet.predict_model(sess, adv)\n",
    "\n",
    "for x, y in zip(adv[:10], y_pred[:10]):\n",
    "    print(np.argmax(y))\n",
    "    print(y)\n",
    "    plt.imshow(x[:, :, 0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# V8\n",
    "\n",
    "Large network, margin: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from hinge_net import HingeNet\n",
    "\n",
    "hingenet = HingeNet(\"hingenet_v8\", [28, 28, 1], [10], learning_rate=1e-3, \n",
    "                    load_model=True, save_path=\"model/hingenet_v8.h5\")\n",
    "hingenet.train_model(sess, data, n_epoch=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = hingenet.model.get_weights()\n",
    "for i, w in enumerate(w):\n",
    "    if i % 2 == 0:\n",
    "        print(np.sum(np.square(w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Least likeley class\n",
    "n_attack = 1000\n",
    "X_atk = X_test[:, :, :, np.newaxis][:n_attack]\n",
    "y_atk = np.argmax(y_test[:n_attack], axis=1)\n",
    "\n",
    "y_pred = hingenet.predict_model(sess, X_atk)\n",
    "y_target = to_categorical(np.argmin(y_pred, axis=1))\n",
    "\n",
    "print(hingenet.eval_model(sess, (X_atk, y_atk)))\n",
    "\n",
    "keras.backend.set_learning_phase(0)\n",
    "set_log_level(logging.DEBUG)\n",
    "\n",
    "# CarliniWagner attack\n",
    "from lib.my_cw import CarliniWagnerL2\n",
    "\n",
    "attack_iterations = 200\n",
    "cw_params = {'binary_search_steps': 3,\n",
    "             'max_iterations': attack_iterations,\n",
    "             'learning_rate': 0.1,\n",
    "             'batch_size': 100,\n",
    "             'initial_const': 10,\n",
    "             'y_target': y_target}\n",
    "cw = CarliniWagnerL2(hingenet, sess=sess)\n",
    "adv = cw.generate_np(X_atk, **cw_params)\n",
    "\n",
    "print(hingenet.eval_model(sess, (adv, np.argmax(y_target, axis=1))))\n",
    "print(np.sqrt(np.mean(np.sum((adv - X_atk)**2, (1, 2, 3)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hinge_net import HingeNet\n",
    "\n",
    "hingenet = HingeNet(\"hingenet_v8-1\", [28, 28, 1], [10], learning_rate=1e-3, \n",
    "                    load_model=True, save_path=\"model/hingenet_v8-1.h5\")\n",
    "hingenet.train_model(sess, data, n_epoch=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = hingenet.model.get_weights()\n",
    "for i, w in enumerate(w):\n",
    "    if i % 2 == 0:\n",
    "        print(np.sum(np.square(w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Least likeley class\n",
    "n_attack = 1000\n",
    "X_atk = X_test[:, :, :, np.newaxis][:n_attack]\n",
    "y_atk = np.argmax(y_test[:n_attack], axis=1)\n",
    "\n",
    "y_pred = hingenet.predict_model(sess, X_atk)\n",
    "y_target = to_categorical(np.argmin(y_pred, axis=1))\n",
    "\n",
    "print(hingenet.eval_model(sess, (X_atk, y_atk)))\n",
    "\n",
    "keras.backend.set_learning_phase(0)\n",
    "set_log_level(logging.DEBUG)\n",
    "\n",
    "# CarliniWagner attack\n",
    "from lib.my_cw import CarliniWagnerL2\n",
    "\n",
    "attack_iterations = 200\n",
    "cw_params = {'binary_search_steps': 3,\n",
    "             'max_iterations': attack_iterations,\n",
    "             'learning_rate': 0.1,\n",
    "             'batch_size': 100,\n",
    "             'initial_const': 10,\n",
    "             'y_target': y_target}\n",
    "cw = CarliniWagnerL2(hingenet, sess=sess)\n",
    "adv = cw.generate_np(X_atk, **cw_params)\n",
    "\n",
    "print(hingenet.eval_model(sess, (adv, np.argmax(y_target, axis=1))))\n",
    "print(np.sqrt(np.mean(np.sum((adv - X_atk)**2, (1, 2, 3)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from hinge_net import HingeNet\n",
    "\n",
    "hingenet = HingeNet(\"hingenet_v8-2\", [28, 28, 1], [10], learning_rate=1e-3, \n",
    "                    load_model=True, save_path=\"model/hingenet_v8-2.h5\")\n",
    "hingenet.train_model(sess, data, n_epoch=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = hingenet.model.get_weights()\n",
    "for i, w in enumerate(w):\n",
    "    if i % 2 == 0:\n",
    "        print(np.sum(np.square(w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Least likeley class\n",
    "n_attack = 1000\n",
    "X_atk = X_test[:, :, :, np.newaxis][:n_attack]\n",
    "y_atk = np.argmax(y_test[:n_attack], axis=1)\n",
    "\n",
    "y_pred = hingenet.predict_model(sess, X_atk)\n",
    "y_target = to_categorical(np.argmin(y_pred, axis=1))\n",
    "\n",
    "print(hingenet.eval_model(sess, (X_atk, y_atk)))\n",
    "\n",
    "keras.backend.set_learning_phase(0)\n",
    "set_log_level(logging.DEBUG)\n",
    "\n",
    "# CarliniWagner attack\n",
    "from lib.my_cw import CarliniWagnerL2\n",
    "\n",
    "attack_iterations = 200\n",
    "cw_params = {'binary_search_steps': 3,\n",
    "             'max_iterations': attack_iterations,\n",
    "             'learning_rate': 0.1,\n",
    "             'batch_size': 100,\n",
    "             'initial_const': 10,\n",
    "             'y_target': y_target}\n",
    "cw = CarliniWagnerL2(hingenet, sess=sess)\n",
    "adv = cw.generate_np(X_atk, **cw_params)\n",
    "\n",
    "print(hingenet.eval_model(sess, (adv, np.argmax(y_target, axis=1))))\n",
    "print(np.sqrt(np.mean(np.sum((adv - X_atk)**2, (1, 2, 3)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# V9\n",
    "\n",
    "margin: 1e2, last layer is softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from hinge_net import HingeNet\n",
    "\n",
    "hingenet = HingeNet(\"hingenet_v9\", [28, 28, 1], [10], learning_rate=1e-3, \n",
    "                    load_model=True, save_path=\"model/hingenet_v9.h5\")\n",
    "hingenet.train_model(sess, data, n_epoch=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = hingenet.model.get_weights()\n",
    "for i, w in enumerate(w):\n",
    "    if i % 2 == 0:\n",
    "        print(np.sum(np.square(w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Least likeley class\n",
    "n_attack = 1000\n",
    "X_atk = X_test[:, :, :, np.newaxis][:n_attack]\n",
    "y_atk = np.argmax(y_test[:n_attack], axis=1)\n",
    "\n",
    "y_pred = hingenet.predict_model(sess, X_atk)\n",
    "y_target = to_categorical(np.argmin(y_pred, axis=1))\n",
    "\n",
    "print(hingenet.eval_model(sess, (X_atk, y_atk)))\n",
    "\n",
    "keras.backend.set_learning_phase(0)\n",
    "set_log_level(logging.DEBUG)\n",
    "\n",
    "# CarliniWagner attack\n",
    "from lib.my_cw import CarliniWagnerL2\n",
    "\n",
    "attack_iterations = 200\n",
    "cw_params = {'binary_search_steps': 3,\n",
    "             'max_iterations': attack_iterations,\n",
    "             'learning_rate': 0.1,\n",
    "             'batch_size': 100,\n",
    "             'initial_const': 10,\n",
    "             'y_target': y_target}\n",
    "cw = CarliniWagnerL2(hingenet, sess=sess)\n",
    "adv = cw.generate_np(X_atk, **cw_params)\n",
    "\n",
    "print(hingenet.eval_model(sess, (adv, np.argmax(y_target, axis=1))))\n",
    "print(np.sqrt(np.mean(np.sum((adv - X_atk)**2, (1, 2, 3)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V9-2\n",
    "\n",
    "margin 1, softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from hinge_net import HingeNet\n",
    "\n",
    "hingenet = HingeNet(\"hingenet_v9-2\", [28, 28, 1], [10], learning_rate=1e-3, \n",
    "                    load_model=True, save_path=\"model/hingenet_v9-2.h5\")\n",
    "hingenet.train_model(sess, data, n_epoch=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = hingenet.model.get_weights()\n",
    "for i, w in enumerate(w):\n",
    "    if i % 2 == 0:\n",
    "        print(np.sum(np.square(w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Least likeley class\n",
    "n_attack = 1000\n",
    "X_atk = X_test[:, :, :, np.newaxis][:n_attack]\n",
    "y_atk = np.argmax(y_test[:n_attack], axis=1)\n",
    "\n",
    "y_pred = hingenet.predict_model(sess, X_atk)\n",
    "y_target = to_categorical(np.argmin(y_pred, axis=1), 10)\n",
    "\n",
    "print(hingenet.eval_model(sess, (X_atk, y_atk)))\n",
    "\n",
    "keras.backend.set_learning_phase(0)\n",
    "set_log_level(logging.DEBUG)\n",
    "\n",
    "# CarliniWagner attack\n",
    "from lib.my_cw import CarliniWagnerL2\n",
    "\n",
    "attack_iterations = 200\n",
    "cw_params = {'binary_search_steps': 3,\n",
    "             'max_iterations': attack_iterations,\n",
    "             'learning_rate': 0.1,\n",
    "             'batch_size': 100,\n",
    "             'initial_const': 10,\n",
    "             'y_target': y_target}\n",
    "cw = CarliniWagnerL2(hingenet, sess=sess)\n",
    "adv = cw.generate_np(X_atk, **cw_params)\n",
    "\n",
    "print(hingenet.eval_model(sess, (adv, np.argmax(y_target, axis=1))))\n",
    "print(np.sqrt(np.mean(np.sum((adv - X_atk)**2, (1, 2, 3)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V9-1\n",
    "\n",
    "margin 1, log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from hinge_net import HingeNet\n",
    "\n",
    "hingenet = HingeNet(\"hingenet_v9-1\", [28, 28, 1], [10], learning_rate=1e-3, \n",
    "                    load_model=False, save_path=\"model/hingenet_v9-1.h5\")\n",
    "hingenet.train_model(sess, data, n_epoch=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = hingenet.model.get_weights()\n",
    "for i, w in enumerate(w):\n",
    "    if i % 2 == 0:\n",
    "        print(np.sum(np.square(w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Least likeley class\n",
    "n_attack = 1000\n",
    "X_atk = X_test[:, :, :, np.newaxis][:n_attack]\n",
    "y_atk = np.argmax(y_test[:n_attack], axis=1)\n",
    "\n",
    "y_pred = hingenet.predict_model(sess, X_atk)\n",
    "y_target = to_categorical(np.argmin(y_pred, axis=1), 10)\n",
    "\n",
    "print(hingenet.eval_model(sess, (X_atk, y_atk)))\n",
    "\n",
    "keras.backend.set_learning_phase(0)\n",
    "set_log_level(logging.DEBUG)\n",
    "\n",
    "# CarliniWagner attack\n",
    "from lib.my_cw import CarliniWagnerL2\n",
    "\n",
    "attack_iterations = 200\n",
    "cw_params = {'binary_search_steps': 3,\n",
    "             'max_iterations': attack_iterations,\n",
    "             'learning_rate': 0.1,\n",
    "             'batch_size': 100,\n",
    "             'initial_const': 10,\n",
    "             'y_target': y_target}\n",
    "cw = CarliniWagnerL2(hingenet, sess=sess)\n",
    "adv = cw.generate_np(X_atk, **cw_params)\n",
    "\n",
    "print(hingenet.eval_model(sess, (adv, np.argmax(y_target, axis=1))))\n",
    "print(np.sqrt(np.mean(np.sum((adv - X_atk)**2, (1, 2, 3)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph = tf.placeholder(tf.float32, [10, 28, 28, 1])\n",
    "y_pred = sess.run(hingenet.get_output(ph), feed_dict={ph: adv[:10]})\n",
    "\n",
    "for x, y in zip(adv[:10], y_pred[:10]):\n",
    "    print(np.argmax(y))\n",
    "    print(y)\n",
    "    plt.imshow(x[:, :, 0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# V10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved weights not found...\n",
      "Model was built, but no weight was loaded\n",
      "============= EPOCH: 0 =============\n",
      "STEP: 0 \tLoss: 2.2861\n",
      "STEP: 50 \tLoss: 0.5436\n",
      "STEP: 100 \tLoss: 0.4075\n",
      "STEP: 150 \tLoss: 0.2423\n",
      "STEP: 200 \tLoss: 0.1894\n",
      "STEP: 250 \tLoss: 0.2103\n",
      "STEP: 300 \tLoss: 0.1851\n",
      "STEP: 350 \tLoss: 0.2330\n",
      "STEP: 400 \tLoss: 0.1302\n",
      "STEP: 450 \tLoss: 0.1250\n",
      "Train Acc|Loss:\t0.9760|0.1186\n",
      "Val Acc|Loss:\t0.9743|0.1261\n",
      "============= EPOCH: 1 =============\n",
      "STEP: 0 \tLoss: 0.1953\n",
      "STEP: 50 \tLoss: 0.1399\n",
      "STEP: 100 \tLoss: 0.1659\n",
      "STEP: 150 \tLoss: 0.0294\n",
      "STEP: 200 \tLoss: 0.1054\n",
      "STEP: 250 \tLoss: 0.1019\n",
      "STEP: 300 \tLoss: 0.1171\n",
      "STEP: 350 \tLoss: 0.0870\n",
      "STEP: 400 \tLoss: 0.1796\n",
      "STEP: 450 \tLoss: 0.1205\n",
      "Train Acc|Loss:\t0.9846|0.0781\n",
      "Val Acc|Loss:\t0.9785|0.1036\n",
      "============= EPOCH: 2 =============\n",
      "STEP: 0 \tLoss: 0.0794\n",
      "STEP: 50 \tLoss: 0.0554\n",
      "STEP: 100 \tLoss: 0.1219\n",
      "STEP: 150 \tLoss: 0.0908\n",
      "STEP: 200 \tLoss: 0.0601\n",
      "STEP: 250 \tLoss: 0.0647\n",
      "STEP: 300 \tLoss: 0.0902\n",
      "STEP: 350 \tLoss: 0.0364\n",
      "STEP: 400 \tLoss: 0.0786\n",
      "STEP: 450 \tLoss: 0.0296\n",
      "Train Acc|Loss:\t0.9873|0.0678\n",
      "Val Acc|Loss:\t0.9799|0.0978\n",
      "============= EPOCH: 3 =============\n",
      "STEP: 0 \tLoss: 0.0796\n",
      "STEP: 50 \tLoss: 0.0693\n",
      "STEP: 100 \tLoss: 0.0358\n",
      "STEP: 150 \tLoss: 0.0680\n",
      "STEP: 200 \tLoss: 0.0581\n",
      "STEP: 250 \tLoss: 0.0820\n",
      "STEP: 300 \tLoss: 0.0333\n",
      "STEP: 350 \tLoss: 0.1207\n",
      "STEP: 400 \tLoss: 0.1192\n",
      "STEP: 450 \tLoss: 0.1140\n",
      "Train Acc|Loss:\t0.9904|0.0517\n",
      "Val Acc|Loss:\t0.9833|0.0809\n",
      "============= EPOCH: 4 =============\n",
      "STEP: 0 \tLoss: 0.0648\n",
      "STEP: 50 \tLoss: 0.0560\n",
      "STEP: 100 \tLoss: 0.0297\n",
      "STEP: 150 \tLoss: 0.0518\n",
      "STEP: 200 \tLoss: 0.0135\n",
      "STEP: 250 \tLoss: 0.0768\n",
      "STEP: 300 \tLoss: 0.0537\n",
      "STEP: 350 \tLoss: 0.0539\n",
      "STEP: 400 \tLoss: 0.0538\n",
      "STEP: 450 \tLoss: 0.0656\n",
      "Train Acc|Loss:\t0.9914|0.0453\n",
      "Val Acc|Loss:\t0.9825|0.0819\n",
      "============= EPOCH: 5 =============\n",
      "STEP: 0 \tLoss: 0.0415\n",
      "STEP: 50 \tLoss: 0.0155\n",
      "STEP: 100 \tLoss: 0.0517\n",
      "STEP: 150 \tLoss: 0.0800\n",
      "STEP: 200 \tLoss: 0.0744\n",
      "STEP: 250 \tLoss: 0.0535\n",
      "STEP: 300 \tLoss: 0.0104\n",
      "STEP: 350 \tLoss: 0.1040\n",
      "STEP: 400 \tLoss: 0.0952\n",
      "STEP: 450 \tLoss: 0.0733\n",
      "Train Acc|Loss:\t0.9928|0.0375\n",
      "Val Acc|Loss:\t0.9843|0.0774\n",
      "============= EPOCH: 6 =============\n",
      "STEP: 0 \tLoss: 0.0104\n",
      "STEP: 50 \tLoss: 0.0121\n",
      "STEP: 100 \tLoss: 0.0428\n",
      "STEP: 150 \tLoss: 0.0489\n",
      "STEP: 200 \tLoss: 0.0338\n",
      "STEP: 250 \tLoss: 0.0616\n",
      "STEP: 300 \tLoss: 0.0268\n",
      "STEP: 350 \tLoss: 0.0381\n",
      "STEP: 400 \tLoss: 0.0380\n",
      "STEP: 450 \tLoss: 0.0758\n",
      "Train Acc|Loss:\t0.9933|0.0367\n",
      "Val Acc|Loss:\t0.9835|0.0827\n",
      "============= EPOCH: 7 =============\n",
      "STEP: 0 \tLoss: 0.0707\n",
      "STEP: 50 \tLoss: 0.0313\n",
      "STEP: 100 \tLoss: 0.0536\n",
      "STEP: 150 \tLoss: 0.0316\n",
      "STEP: 200 \tLoss: 0.0549\n",
      "STEP: 250 \tLoss: 0.0466\n",
      "STEP: 300 \tLoss: 0.0675\n",
      "STEP: 350 \tLoss: 0.0452\n",
      "STEP: 400 \tLoss: 0.0633\n",
      "STEP: 450 \tLoss: 0.0129\n",
      "Train Acc|Loss:\t0.9942|0.0283\n",
      "Val Acc|Loss:\t0.9849|0.0742\n",
      "============= EPOCH: 8 =============\n",
      "STEP: 0 \tLoss: 0.0164\n",
      "STEP: 50 \tLoss: 0.0393\n",
      "STEP: 100 \tLoss: 0.0207\n",
      "STEP: 150 \tLoss: 0.0901\n",
      "STEP: 200 \tLoss: 0.0198\n",
      "STEP: 250 \tLoss: 0.0427\n",
      "STEP: 300 \tLoss: 0.0055\n",
      "STEP: 350 \tLoss: 0.0469\n",
      "STEP: 400 \tLoss: 0.0055\n",
      "STEP: 450 \tLoss: 0.0381\n",
      "Train Acc|Loss:\t0.9945|0.0284\n",
      "Val Acc|Loss:\t0.9851|0.0723\n",
      "============= EPOCH: 9 =============\n",
      "STEP: 0 \tLoss: 0.0149\n",
      "STEP: 50 \tLoss: 0.0557\n",
      "STEP: 100 \tLoss: 0.0437\n",
      "STEP: 150 \tLoss: 0.0215\n",
      "STEP: 200 \tLoss: 0.0220\n",
      "STEP: 250 \tLoss: 0.0163\n",
      "STEP: 300 \tLoss: 0.0500\n",
      "STEP: 350 \tLoss: 0.0241\n",
      "STEP: 400 \tLoss: 0.0236\n",
      "STEP: 450 \tLoss: 0.0300\n",
      "Train Acc|Loss:\t0.9946|0.0269\n",
      "Val Acc|Loss:\t0.9837|0.0723\n"
     ]
    }
   ],
   "source": [
    "from hinge_net import HingeNet\n",
    "\n",
    "hingenet = HingeNet(\"v10.3\", [28, 28, 1], [10], learning_rate=1e-3, \n",
    "                    loss=\"hinge\", margin=2, reg=0, activation=\"custom\",\n",
    "                    load_model=True, save_path=\"model/v10.3.h5\")\n",
    "hingenet.train_model(sess, data, n_epoch=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9851, 0.07231615725755691)"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hingenet.eval_model(sess, (X_test[:, :, :, np.newaxis], np.argmax(y_test, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Least likeley class\n",
    "n_attack = 1000\n",
    "X_atk = X_test[:, :, :, np.newaxis][:n_attack]\n",
    "y_atk = np.argmax(y_test[:n_attack], axis=1)\n",
    "\n",
    "y_pred = hingenet.predict_model(sess, X_atk)\n",
    "y_target = to_categorical(np.argmin(y_pred, axis=1), 10)\n",
    "# y_target = to_categorical((np.argmax(y_pred, axis=1) + 1) % 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.98, 0.08815036082267762)"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hingenet.eval_model(sess, (X_atk, y_atk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2018-10-25 20:03:06,911 cleverhans] Constructing new graph for attack CarliniWagnerL2\n",
      "[DEBUG 2018-10-25 20:03:09,059 cleverhans] Running CWL2 attack on instance 0 of 1000\n",
      "[DEBUG 2018-10-25 20:03:09,602 cleverhans]   Binary search step 0 of 10\n",
      "[DEBUG 2018-10-25 20:03:14,912 cleverhans]     Iteration 0 of 500: loss=108 l2=0\n",
      "[DEBUG 2018-10-25 20:03:16,945 cleverhans]     Iteration 50 of 500: loss=27.7 l2=8.63\n",
      "[DEBUG 2018-10-25 20:03:18,919 cleverhans]     Iteration 100 of 500: loss=21 l2=6.34\n",
      "[DEBUG 2018-10-25 20:03:20,755 cleverhans]     Iteration 150 of 500: loss=18.9 l2=5.63\n",
      "[DEBUG 2018-10-25 20:03:22,494 cleverhans]     Iteration 200 of 500: loss=17.8 l2=5.15\n",
      "[DEBUG 2018-10-25 20:03:24,177 cleverhans]     Iteration 250 of 500: loss=16.5 l2=4.81\n",
      "[DEBUG 2018-10-25 20:03:25,821 cleverhans]     Iteration 300 of 500: loss=15.3 l2=4.54\n",
      "[DEBUG 2018-10-25 20:03:27,451 cleverhans]     Iteration 350 of 500: loss=14.2 l2=4.31\n",
      "[DEBUG 2018-10-25 20:03:29,018 cleverhans]     Iteration 400 of 500: loss=13.5 l2=4.11\n",
      "[DEBUG 2018-10-25 20:03:30,595 cleverhans]     Iteration 450 of 500: loss=12.8 l2=4.04\n",
      "[DEBUG 2018-10-25 20:03:32,104 cleverhans]   Successfully generated adversarial examples on 796 of 1000 instances.\n",
      "[DEBUG 2018-10-25 20:03:32,105 cleverhans]    Mean successful distortion: 1.746\n",
      "[DEBUG 2018-10-25 20:03:32,107 cleverhans]   Binary search step 1 of 10\n",
      "[DEBUG 2018-10-25 20:03:32,132 cleverhans]     Iteration 0 of 500: loss=271 l2=0\n",
      "[DEBUG 2018-10-25 20:03:34,069 cleverhans]     Iteration 50 of 500: loss=89.4 l2=7.86\n",
      "[DEBUG 2018-10-25 20:03:35,968 cleverhans]     Iteration 100 of 500: loss=65.9 l2=7.24\n",
      "[DEBUG 2018-10-25 20:03:37,793 cleverhans]     Iteration 150 of 500: loss=56.7 l2=6.85\n",
      "[DEBUG 2018-10-25 20:03:39,614 cleverhans]     Iteration 200 of 500: loss=53.6 l2=6.36\n",
      "[DEBUG 2018-10-25 20:03:41,342 cleverhans]     Iteration 250 of 500: loss=51.5 l2=5.89\n",
      "[DEBUG 2018-10-25 20:03:43,132 cleverhans]     Iteration 300 of 500: loss=47 l2=5.62\n",
      "[DEBUG 2018-10-25 20:03:44,847 cleverhans]     Iteration 350 of 500: loss=42.1 l2=5.48\n",
      "[DEBUG 2018-10-25 20:03:46,546 cleverhans]     Iteration 400 of 500: loss=38.2 l2=5.29\n",
      "[DEBUG 2018-10-25 20:03:48,274 cleverhans]     Iteration 450 of 500: loss=34.9 l2=5.16\n",
      "[DEBUG 2018-10-25 20:03:49,971 cleverhans]   Successfully generated adversarial examples on 906 of 1000 instances.\n",
      "[DEBUG 2018-10-25 20:03:49,972 cleverhans]    Mean successful distortion: 1.874\n",
      "[DEBUG 2018-10-25 20:03:49,974 cleverhans]   Binary search step 2 of 10\n",
      "[DEBUG 2018-10-25 20:03:49,999 cleverhans]     Iteration 0 of 500: loss=1.14e+03 l2=0\n",
      "[DEBUG 2018-10-25 20:03:51,961 cleverhans]     Iteration 50 of 500: loss=410 l2=6.72\n",
      "[DEBUG 2018-10-25 20:03:53,801 cleverhans]     Iteration 100 of 500: loss=305 l2=6.79\n",
      "[DEBUG 2018-10-25 20:03:55,630 cleverhans]     Iteration 150 of 500: loss=265 l2=6.62\n",
      "[DEBUG 2018-10-25 20:03:57,461 cleverhans]     Iteration 200 of 500: loss=255 l2=6.31\n",
      "[DEBUG 2018-10-25 20:03:59,213 cleverhans]     Iteration 250 of 500: loss=251 l2=6\n",
      "[DEBUG 2018-10-25 20:04:00,987 cleverhans]     Iteration 300 of 500: loss=246 l2=5.71\n",
      "[DEBUG 2018-10-25 20:04:02,732 cleverhans]     Iteration 350 of 500: loss=244 l2=5.54\n",
      "[DEBUG 2018-10-25 20:04:04,472 cleverhans]     Iteration 400 of 500: loss=240 l2=5.41\n",
      "[DEBUG 2018-10-25 20:04:06,234 cleverhans]     Iteration 450 of 500: loss=236 l2=5.33\n",
      "[DEBUG 2018-10-25 20:04:07,970 cleverhans]   Successfully generated adversarial examples on 925 of 1000 instances.\n",
      "[DEBUG 2018-10-25 20:04:07,971 cleverhans]    Mean successful distortion: 1.839\n",
      "[DEBUG 2018-10-25 20:04:07,972 cleverhans]   Binary search step 3 of 10\n",
      "[DEBUG 2018-10-25 20:04:08,000 cleverhans]     Iteration 0 of 500: loss=8.56e+03 l2=0\n",
      "[DEBUG 2018-10-25 20:04:10,005 cleverhans]     Iteration 50 of 500: loss=3.07e+03 l2=5.94\n",
      "[DEBUG 2018-10-25 20:04:11,951 cleverhans]     Iteration 100 of 500: loss=2.24e+03 l2=6.1\n",
      "[DEBUG 2018-10-25 20:04:13,814 cleverhans]     Iteration 150 of 500: loss=2.03e+03 l2=6.08\n",
      "[DEBUG 2018-10-25 20:04:15,646 cleverhans]     Iteration 200 of 500: loss=1.99e+03 l2=5.92\n",
      "[DEBUG 2018-10-25 20:04:17,458 cleverhans]     Iteration 250 of 500: loss=1.95e+03 l2=5.72\n",
      "[DEBUG 2018-10-25 20:04:19,322 cleverhans]     Iteration 300 of 500: loss=1.9e+03 l2=5.63\n",
      "[DEBUG 2018-10-25 20:04:21,153 cleverhans]     Iteration 350 of 500: loss=1.9e+03 l2=5.48\n",
      "[DEBUG 2018-10-25 20:04:22,928 cleverhans]     Iteration 400 of 500: loss=1.89e+03 l2=5.35\n",
      "[DEBUG 2018-10-25 20:04:24,722 cleverhans]     Iteration 450 of 500: loss=1.85e+03 l2=5.3\n",
      "[DEBUG 2018-10-25 20:04:26,472 cleverhans]   Successfully generated adversarial examples on 939 of 1000 instances.\n",
      "[DEBUG 2018-10-25 20:04:26,473 cleverhans]    Mean successful distortion: 1.826\n",
      "[DEBUG 2018-10-25 20:04:26,474 cleverhans]   Binary search step 4 of 10\n",
      "[DEBUG 2018-10-25 20:04:26,500 cleverhans]     Iteration 0 of 500: loss=6.91e+04 l2=0\n",
      "[DEBUG 2018-10-25 20:04:28,511 cleverhans]     Iteration 50 of 500: loss=2.56e+04 l2=5.41\n",
      "[DEBUG 2018-10-25 20:04:30,440 cleverhans]     Iteration 100 of 500: loss=1.97e+04 l2=5.56\n",
      "[DEBUG 2018-10-25 20:04:32,384 cleverhans]     Iteration 150 of 500: loss=1.82e+04 l2=5.61\n",
      "[DEBUG 2018-10-25 20:04:34,268 cleverhans]     Iteration 200 of 500: loss=1.72e+04 l2=5.54\n",
      "[DEBUG 2018-10-25 20:04:36,154 cleverhans]     Iteration 250 of 500: loss=1.71e+04 l2=5.5\n",
      "[DEBUG 2018-10-25 20:04:38,062 cleverhans]     Iteration 300 of 500: loss=1.71e+04 l2=5.42\n",
      "[DEBUG 2018-10-25 20:04:39,937 cleverhans]     Iteration 350 of 500: loss=1.71e+04 l2=5.28\n",
      "[DEBUG 2018-10-25 20:04:41,811 cleverhans]     Iteration 400 of 500: loss=1.7e+04 l2=5.24\n",
      "[DEBUG 2018-10-25 20:04:43,634 cleverhans]     Iteration 450 of 500: loss=1.7e+04 l2=5.18\n",
      "[DEBUG 2018-10-25 20:04:45,433 cleverhans]   Successfully generated adversarial examples on 944 of 1000 instances.\n",
      "[DEBUG 2018-10-25 20:04:45,434 cleverhans]    Mean successful distortion: 1.815\n",
      "[DEBUG 2018-10-25 20:04:45,435 cleverhans]   Binary search step 5 of 10\n",
      "[DEBUG 2018-10-25 20:04:45,461 cleverhans]     Iteration 0 of 500: loss=6.25e+05 l2=0\n",
      "[DEBUG 2018-10-25 20:04:47,491 cleverhans]     Iteration 50 of 500: loss=2.28e+05 l2=5.19\n",
      "[DEBUG 2018-10-25 20:04:49,440 cleverhans]     Iteration 100 of 500: loss=1.86e+05 l2=5.33\n",
      "[DEBUG 2018-10-25 20:04:51,374 cleverhans]     Iteration 150 of 500: loss=1.78e+05 l2=5.32\n",
      "[DEBUG 2018-10-25 20:04:53,311 cleverhans]     Iteration 200 of 500: loss=1.75e+05 l2=5.22\n",
      "[DEBUG 2018-10-25 20:04:55,233 cleverhans]     Iteration 250 of 500: loss=1.74e+05 l2=5.11\n",
      "[DEBUG 2018-10-25 20:04:57,138 cleverhans]     Iteration 300 of 500: loss=1.74e+05 l2=5.07\n",
      "[DEBUG 2018-10-25 20:04:59,022 cleverhans]     Iteration 350 of 500: loss=1.74e+05 l2=5.05\n",
      "[DEBUG 2018-10-25 20:05:00,935 cleverhans]     Iteration 400 of 500: loss=1.74e+05 l2=5.08\n",
      "[DEBUG 2018-10-25 20:05:02,799 cleverhans]     Iteration 450 of 500: loss=1.73e+05 l2=5.08\n",
      "[DEBUG 2018-10-25 20:05:04,623 cleverhans]   Successfully generated adversarial examples on 945 of 1000 instances.\n",
      "[DEBUG 2018-10-25 20:05:04,624 cleverhans]    Mean successful distortion: 1.798\n",
      "[DEBUG 2018-10-25 20:05:04,625 cleverhans]   Binary search step 6 of 10\n",
      "[DEBUG 2018-10-25 20:05:04,649 cleverhans]     Iteration 0 of 500: loss=6.11e+06 l2=0\n",
      "[DEBUG 2018-10-25 20:05:04,650 cleverhans]     Failed to make progress; stop early\n",
      "[DEBUG 2018-10-25 20:05:04,663 cleverhans]   Successfully generated adversarial examples on 945 of 1000 instances.\n",
      "[DEBUG 2018-10-25 20:05:04,664 cleverhans]    Mean successful distortion: 1.798\n",
      "[DEBUG 2018-10-25 20:05:04,665 cleverhans]   Binary search step 7 of 10\n",
      "[DEBUG 2018-10-25 20:05:04,692 cleverhans]     Iteration 0 of 500: loss=6.1e+07 l2=0\n",
      "[DEBUG 2018-10-25 20:05:04,693 cleverhans]     Failed to make progress; stop early\n",
      "[DEBUG 2018-10-25 20:05:04,705 cleverhans]   Successfully generated adversarial examples on 945 of 1000 instances.\n",
      "[DEBUG 2018-10-25 20:05:04,706 cleverhans]    Mean successful distortion: 1.798\n",
      "[DEBUG 2018-10-25 20:05:04,707 cleverhans]   Binary search step 8 of 10\n",
      "[DEBUG 2018-10-25 20:05:04,731 cleverhans]     Iteration 0 of 500: loss=6.1e+08 l2=0\n",
      "[DEBUG 2018-10-25 20:05:04,732 cleverhans]     Failed to make progress; stop early\n",
      "[DEBUG 2018-10-25 20:05:04,744 cleverhans]   Successfully generated adversarial examples on 945 of 1000 instances.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DEBUG 2018-10-25 20:05:04,745 cleverhans]    Mean successful distortion: 1.798\n",
      "[DEBUG 2018-10-25 20:05:04,746 cleverhans]   Binary search step 9 of 10\n",
      "[DEBUG 2018-10-25 20:05:04,769 cleverhans]     Iteration 0 of 500: loss=6.1e+09 l2=0\n",
      "[DEBUG 2018-10-25 20:05:04,770 cleverhans]     Failed to make progress; stop early\n",
      "[DEBUG 2018-10-25 20:05:04,784 cleverhans]   Successfully generated adversarial examples on 945 of 1000 instances.\n",
      "[DEBUG 2018-10-25 20:05:04,785 cleverhans]    Mean successful distortion: 1.798\n"
     ]
    }
   ],
   "source": [
    "keras.backend.set_learning_phase(0)\n",
    "set_log_level(logging.DEBUG)\n",
    "\n",
    "# CarliniWagner attack\n",
    "from lib.my_cw import CarliniWagnerL2\n",
    "\n",
    "attack_iterations = 500\n",
    "cw_params = {'binary_search_steps': 10,\n",
    "             'max_iterations': attack_iterations,\n",
    "             'learning_rate': 0.1,\n",
    "             'batch_size': n_attack,\n",
    "             'initial_const': 1,\n",
    "             'y_target': y_target}\n",
    "cw = CarliniWagnerL2(hingenet, sess=sess)\n",
    "adv = cw.generate_np(X_atk, **cw_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa44671ff60>"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(adv[5, :, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/research/nn_proof/lib/my_pgd.py:698: UserWarning: Supplied extra keyword arguments that are not used in the graph computation. They have been ignored.\n",
      "  warnings.warn(\"Supplied extra keyword arguments that are not \"\n",
      "[INFO 2018-10-25 19:23:26,621 cleverhans] Constructing new graph for attack ProjectedGradientDescent\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.049, 2.8439740867614747)\n",
      "4.038855\n",
      "(0.053, 2.8361883239746093)\n",
      "4.038858\n",
      "(0.043, 2.850980401992798)\n",
      "4.0296144\n",
      "(0.058, 2.8289904518127442)\n",
      "4.0250134\n",
      "(0.047, 2.850432149887085)\n",
      "4.0323324\n",
      "(0.045, 2.846483455657959)\n",
      "4.0422564\n",
      "(0.05, 2.846467294692993)\n",
      "4.0337825\n",
      "(0.039, 2.8638558540344237)\n",
      "4.0279226\n",
      "(0.048, 2.8542617073059082)\n",
      "4.037876\n",
      "(0.051, 2.835804832458496)\n",
      "4.0379004\n",
      "0.152\n",
      "3.9598035859434226\n"
     ]
    }
   ],
   "source": [
    "keras.backend.set_learning_phase(0)\n",
    "set_log_level(logging.DEBUG)\n",
    "\n",
    "from lib.my_pgd import ProjectedGradientDescent\n",
    "\n",
    "pgd_params = {'eps': 0.3,\n",
    "              'eps_iter': 0.05,\n",
    "              'clip_min': 0.,\n",
    "              'clip_max': 1.,\n",
    "              'ord': np.inf, \n",
    "              'nb_iter': 10,\n",
    "              'rand_init': True,\n",
    "              'batch_size': 100}\n",
    "pgd = ProjectedGradientDescent(hingenet, sess=sess)\n",
    "\n",
    "y_tar = np.argmax(y_target, axis=1)\n",
    "best_adv = np.zeros_like(X_atk)\n",
    "best_dist = np.zeros([n_attack]) + 1e5\n",
    "for i in range(10):\n",
    "    adv = pgd.generate_np(X_atk, **pgd_params)\n",
    "    print(hingenet.eval_model(sess, (adv, y_tar)))\n",
    "    dist = np.sqrt(np.sum((adv - X_atk)**2, (1, 2, 3)))\n",
    "    print(np.mean(dist))\n",
    "    pred = hingenet.predict_model(sess, adv)\n",
    "    y_pred = np.argmax(pred, axis=1)\n",
    "    for j in range(n_attack):\n",
    "        if y_pred[j] == y_tar[j] and dist[j] < best_dist[j]:\n",
    "            best_adv[j] = adv[j]\n",
    "            best_dist[j] = dist[j]\n",
    "print(np.mean(best_dist < 1e5))\n",
    "print(np.mean(best_dist[best_dist < 1e5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2018-10-25 19:59:12,229 cleverhans] Constructing new graph for attack CarliniWagnerL2\n",
      "[DEBUG 2018-10-25 19:59:14,384 cleverhans] Running CWL2 attack on instance 0 of 1000\n",
      "[DEBUG 2018-10-25 19:59:14,959 cleverhans]   Binary search step 0 of 10\n",
      "[DEBUG 2018-10-25 19:59:20,216 cleverhans]     Iteration 0 of 500: loss=72.8 l2=0\n",
      "[DEBUG 2018-10-25 19:59:21,991 cleverhans]     Iteration 50 of 500: loss=19.3 l2=4.49\n",
      "[DEBUG 2018-10-25 19:59:23,867 cleverhans]     Iteration 100 of 500: loss=16.6 l2=2.71\n",
      "[DEBUG 2018-10-25 19:59:25,564 cleverhans]     Iteration 150 of 500: loss=15.7 l2=2.4\n",
      "[DEBUG 2018-10-25 19:59:27,158 cleverhans]     Iteration 200 of 500: loss=15.3 l2=2.31\n",
      "[DEBUG 2018-10-25 19:59:28,713 cleverhans]     Iteration 250 of 500: loss=14.9 l2=2.23\n",
      "[DEBUG 2018-10-25 19:59:30,237 cleverhans]     Iteration 300 of 500: loss=14.3 l2=2.15\n",
      "[DEBUG 2018-10-25 19:59:31,773 cleverhans]     Iteration 350 of 500: loss=13.3 l2=2.12\n",
      "[DEBUG 2018-10-25 19:59:33,300 cleverhans]     Iteration 400 of 500: loss=12.8 l2=2.06\n",
      "[DEBUG 2018-10-25 19:59:34,819 cleverhans]     Iteration 450 of 500: loss=12.1 l2=2.06\n",
      "[DEBUG 2018-10-25 19:59:36,282 cleverhans]   Successfully generated adversarial examples on 822 of 1000 instances.\n",
      "[DEBUG 2018-10-25 19:59:36,283 cleverhans]    Mean successful distortion: 1.141\n",
      "[DEBUG 2018-10-25 19:59:36,284 cleverhans]   Binary search step 1 of 10\n",
      "[DEBUG 2018-10-25 19:59:36,309 cleverhans]     Iteration 0 of 500: loss=172 l2=0\n",
      "[DEBUG 2018-10-25 19:59:38,153 cleverhans]     Iteration 50 of 500: loss=73.2 l2=4.13\n",
      "[DEBUG 2018-10-25 19:59:39,914 cleverhans]     Iteration 100 of 500: loss=67.1 l2=3.22\n",
      "[DEBUG 2018-10-25 19:59:41,610 cleverhans]     Iteration 150 of 500: loss=61.3 l2=2.99\n",
      "[DEBUG 2018-10-25 19:59:43,334 cleverhans]     Iteration 200 of 500: loss=53.2 l2=3.04\n",
      "[DEBUG 2018-10-25 19:59:45,132 cleverhans]     Iteration 250 of 500: loss=47.5 l2=2.97\n",
      "[DEBUG 2018-10-25 19:59:46,794 cleverhans]     Iteration 300 of 500: loss=41.1 l2=3.02\n",
      "[DEBUG 2018-10-25 19:59:48,422 cleverhans]     Iteration 350 of 500: loss=36.3 l2=3.01\n",
      "[DEBUG 2018-10-25 19:59:50,091 cleverhans]     Iteration 400 of 500: loss=31.8 l2=3.03\n",
      "[DEBUG 2018-10-25 19:59:51,738 cleverhans]     Iteration 450 of 500: loss=28.7 l2=3.02\n",
      "[DEBUG 2018-10-25 19:59:53,339 cleverhans]   Successfully generated adversarial examples on 961 of 1000 instances.\n",
      "[DEBUG 2018-10-25 19:59:53,340 cleverhans]    Mean successful distortion: 1.327\n",
      "[DEBUG 2018-10-25 19:59:53,342 cleverhans]   Binary search step 2 of 10\n",
      "[DEBUG 2018-10-25 19:59:53,366 cleverhans]     Iteration 0 of 500: loss=398 l2=0\n",
      "[DEBUG 2018-10-25 19:59:55,228 cleverhans]     Iteration 50 of 500: loss=238 l2=3.23\n",
      "[DEBUG 2018-10-25 19:59:57,049 cleverhans]     Iteration 100 of 500: loss=217 l2=2.75\n",
      "[DEBUG 2018-10-25 19:59:58,795 cleverhans]     Iteration 150 of 500: loss=207 l2=2.56\n",
      "[DEBUG 2018-10-25 20:00:00,511 cleverhans]     Iteration 200 of 500: loss=205 l2=2.48\n",
      "[DEBUG 2018-10-25 20:00:02,233 cleverhans]     Iteration 250 of 500: loss=202 l2=2.46\n",
      "[DEBUG 2018-10-25 20:00:03,903 cleverhans]     Iteration 300 of 500: loss=198 l2=2.36\n",
      "[DEBUG 2018-10-25 20:00:05,550 cleverhans]     Iteration 350 of 500: loss=191 l2=2.41\n",
      "[DEBUG 2018-10-25 20:00:07,277 cleverhans]     Iteration 400 of 500: loss=183 l2=2.36\n",
      "[DEBUG 2018-10-25 20:00:08,970 cleverhans]     Iteration 450 of 500: loss=151 l2=2.56\n",
      "[DEBUG 2018-10-25 20:00:10,641 cleverhans]   Successfully generated adversarial examples on 980 of 1000 instances.\n",
      "[DEBUG 2018-10-25 20:00:10,642 cleverhans]    Mean successful distortion: 1.296\n",
      "[DEBUG 2018-10-25 20:00:10,644 cleverhans]   Binary search step 3 of 10\n",
      "[DEBUG 2018-10-25 20:00:10,667 cleverhans]     Iteration 0 of 500: loss=1.85e+03 l2=0\n",
      "[DEBUG 2018-10-25 20:00:12,569 cleverhans]     Iteration 50 of 500: loss=1.29e+03 l2=2.68\n",
      "[DEBUG 2018-10-25 20:00:14,358 cleverhans]     Iteration 100 of 500: loss=1.23e+03 l2=2.37\n",
      "[DEBUG 2018-10-25 20:00:16,158 cleverhans]     Iteration 150 of 500: loss=1.22e+03 l2=2.25\n",
      "[DEBUG 2018-10-25 20:00:17,976 cleverhans]     Iteration 200 of 500: loss=1.22e+03 l2=2.21\n",
      "[DEBUG 2018-10-25 20:00:19,687 cleverhans]     Iteration 250 of 500: loss=1.22e+03 l2=2.18\n",
      "[DEBUG 2018-10-25 20:00:21,461 cleverhans]     Iteration 300 of 500: loss=1.21e+03 l2=2.23\n",
      "[DEBUG 2018-10-25 20:00:23,159 cleverhans]     Iteration 350 of 500: loss=1.2e+03 l2=2.38\n",
      "[DEBUG 2018-10-25 20:00:24,858 cleverhans]     Iteration 400 of 500: loss=1.2e+03 l2=2.33\n",
      "[DEBUG 2018-10-25 20:00:26,640 cleverhans]     Iteration 450 of 500: loss=1.12e+03 l2=2.39\n",
      "[DEBUG 2018-10-25 20:00:28,392 cleverhans]   Successfully generated adversarial examples on 982 of 1000 instances.\n",
      "[DEBUG 2018-10-25 20:00:28,393 cleverhans]    Mean successful distortion: 1.248\n",
      "[DEBUG 2018-10-25 20:00:28,395 cleverhans]   Binary search step 4 of 10\n",
      "[DEBUG 2018-10-25 20:00:28,420 cleverhans]     Iteration 0 of 500: loss=1.55e+04 l2=0\n",
      "[DEBUG 2018-10-25 20:00:30,330 cleverhans]     Iteration 50 of 500: loss=1.11e+04 l2=2.27\n",
      "[DEBUG 2018-10-25 20:00:32,204 cleverhans]     Iteration 100 of 500: loss=1.09e+04 l2=2.02\n",
      "[DEBUG 2018-10-25 20:00:34,034 cleverhans]     Iteration 150 of 500: loss=1.09e+04 l2=1.86\n",
      "[DEBUG 2018-10-25 20:00:35,840 cleverhans]     Iteration 200 of 500: loss=1.09e+04 l2=1.81\n",
      "[DEBUG 2018-10-25 20:00:35,841 cleverhans]     Failed to make progress; stop early\n",
      "[DEBUG 2018-10-25 20:00:35,855 cleverhans]   Successfully generated adversarial examples on 982 of 1000 instances.\n",
      "[DEBUG 2018-10-25 20:00:35,856 cleverhans]    Mean successful distortion: 1.246\n",
      "[DEBUG 2018-10-25 20:00:35,857 cleverhans]   Binary search step 5 of 10\n",
      "[DEBUG 2018-10-25 20:00:35,881 cleverhans]     Iteration 0 of 500: loss=1.53e+05 l2=0\n",
      "[DEBUG 2018-10-25 20:00:37,778 cleverhans]     Iteration 50 of 500: loss=1.09e+05 l2=2.32\n",
      "[DEBUG 2018-10-25 20:00:39,652 cleverhans]     Iteration 100 of 500: loss=1.08e+05 l2=2.05\n",
      "[DEBUG 2018-10-25 20:00:41,485 cleverhans]     Iteration 150 of 500: loss=1.08e+05 l2=1.94\n",
      "[DEBUG 2018-10-25 20:00:43,309 cleverhans]     Iteration 200 of 500: loss=1.07e+05 l2=1.96\n",
      "[DEBUG 2018-10-25 20:00:45,134 cleverhans]     Iteration 250 of 500: loss=1.07e+05 l2=2.03\n",
      "[DEBUG 2018-10-25 20:00:45,135 cleverhans]     Failed to make progress; stop early\n",
      "[DEBUG 2018-10-25 20:00:45,151 cleverhans]   Successfully generated adversarial examples on 982 of 1000 instances.\n",
      "[DEBUG 2018-10-25 20:00:45,151 cleverhans]    Mean successful distortion: 1.245\n",
      "[DEBUG 2018-10-25 20:00:45,153 cleverhans]   Binary search step 6 of 10\n",
      "[DEBUG 2018-10-25 20:00:45,177 cleverhans]     Iteration 0 of 500: loss=1.53e+06 l2=0\n",
      "[DEBUG 2018-10-25 20:00:45,178 cleverhans]     Failed to make progress; stop early\n",
      "[DEBUG 2018-10-25 20:00:45,191 cleverhans]   Successfully generated adversarial examples on 982 of 1000 instances.\n",
      "[DEBUG 2018-10-25 20:00:45,192 cleverhans]    Mean successful distortion: 1.245\n",
      "[DEBUG 2018-10-25 20:00:45,193 cleverhans]   Binary search step 7 of 10\n",
      "[DEBUG 2018-10-25 20:00:45,217 cleverhans]     Iteration 0 of 500: loss=1.53e+07 l2=0\n",
      "[DEBUG 2018-10-25 20:00:45,217 cleverhans]     Failed to make progress; stop early\n",
      "[DEBUG 2018-10-25 20:00:45,228 cleverhans]   Successfully generated adversarial examples on 982 of 1000 instances.\n",
      "[DEBUG 2018-10-25 20:00:45,229 cleverhans]    Mean successful distortion: 1.245\n",
      "[DEBUG 2018-10-25 20:00:45,230 cleverhans]   Binary search step 8 of 10\n",
      "[DEBUG 2018-10-25 20:00:45,254 cleverhans]     Iteration 0 of 500: loss=1.53e+08 l2=0\n",
      "[DEBUG 2018-10-25 20:00:45,254 cleverhans]     Failed to make progress; stop early\n",
      "[DEBUG 2018-10-25 20:00:45,266 cleverhans]   Successfully generated adversarial examples on 982 of 1000 instances.\n",
      "[DEBUG 2018-10-25 20:00:45,267 cleverhans]    Mean successful distortion: 1.245\n",
      "[DEBUG 2018-10-25 20:00:45,269 cleverhans]   Binary search step 9 of 10\n",
      "[DEBUG 2018-10-25 20:00:45,294 cleverhans]     Iteration 0 of 500: loss=1.53e+09 l2=0\n",
      "[DEBUG 2018-10-25 20:00:45,295 cleverhans]     Failed to make progress; stop early\n",
      "[DEBUG 2018-10-25 20:00:45,311 cleverhans]   Successfully generated adversarial examples on 982 of 1000 instances.\n",
      "[DEBUG 2018-10-25 20:00:45,312 cleverhans]    Mean successful distortion: 1.245\n"
     ]
    }
   ],
   "source": [
    "keras.backend.set_learning_phase(0)\n",
    "set_log_level(logging.DEBUG)\n",
    "\n",
    "# CarliniWagner attack\n",
    "from lib.my_cw import CarliniWagnerL2\n",
    "\n",
    "attack_iterations = 500\n",
    "cw_params = {'binary_search_steps': 10,\n",
    "             'max_iterations': attack_iterations,\n",
    "             'learning_rate': 0.1,\n",
    "             'batch_size': n_attack,\n",
    "             'initial_const': 10}\n",
    "cw = CarliniWagnerL2(hingenet, sess=sess)\n",
    "adv = cw.generate_np(X_atk, **cw_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from hinge_net import HingeNet\n",
    "\n",
    "hingenet = HingeNet(\"softmax_xent\", [28, 28, 1], [10], learning_rate=1e-3, \n",
    "                    loss=\"xent\", load_model=True, save_path=\"model/softmax_xent.h5\")\n",
    "# hingenet.train_model(sess, data, n_epoch=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.993, 0.02630199917015052)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hingenet.eval_model(sess, (X_test[:, :, :, np.newaxis], np.argmax(y_test, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Least likeley class\n",
    "n_attack = 1000\n",
    "X_atk = X_test[:, :, :, np.newaxis][:n_attack]\n",
    "y_atk = np.argmax(y_test[:n_attack], axis=1)\n",
    "\n",
    "y_pred = hingenet.predict_model(sess, X_atk)\n",
    "y_target = to_categorical(np.argmin(y_pred, axis=1))\n",
    "# y_target = to_categorical((np.argmax(y_pred, axis=1) + 1) % 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.993, 0.01569840869307518)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hingenet.eval_model(sess, (X_atk, y_atk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# softmax_xent\n",
    "\n",
    "keras.backend.set_learning_phase(0)\n",
    "set_log_level(logging.DEBUG)\n",
    "\n",
    "from lib.my_pgd import ProjectedGradientDescent\n",
    "\n",
    "pgd_params = {'eps': 0.3,\n",
    "              'eps_iter': 0.05,\n",
    "              'clip_min': 0.,\n",
    "              'clip_max': 1.,\n",
    "              'ord': np.inf, \n",
    "              'nb_iter': 10,\n",
    "              'rand_init': True,\n",
    "              'batch_size': 100,\n",
    "              'y_target': y_target}\n",
    "pgd = ProjectedGradientDescent(hingenet, sess=sess)\n",
    "\n",
    "y_tar = np.argmax(y_target, axis=1)\n",
    "best_adv = np.zeros_like(X_atk)\n",
    "best_dist = np.zeros([n_attack]) + 1e5\n",
    "for i in range(10):\n",
    "    adv = pgd.generate_np(X_atk, **pgd_params)\n",
    "    print(hingenet.eval_model(sess, (adv, y_tar)))\n",
    "    dist = np.sqrt(np.sum((adv - X_atk)**2, (1, 2, 3)))\n",
    "    print(np.mean(dist))\n",
    "    pred = hingenet.predict_model(sess, adv)\n",
    "    y_pred = np.argmax(pred, axis=1)\n",
    "    for j in range(n_attack):\n",
    "        if y_pred[j] == y_tar[j] and dist[j] < best_dist[j]:\n",
    "            best_adv[j] = adv[j]\n",
    "            best_dist[j] = dist[j]\n",
    "print(np.mean(best_dist < 1e5))\n",
    "print(np.mean(best_dist[best_dist < 1e5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax_xent (untargeted)\n",
    "\n",
    "keras.backend.set_learning_phase(0)\n",
    "set_log_level(logging.DEBUG)\n",
    "\n",
    "from lib.my_pgd import ProjectedGradientDescent\n",
    "\n",
    "pgd_params = {'eps': 0.3,\n",
    "              'eps_iter': 0.05,\n",
    "              'clip_min': 0.,\n",
    "              'clip_max': 1.,\n",
    "              'ord': np.inf, \n",
    "              'nb_iter': 10,\n",
    "              'rand_init': True,\n",
    "              'batch_size': 100}\n",
    "pgd = ProjectedGradientDescent(hingenet, sess=sess)\n",
    "\n",
    "y_tar = np.argmax(y_target, axis=1)\n",
    "best_adv = np.zeros_like(X_atk)\n",
    "best_dist = np.zeros([n_attack]) + 1e5\n",
    "for i in range(10):\n",
    "    adv = pgd.generate_np(X_atk, **pgd_params)\n",
    "    print(hingenet.eval_model(sess, (adv, y_tar)))\n",
    "    dist = np.sqrt(np.sum((adv - X_atk)**2, (1, 2, 3)))\n",
    "    print(np.mean(dist))\n",
    "    pred = hingenet.predict_model(sess, adv)\n",
    "    y_pred = np.argmax(pred, axis=1)\n",
    "    for j in range(n_attack):\n",
    "        if y_pred[j] == y_tar[j] and dist[j] < best_dist[j]:\n",
    "            best_adv[j] = adv[j]\n",
    "            best_dist[j] = dist[j]\n",
    "print(np.mean(best_dist < 1e5))\n",
    "print(np.mean(best_dist[best_dist < 1e5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2018-10-25 00:06:30,614 cleverhans] Constructing new graph for attack CarliniWagnerL2\n",
      "[DEBUG 2018-10-25 00:06:30,879 cleverhans] Running CWL2 attack on instance 0 of 1000\n",
      "[DEBUG 2018-10-25 00:06:30,979 cleverhans]   Binary search step 0 of 10\n",
      "[DEBUG 2018-10-25 00:06:31,139 cleverhans]     Iteration 0 of 500: loss=38.1 l2=0\n",
      "[DEBUG 2018-10-25 00:06:32,926 cleverhans]     Iteration 50 of 500: loss=11.4 l2=8.99\n",
      "[DEBUG 2018-10-25 00:06:34,610 cleverhans]     Iteration 100 of 500: loss=10.4 l2=8.35\n",
      "[DEBUG 2018-10-25 00:06:36,213 cleverhans]     Iteration 150 of 500: loss=9.76 l2=8.31\n",
      "[DEBUG 2018-10-25 00:06:37,821 cleverhans]     Iteration 200 of 500: loss=8.87 l2=7.95\n",
      "[DEBUG 2018-10-25 00:06:39,422 cleverhans]     Iteration 250 of 500: loss=8.07 l2=7.46\n",
      "[DEBUG 2018-10-25 00:06:40,976 cleverhans]     Iteration 300 of 500: loss=7.48 l2=7\n",
      "[DEBUG 2018-10-25 00:06:42,500 cleverhans]     Iteration 350 of 500: loss=7.03 l2=6.66\n",
      "[DEBUG 2018-10-25 00:06:43,985 cleverhans]     Iteration 400 of 500: loss=6.7 l2=6.39\n",
      "[DEBUG 2018-10-25 00:06:45,421 cleverhans]     Iteration 450 of 500: loss=6.45 l2=6.18\n",
      "[DEBUG 2018-10-25 00:06:46,808 cleverhans]   Successfully generated adversarial examples on 879 of 1000 instances.\n",
      "[DEBUG 2018-10-25 00:06:46,809 cleverhans]    Mean successful distortion: 2.398\n",
      "[DEBUG 2018-10-25 00:06:46,810 cleverhans]   Binary search step 1 of 10\n",
      "[DEBUG 2018-10-25 00:06:46,830 cleverhans]     Iteration 0 of 500: loss=61.6 l2=0\n",
      "[DEBUG 2018-10-25 00:06:48,570 cleverhans]     Iteration 50 of 500: loss=13.3 l2=8.27\n",
      "[DEBUG 2018-10-25 00:06:50,284 cleverhans]     Iteration 100 of 500: loss=10.1 l2=7.64\n",
      "[DEBUG 2018-10-25 00:06:51,928 cleverhans]     Iteration 150 of 500: loss=9.54 l2=7.22\n",
      "[DEBUG 2018-10-25 00:06:53,555 cleverhans]     Iteration 200 of 500: loss=8.96 l2=6.93\n",
      "[DEBUG 2018-10-25 00:06:55,186 cleverhans]     Iteration 250 of 500: loss=8.3 l2=6.67\n",
      "[DEBUG 2018-10-25 00:06:56,750 cleverhans]     Iteration 300 of 500: loss=7.74 l2=6.4\n",
      "[DEBUG 2018-10-25 00:06:58,398 cleverhans]     Iteration 350 of 500: loss=7.28 l2=6.16\n",
      "[DEBUG 2018-10-25 00:07:00,057 cleverhans]     Iteration 400 of 500: loss=6.94 l2=6\n",
      "[DEBUG 2018-10-25 00:07:01,731 cleverhans]     Iteration 450 of 500: loss=6.68 l2=5.87\n",
      "[DEBUG 2018-10-25 00:07:03,365 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 00:07:03,366 cleverhans]    Mean successful distortion: 2.462\n",
      "[DEBUG 2018-10-25 00:07:03,368 cleverhans]   Binary search step 2 of 10\n",
      "[DEBUG 2018-10-25 00:07:03,386 cleverhans]     Iteration 0 of 500: loss=42.1 l2=0\n",
      "[DEBUG 2018-10-25 00:07:05,122 cleverhans]     Iteration 50 of 500: loss=11.8 l2=7.57\n",
      "[DEBUG 2018-10-25 00:07:06,803 cleverhans]     Iteration 100 of 500: loss=9.86 l2=7.03\n",
      "[DEBUG 2018-10-25 00:07:08,432 cleverhans]     Iteration 150 of 500: loss=9.25 l2=6.74\n",
      "[DEBUG 2018-10-25 00:07:10,094 cleverhans]     Iteration 200 of 500: loss=8.6 l2=6.45\n",
      "[DEBUG 2018-10-25 00:07:11,755 cleverhans]     Iteration 250 of 500: loss=8 l2=6.17\n",
      "[DEBUG 2018-10-25 00:07:13,375 cleverhans]     Iteration 300 of 500: loss=7.51 l2=5.97\n",
      "[DEBUG 2018-10-25 00:07:15,024 cleverhans]     Iteration 350 of 500: loss=7.1 l2=5.8\n",
      "[DEBUG 2018-10-25 00:07:16,678 cleverhans]     Iteration 400 of 500: loss=6.77 l2=5.65\n",
      "[DEBUG 2018-10-25 00:07:18,324 cleverhans]     Iteration 450 of 500: loss=6.51 l2=5.54\n",
      "[DEBUG 2018-10-25 00:07:19,993 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 00:07:19,994 cleverhans]    Mean successful distortion: 2.437\n",
      "[DEBUG 2018-10-25 00:07:19,995 cleverhans]   Binary search step 3 of 10\n",
      "[DEBUG 2018-10-25 00:07:20,013 cleverhans]     Iteration 0 of 500: loss=32.2 l2=0\n",
      "[DEBUG 2018-10-25 00:07:21,684 cleverhans]     Iteration 50 of 500: loss=11 l2=7.28\n",
      "[DEBUG 2018-10-25 00:07:23,356 cleverhans]     Iteration 100 of 500: loss=9.84 l2=6.86\n",
      "[DEBUG 2018-10-25 00:07:24,981 cleverhans]     Iteration 150 of 500: loss=9.27 l2=6.75\n",
      "[DEBUG 2018-10-25 00:07:26,598 cleverhans]     Iteration 200 of 500: loss=8.68 l2=6.55\n",
      "[DEBUG 2018-10-25 00:07:28,235 cleverhans]     Iteration 250 of 500: loss=8.07 l2=6.32\n",
      "[DEBUG 2018-10-25 00:07:29,856 cleverhans]     Iteration 300 of 500: loss=7.53 l2=6.13\n",
      "[DEBUG 2018-10-25 00:07:31,510 cleverhans]     Iteration 350 of 500: loss=7.1 l2=5.95\n",
      "[DEBUG 2018-10-25 00:07:33,175 cleverhans]     Iteration 400 of 500: loss=6.76 l2=5.81\n",
      "[DEBUG 2018-10-25 00:07:34,875 cleverhans]     Iteration 450 of 500: loss=6.47 l2=5.7\n",
      "[DEBUG 2018-10-25 00:07:36,552 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 00:07:36,553 cleverhans]    Mean successful distortion: 2.424\n",
      "[DEBUG 2018-10-25 00:07:36,554 cleverhans]   Binary search step 4 of 10\n",
      "[DEBUG 2018-10-25 00:07:36,572 cleverhans]     Iteration 0 of 500: loss=27.4 l2=0\n",
      "[DEBUG 2018-10-25 00:07:38,287 cleverhans]     Iteration 50 of 500: loss=10.5 l2=7\n",
      "[DEBUG 2018-10-25 00:07:39,915 cleverhans]     Iteration 100 of 500: loss=9.79 l2=6.75\n",
      "[DEBUG 2018-10-25 00:07:41,587 cleverhans]     Iteration 150 of 500: loss=9.29 l2=6.74\n",
      "[DEBUG 2018-10-25 00:07:43,253 cleverhans]     Iteration 200 of 500: loss=8.73 l2=6.61\n",
      "[DEBUG 2018-10-25 00:07:44,911 cleverhans]     Iteration 250 of 500: loss=8.09 l2=6.4\n",
      "[DEBUG 2018-10-25 00:07:46,570 cleverhans]     Iteration 300 of 500: loss=7.55 l2=6.2\n",
      "[DEBUG 2018-10-25 00:07:48,192 cleverhans]     Iteration 350 of 500: loss=7.11 l2=6.07\n",
      "[DEBUG 2018-10-25 00:07:49,850 cleverhans]     Iteration 400 of 500: loss=6.75 l2=5.96\n",
      "[DEBUG 2018-10-25 00:07:51,501 cleverhans]     Iteration 450 of 500: loss=6.46 l2=5.84\n",
      "[DEBUG 2018-10-25 00:07:53,195 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 00:07:53,196 cleverhans]    Mean successful distortion: 2.417\n",
      "[DEBUG 2018-10-25 00:07:53,198 cleverhans]   Binary search step 5 of 10\n",
      "[DEBUG 2018-10-25 00:07:53,217 cleverhans]     Iteration 0 of 500: loss=25.1 l2=0\n",
      "[DEBUG 2018-10-25 00:07:54,928 cleverhans]     Iteration 50 of 500: loss=10.2 l2=6.77\n",
      "[DEBUG 2018-10-25 00:07:56,571 cleverhans]     Iteration 100 of 500: loss=9.66 l2=6.57\n",
      "[DEBUG 2018-10-25 00:07:58,230 cleverhans]     Iteration 150 of 500: loss=9.27 l2=6.59\n",
      "[DEBUG 2018-10-25 00:07:59,875 cleverhans]     Iteration 200 of 500: loss=8.72 l2=6.52\n",
      "[DEBUG 2018-10-25 00:08:01,519 cleverhans]     Iteration 250 of 500: loss=8.09 l2=6.32\n",
      "[DEBUG 2018-10-25 00:08:03,190 cleverhans]     Iteration 300 of 500: loss=7.56 l2=6.18\n",
      "[DEBUG 2018-10-25 00:08:04,855 cleverhans]     Iteration 350 of 500: loss=7.11 l2=6.06\n",
      "[DEBUG 2018-10-25 00:08:06,523 cleverhans]     Iteration 400 of 500: loss=6.76 l2=5.96\n",
      "[DEBUG 2018-10-25 00:08:08,238 cleverhans]     Iteration 450 of 500: loss=6.47 l2=5.87\n",
      "[DEBUG 2018-10-25 00:08:09,903 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 00:08:09,904 cleverhans]    Mean successful distortion: 2.412\n",
      "[DEBUG 2018-10-25 00:08:09,906 cleverhans]   Binary search step 6 of 10\n",
      "[DEBUG 2018-10-25 00:08:09,924 cleverhans]     Iteration 0 of 500: loss=24.2 l2=0\n",
      "[DEBUG 2018-10-25 00:08:11,619 cleverhans]     Iteration 50 of 500: loss=10.1 l2=6.64\n",
      "[DEBUG 2018-10-25 00:08:13,268 cleverhans]     Iteration 100 of 500: loss=9.57 l2=6.45\n",
      "[DEBUG 2018-10-25 00:08:14,906 cleverhans]     Iteration 150 of 500: loss=9.27 l2=6.47\n",
      "[DEBUG 2018-10-25 00:08:16,559 cleverhans]     Iteration 200 of 500: loss=8.73 l2=6.41\n",
      "[DEBUG 2018-10-25 00:08:18,219 cleverhans]     Iteration 250 of 500: loss=8.1 l2=6.26\n",
      "[DEBUG 2018-10-25 00:08:19,897 cleverhans]     Iteration 300 of 500: loss=7.57 l2=6.1\n",
      "[DEBUG 2018-10-25 00:08:21,594 cleverhans]     Iteration 350 of 500: loss=7.12 l2=6.02\n",
      "[DEBUG 2018-10-25 00:08:23,259 cleverhans]     Iteration 400 of 500: loss=6.77 l2=5.94\n",
      "[DEBUG 2018-10-25 00:08:24,963 cleverhans]     Iteration 450 of 500: loss=6.46 l2=5.87\n",
      "[DEBUG 2018-10-25 00:08:26,645 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 00:08:26,646 cleverhans]    Mean successful distortion: 2.41\n",
      "[DEBUG 2018-10-25 00:08:26,648 cleverhans]   Binary search step 7 of 10\n",
      "[DEBUG 2018-10-25 00:08:26,666 cleverhans]     Iteration 0 of 500: loss=23.9 l2=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DEBUG 2018-10-25 00:08:28,376 cleverhans]     Iteration 50 of 500: loss=10.1 l2=6.6\n",
      "[DEBUG 2018-10-25 00:08:30,036 cleverhans]     Iteration 100 of 500: loss=9.55 l2=6.42\n",
      "[DEBUG 2018-10-25 00:08:31,673 cleverhans]     Iteration 150 of 500: loss=9.26 l2=6.44\n",
      "[DEBUG 2018-10-25 00:08:33,304 cleverhans]     Iteration 200 of 500: loss=8.72 l2=6.38\n",
      "[DEBUG 2018-10-25 00:08:34,930 cleverhans]     Iteration 250 of 500: loss=8.09 l2=6.24\n",
      "[DEBUG 2018-10-25 00:08:36,561 cleverhans]     Iteration 300 of 500: loss=7.57 l2=6.1\n",
      "[DEBUG 2018-10-25 00:08:38,212 cleverhans]     Iteration 350 of 500: loss=7.14 l2=6\n",
      "[DEBUG 2018-10-25 00:08:39,877 cleverhans]     Iteration 400 of 500: loss=6.77 l2=5.95\n",
      "[DEBUG 2018-10-25 00:08:41,571 cleverhans]     Iteration 450 of 500: loss=6.47 l2=5.89\n",
      "[DEBUG 2018-10-25 00:08:43,241 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 00:08:43,242 cleverhans]    Mean successful distortion: 2.409\n",
      "[DEBUG 2018-10-25 00:08:43,243 cleverhans]   Binary search step 8 of 10\n",
      "[DEBUG 2018-10-25 00:08:43,261 cleverhans]     Iteration 0 of 500: loss=23.8 l2=0\n",
      "[DEBUG 2018-10-25 00:08:44,996 cleverhans]     Iteration 50 of 500: loss=10 l2=6.58\n",
      "[DEBUG 2018-10-25 00:08:46,661 cleverhans]     Iteration 100 of 500: loss=9.54 l2=6.42\n",
      "[DEBUG 2018-10-25 00:08:48,345 cleverhans]     Iteration 150 of 500: loss=9.25 l2=6.43\n",
      "[DEBUG 2018-10-25 00:08:49,973 cleverhans]     Iteration 200 of 500: loss=8.72 l2=6.39\n",
      "[DEBUG 2018-10-25 00:08:51,659 cleverhans]     Iteration 250 of 500: loss=8.09 l2=6.23\n",
      "[DEBUG 2018-10-25 00:08:53,320 cleverhans]     Iteration 300 of 500: loss=7.57 l2=6.09\n",
      "[DEBUG 2018-10-25 00:08:54,998 cleverhans]     Iteration 350 of 500: loss=7.12 l2=6\n",
      "[DEBUG 2018-10-25 00:08:56,685 cleverhans]     Iteration 400 of 500: loss=6.76 l2=5.93\n",
      "[DEBUG 2018-10-25 00:08:58,367 cleverhans]     Iteration 450 of 500: loss=6.45 l2=5.89\n",
      "[DEBUG 2018-10-25 00:09:00,048 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 00:09:00,049 cleverhans]    Mean successful distortion: 2.408\n",
      "[DEBUG 2018-10-25 00:09:00,051 cleverhans]   Binary search step 9 of 10\n",
      "[DEBUG 2018-10-25 00:09:00,069 cleverhans]     Iteration 0 of 500: loss=24 l2=0\n",
      "[DEBUG 2018-10-25 00:09:01,760 cleverhans]     Iteration 50 of 500: loss=10.1 l2=6.65\n",
      "[DEBUG 2018-10-25 00:09:03,395 cleverhans]     Iteration 100 of 500: loss=9.55 l2=6.49\n",
      "[DEBUG 2018-10-25 00:09:05,045 cleverhans]     Iteration 150 of 500: loss=9.26 l2=6.51\n",
      "[DEBUG 2018-10-25 00:09:06,689 cleverhans]     Iteration 200 of 500: loss=8.72 l2=6.46\n",
      "[DEBUG 2018-10-25 00:09:08,345 cleverhans]     Iteration 250 of 500: loss=8.09 l2=6.3\n",
      "[DEBUG 2018-10-25 00:09:10,013 cleverhans]     Iteration 300 of 500: loss=7.55 l2=6.17\n",
      "[DEBUG 2018-10-25 00:09:11,655 cleverhans]     Iteration 350 of 500: loss=7.1 l2=6.08\n",
      "[DEBUG 2018-10-25 00:09:13,302 cleverhans]     Iteration 400 of 500: loss=6.73 l2=6.02\n",
      "[DEBUG 2018-10-25 00:09:14,977 cleverhans]     Iteration 450 of 500: loss=6.42 l2=5.97\n",
      "[DEBUG 2018-10-25 00:09:16,611 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 00:09:16,612 cleverhans]    Mean successful distortion: 2.408\n"
     ]
    }
   ],
   "source": [
    "keras.backend.set_learning_phase(0)\n",
    "set_log_level(logging.DEBUG)\n",
    "\n",
    "# CarliniWagner attack\n",
    "from lib.my_cw import CarliniWagnerL2\n",
    "\n",
    "attack_iterations = 500\n",
    "cw_params = {'binary_search_steps': 10,\n",
    "             'max_iterations': attack_iterations,\n",
    "             'learning_rate': 0.1,\n",
    "             'batch_size': n_attack,\n",
    "             'initial_const': 1,\n",
    "             'y_target': y_target}\n",
    "cw = CarliniWagnerL2(hingenet, sess=sess)\n",
    "adv = cw.generate_np(X_atk, **cw_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = np.sqrt(np.sum((X_atk - adv)**2, (1, 2, 3)))\n",
    "plt.hist(dist)\n",
    "print(np.min(dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2018-10-25 00:17:49,337 cleverhans] Constructing new graph for attack CarliniWagnerL2\n",
      "[DEBUG 2018-10-25 00:17:49,713 cleverhans] Running CWL2 attack on instance 0 of 1000\n",
      "[DEBUG 2018-10-25 00:17:49,821 cleverhans]   Binary search step 0 of 10\n",
      "[DEBUG 2018-10-25 00:17:50,002 cleverhans]     Iteration 0 of 1000: loss=38.1 l2=0\n",
      "[DEBUG 2018-10-25 00:17:53,482 cleverhans]     Iteration 100 of 1000: loss=10.4 l2=8.35\n",
      "[DEBUG 2018-10-25 00:17:56,757 cleverhans]     Iteration 200 of 1000: loss=8.87 l2=7.95\n",
      "[DEBUG 2018-10-25 00:17:59,911 cleverhans]     Iteration 300 of 1000: loss=7.47 l2=7\n",
      "[DEBUG 2018-10-25 00:18:02,890 cleverhans]     Iteration 400 of 1000: loss=6.7 l2=6.4\n",
      "[DEBUG 2018-10-25 00:18:05,710 cleverhans]     Iteration 500 of 1000: loss=6.26 l2=6\n",
      "[DEBUG 2018-10-25 00:18:08,418 cleverhans]     Iteration 600 of 1000: loss=5.96 l2=5.75\n",
      "[DEBUG 2018-10-25 00:18:11,049 cleverhans]     Iteration 700 of 1000: loss=5.77 l2=5.6\n",
      "[DEBUG 2018-10-25 00:18:13,672 cleverhans]     Iteration 800 of 1000: loss=5.64 l2=5.46\n",
      "[DEBUG 2018-10-25 00:18:16,220 cleverhans]     Iteration 900 of 1000: loss=5.53 l2=5.36\n",
      "[DEBUG 2018-10-25 00:18:18,724 cleverhans]   Successfully generated adversarial examples on 961 of 1000 instances.\n",
      "[DEBUG 2018-10-25 00:18:18,725 cleverhans]    Mean successful distortion: 2.241\n",
      "[DEBUG 2018-10-25 00:18:18,726 cleverhans]   Binary search step 1 of 10\n",
      "[DEBUG 2018-10-25 00:18:18,746 cleverhans]     Iteration 0 of 1000: loss=33.3 l2=0\n",
      "[DEBUG 2018-10-25 00:18:22,010 cleverhans]     Iteration 100 of 1000: loss=9.19 l2=6.43\n",
      "[DEBUG 2018-10-25 00:18:25,199 cleverhans]     Iteration 200 of 1000: loss=8.53 l2=6.18\n",
      "[DEBUG 2018-10-25 00:18:28,355 cleverhans]     Iteration 300 of 1000: loss=7.4 l2=5.84\n",
      "[DEBUG 2018-10-25 00:18:31,526 cleverhans]     Iteration 400 of 1000: loss=6.67 l2=5.57\n",
      "[DEBUG 2018-10-25 00:18:34,748 cleverhans]     Iteration 500 of 1000: loss=6.22 l2=5.36\n",
      "[DEBUG 2018-10-25 00:18:37,850 cleverhans]     Iteration 600 of 1000: loss=5.91 l2=5.23\n",
      "[DEBUG 2018-10-25 00:18:40,965 cleverhans]     Iteration 700 of 1000: loss=5.69 l2=5.11\n",
      "[DEBUG 2018-10-25 00:18:44,170 cleverhans]     Iteration 800 of 1000: loss=5.55 l2=5.04\n",
      "[DEBUG 2018-10-25 00:18:47,381 cleverhans]     Iteration 900 of 1000: loss=5.44 l2=4.99\n",
      "[DEBUG 2018-10-25 00:18:50,585 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 00:18:50,586 cleverhans]    Mean successful distortion: 2.253\n",
      "[DEBUG 2018-10-25 00:18:50,587 cleverhans]   Binary search step 2 of 10\n",
      "[DEBUG 2018-10-25 00:18:50,606 cleverhans]     Iteration 0 of 1000: loss=23.9 l2=0\n",
      "[DEBUG 2018-10-25 00:18:54,036 cleverhans]     Iteration 100 of 1000: loss=8.48 l2=5.12\n",
      "[DEBUG 2018-10-25 00:18:57,414 cleverhans]     Iteration 200 of 1000: loss=7.83 l2=4.92\n",
      "[DEBUG 2018-10-25 00:19:00,780 cleverhans]     Iteration 300 of 1000: loss=7.06 l2=4.73\n",
      "[DEBUG 2018-10-25 00:19:04,151 cleverhans]     Iteration 400 of 1000: loss=6.46 l2=4.63\n",
      "[DEBUG 2018-10-25 00:19:07,496 cleverhans]     Iteration 500 of 1000: loss=6.05 l2=4.56\n",
      "[DEBUG 2018-10-25 00:19:10,846 cleverhans]     Iteration 600 of 1000: loss=5.78 l2=4.52\n",
      "[DEBUG 2018-10-25 00:19:14,168 cleverhans]     Iteration 700 of 1000: loss=5.58 l2=4.47\n",
      "[DEBUG 2018-10-25 00:19:17,569 cleverhans]     Iteration 800 of 1000: loss=5.44 l2=4.44\n",
      "[DEBUG 2018-10-25 00:19:20,968 cleverhans]     Iteration 900 of 1000: loss=5.33 l2=4.43\n",
      "[DEBUG 2018-10-25 00:19:24,311 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 00:19:24,312 cleverhans]    Mean successful distortion: 2.242\n",
      "[DEBUG 2018-10-25 00:19:24,314 cleverhans]   Binary search step 3 of 10\n",
      "[DEBUG 2018-10-25 00:19:24,333 cleverhans]     Iteration 0 of 1000: loss=21.4 l2=0\n",
      "[DEBUG 2018-10-25 00:19:27,726 cleverhans]     Iteration 100 of 1000: loss=8.75 l2=5.34\n",
      "[DEBUG 2018-10-25 00:19:31,106 cleverhans]     Iteration 200 of 1000: loss=8.14 l2=5.27\n",
      "[DEBUG 2018-10-25 00:19:34,524 cleverhans]     Iteration 300 of 1000: loss=7.22 l2=5.09\n",
      "[DEBUG 2018-10-25 00:19:37,832 cleverhans]     Iteration 400 of 1000: loss=6.57 l2=4.94\n",
      "[DEBUG 2018-10-25 00:19:41,190 cleverhans]     Iteration 500 of 1000: loss=6.14 l2=4.86\n",
      "[DEBUG 2018-10-25 00:19:44,542 cleverhans]     Iteration 600 of 1000: loss=5.84 l2=4.79\n",
      "[DEBUG 2018-10-25 00:19:47,897 cleverhans]     Iteration 700 of 1000: loss=5.62 l2=4.76\n",
      "[DEBUG 2018-10-25 00:19:51,296 cleverhans]     Iteration 800 of 1000: loss=5.47 l2=4.71\n",
      "[DEBUG 2018-10-25 00:19:54,653 cleverhans]     Iteration 900 of 1000: loss=5.35 l2=4.68\n",
      "[DEBUG 2018-10-25 00:19:58,009 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 00:19:58,010 cleverhans]    Mean successful distortion: 2.235\n",
      "[DEBUG 2018-10-25 00:19:58,011 cleverhans]   Binary search step 4 of 10\n",
      "[DEBUG 2018-10-25 00:19:58,029 cleverhans]     Iteration 0 of 1000: loss=19.7 l2=0\n",
      "[DEBUG 2018-10-25 00:20:01,368 cleverhans]     Iteration 100 of 1000: loss=8.75 l2=5.37\n",
      "[DEBUG 2018-10-25 00:20:04,681 cleverhans]     Iteration 200 of 1000: loss=8.22 l2=5.35\n",
      "[DEBUG 2018-10-25 00:20:08,040 cleverhans]     Iteration 300 of 1000: loss=7.32 l2=5.17\n",
      "[DEBUG 2018-10-25 00:20:11,375 cleverhans]     Iteration 400 of 1000: loss=6.66 l2=5.06\n",
      "[DEBUG 2018-10-25 00:20:14,738 cleverhans]     Iteration 500 of 1000: loss=6.21 l2=4.98\n",
      "[DEBUG 2018-10-25 00:20:18,134 cleverhans]     Iteration 600 of 1000: loss=5.9 l2=4.96\n",
      "[DEBUG 2018-10-25 00:20:21,475 cleverhans]     Iteration 700 of 1000: loss=5.68 l2=4.93\n",
      "[DEBUG 2018-10-25 00:20:24,859 cleverhans]     Iteration 800 of 1000: loss=5.51 l2=4.9\n",
      "[DEBUG 2018-10-25 00:20:28,232 cleverhans]     Iteration 900 of 1000: loss=5.39 l2=4.86\n",
      "[DEBUG 2018-10-25 00:20:31,587 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 00:20:31,588 cleverhans]    Mean successful distortion: 2.231\n",
      "[DEBUG 2018-10-25 00:20:31,589 cleverhans]   Binary search step 5 of 10\n",
      "[DEBUG 2018-10-25 00:20:31,608 cleverhans]     Iteration 0 of 1000: loss=18.9 l2=0\n",
      "[DEBUG 2018-10-25 00:20:35,011 cleverhans]     Iteration 100 of 1000: loss=8.73 l2=5.31\n",
      "[DEBUG 2018-10-25 00:20:38,361 cleverhans]     Iteration 200 of 1000: loss=8.24 l2=5.3\n",
      "[DEBUG 2018-10-25 00:20:41,666 cleverhans]     Iteration 300 of 1000: loss=7.33 l2=5.15\n",
      "[DEBUG 2018-10-25 00:20:45,020 cleverhans]     Iteration 400 of 1000: loss=6.68 l2=5.04\n",
      "[DEBUG 2018-10-25 00:20:48,390 cleverhans]     Iteration 500 of 1000: loss=6.23 l2=5\n",
      "[DEBUG 2018-10-25 00:20:51,729 cleverhans]     Iteration 600 of 1000: loss=5.91 l2=4.97\n",
      "[DEBUG 2018-10-25 00:20:55,136 cleverhans]     Iteration 700 of 1000: loss=5.69 l2=4.96\n",
      "[DEBUG 2018-10-25 00:20:58,524 cleverhans]     Iteration 800 of 1000: loss=5.52 l2=4.93\n",
      "[DEBUG 2018-10-25 00:21:01,933 cleverhans]     Iteration 900 of 1000: loss=5.38 l2=4.92\n",
      "[DEBUG 2018-10-25 00:21:05,263 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 00:21:05,264 cleverhans]    Mean successful distortion: 2.228\n",
      "[DEBUG 2018-10-25 00:21:05,266 cleverhans]   Binary search step 6 of 10\n",
      "[DEBUG 2018-10-25 00:21:05,286 cleverhans]     Iteration 0 of 1000: loss=18.5 l2=0\n",
      "[DEBUG 2018-10-25 00:21:08,640 cleverhans]     Iteration 100 of 1000: loss=8.7 l2=5.27\n",
      "[DEBUG 2018-10-25 00:21:12,059 cleverhans]     Iteration 200 of 1000: loss=8.24 l2=5.28\n",
      "[DEBUG 2018-10-25 00:21:15,382 cleverhans]     Iteration 300 of 1000: loss=7.34 l2=5.12\n",
      "[DEBUG 2018-10-25 00:21:18,768 cleverhans]     Iteration 400 of 1000: loss=6.68 l2=5.04\n",
      "[DEBUG 2018-10-25 00:21:22,119 cleverhans]     Iteration 500 of 1000: loss=6.24 l2=5\n",
      "[DEBUG 2018-10-25 00:21:25,537 cleverhans]     Iteration 600 of 1000: loss=5.92 l2=4.98\n",
      "[DEBUG 2018-10-25 00:21:28,941 cleverhans]     Iteration 700 of 1000: loss=5.69 l2=4.97\n",
      "[DEBUG 2018-10-25 00:21:32,321 cleverhans]     Iteration 800 of 1000: loss=5.52 l2=4.96\n",
      "[DEBUG 2018-10-25 00:21:35,713 cleverhans]     Iteration 900 of 1000: loss=5.39 l2=4.95\n",
      "[DEBUG 2018-10-25 00:21:39,079 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 00:21:39,081 cleverhans]    Mean successful distortion: 2.227\n",
      "[DEBUG 2018-10-25 00:21:39,082 cleverhans]   Binary search step 7 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DEBUG 2018-10-25 00:21:39,101 cleverhans]     Iteration 0 of 1000: loss=18.4 l2=0\n",
      "[DEBUG 2018-10-25 00:21:42,548 cleverhans]     Iteration 100 of 1000: loss=8.7 l2=5.25\n",
      "[DEBUG 2018-10-25 00:21:45,885 cleverhans]     Iteration 200 of 1000: loss=8.24 l2=5.26\n",
      "[DEBUG 2018-10-25 00:21:49,216 cleverhans]     Iteration 300 of 1000: loss=7.34 l2=5.11\n",
      "[DEBUG 2018-10-25 00:21:52,581 cleverhans]     Iteration 400 of 1000: loss=6.68 l2=5.03\n",
      "[DEBUG 2018-10-25 00:21:55,967 cleverhans]     Iteration 500 of 1000: loss=6.24 l2=4.99\n",
      "[DEBUG 2018-10-25 00:21:59,287 cleverhans]     Iteration 600 of 1000: loss=5.92 l2=4.98\n",
      "[DEBUG 2018-10-25 00:22:02,642 cleverhans]     Iteration 700 of 1000: loss=5.69 l2=4.97\n",
      "[DEBUG 2018-10-25 00:22:06,007 cleverhans]     Iteration 800 of 1000: loss=5.52 l2=4.97\n",
      "[DEBUG 2018-10-25 00:22:09,394 cleverhans]     Iteration 900 of 1000: loss=5.39 l2=4.96\n",
      "[DEBUG 2018-10-25 00:22:12,759 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 00:22:12,760 cleverhans]    Mean successful distortion: 2.226\n",
      "[DEBUG 2018-10-25 00:22:12,761 cleverhans]   Binary search step 8 of 10\n",
      "[DEBUG 2018-10-25 00:22:12,779 cleverhans]     Iteration 0 of 1000: loss=18.3 l2=0\n",
      "[DEBUG 2018-10-25 00:22:16,212 cleverhans]     Iteration 100 of 1000: loss=8.69 l2=5.24\n",
      "[DEBUG 2018-10-25 00:22:19,591 cleverhans]     Iteration 200 of 1000: loss=8.23 l2=5.26\n",
      "[DEBUG 2018-10-25 00:22:22,976 cleverhans]     Iteration 300 of 1000: loss=7.34 l2=5.11\n",
      "[DEBUG 2018-10-25 00:22:26,312 cleverhans]     Iteration 400 of 1000: loss=6.69 l2=5.02\n",
      "[DEBUG 2018-10-25 00:22:29,661 cleverhans]     Iteration 500 of 1000: loss=6.24 l2=4.99\n",
      "[DEBUG 2018-10-25 00:22:33,045 cleverhans]     Iteration 600 of 1000: loss=5.93 l2=4.97\n",
      "[DEBUG 2018-10-25 00:22:36,475 cleverhans]     Iteration 700 of 1000: loss=5.7 l2=4.97\n",
      "[DEBUG 2018-10-25 00:22:39,971 cleverhans]     Iteration 800 of 1000: loss=5.52 l2=4.96\n",
      "[DEBUG 2018-10-25 00:22:43,451 cleverhans]     Iteration 900 of 1000: loss=5.38 l2=4.94\n",
      "[DEBUG 2018-10-25 00:22:46,824 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 00:22:46,825 cleverhans]    Mean successful distortion: 2.226\n",
      "[DEBUG 2018-10-25 00:22:46,827 cleverhans]   Binary search step 9 of 10\n",
      "[DEBUG 2018-10-25 00:22:46,845 cleverhans]     Iteration 0 of 1000: loss=18.4 l2=0\n",
      "[DEBUG 2018-10-25 00:22:50,263 cleverhans]     Iteration 100 of 1000: loss=8.71 l2=5.29\n",
      "[DEBUG 2018-10-25 00:22:53,585 cleverhans]     Iteration 200 of 1000: loss=8.24 l2=5.3\n",
      "[DEBUG 2018-10-25 00:22:56,954 cleverhans]     Iteration 300 of 1000: loss=7.34 l2=5.15\n",
      "[DEBUG 2018-10-25 00:23:00,276 cleverhans]     Iteration 400 of 1000: loss=6.68 l2=5.08\n",
      "[DEBUG 2018-10-25 00:23:03,658 cleverhans]     Iteration 500 of 1000: loss=6.23 l2=5.05\n",
      "[DEBUG 2018-10-25 00:23:07,017 cleverhans]     Iteration 600 of 1000: loss=5.92 l2=5.03\n",
      "[DEBUG 2018-10-25 00:23:10,425 cleverhans]     Iteration 700 of 1000: loss=5.67 l2=5.04\n",
      "[DEBUG 2018-10-25 00:23:13,786 cleverhans]     Iteration 800 of 1000: loss=5.49 l2=5.04\n",
      "[DEBUG 2018-10-25 00:23:17,171 cleverhans]     Iteration 900 of 1000: loss=5.36 l2=5.01\n",
      "[DEBUG 2018-10-25 00:23:20,413 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 00:23:20,414 cleverhans]    Mean successful distortion: 2.226\n"
     ]
    }
   ],
   "source": [
    "keras.backend.set_learning_phase(0)\n",
    "set_log_level(logging.DEBUG)\n",
    "\n",
    "# CarliniWagner attack\n",
    "from lib.my_cw import CarliniWagnerL2\n",
    "\n",
    "attack_iterations = 1000\n",
    "cw_params = {'binary_search_steps': 10,\n",
    "             'max_iterations': attack_iterations,\n",
    "             'learning_rate': 0.1,\n",
    "             'batch_size': n_attack,\n",
    "             'initial_const': 1,\n",
    "             'y_target': y_target}\n",
    "cw = CarliniWagnerL2(hingenet, sess=sess)\n",
    "adv = cw.generate_np(X_atk, **cw_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2018-10-25 04:11:13,405 cleverhans] Constructing new graph for attack CarliniWagnerL2\n",
      "[DEBUG 2018-10-25 04:11:13,931 cleverhans] Running CWL2 attack on instance 0 of 1000\n",
      "[DEBUG 2018-10-25 04:11:14,074 cleverhans]   Binary search step 0 of 10\n",
      "[DEBUG 2018-10-25 04:11:14,350 cleverhans]     Iteration 0 of 500: loss=16.5 l2=0\n",
      "[DEBUG 2018-10-25 04:11:15,990 cleverhans]     Iteration 50 of 500: loss=4.31 l2=3.79\n",
      "[DEBUG 2018-10-25 04:11:17,384 cleverhans]     Iteration 100 of 500: loss=4 l2=3.52\n",
      "[DEBUG 2018-10-25 04:11:18,700 cleverhans]     Iteration 150 of 500: loss=3.83 l2=3.46\n",
      "[DEBUG 2018-10-25 04:11:19,989 cleverhans]     Iteration 200 of 500: loss=3.54 l2=3.33\n",
      "[DEBUG 2018-10-25 04:11:21,266 cleverhans]     Iteration 250 of 500: loss=3.25 l2=3.11\n",
      "[DEBUG 2018-10-25 04:11:22,525 cleverhans]     Iteration 300 of 500: loss=3 l2=2.89\n",
      "[DEBUG 2018-10-25 04:11:23,749 cleverhans]     Iteration 350 of 500: loss=2.84 l2=2.73\n",
      "[DEBUG 2018-10-25 04:11:24,982 cleverhans]     Iteration 400 of 500: loss=2.7 l2=2.6\n",
      "[DEBUG 2018-10-25 04:11:26,198 cleverhans]     Iteration 450 of 500: loss=2.59 l2=2.5\n",
      "[DEBUG 2018-10-25 04:11:27,397 cleverhans]   Successfully generated adversarial examples on 996 of 1000 instances.\n",
      "[DEBUG 2018-10-25 04:11:27,398 cleverhans]    Mean successful distortion: 1.462\n",
      "[DEBUG 2018-10-25 04:11:27,400 cleverhans]   Binary search step 1 of 10\n",
      "[DEBUG 2018-10-25 04:11:27,416 cleverhans]     Iteration 0 of 500: loss=8.94 l2=0\n",
      "[DEBUG 2018-10-25 04:11:28,988 cleverhans]     Iteration 50 of 500: loss=3.79 l2=2.75\n",
      "[DEBUG 2018-10-25 04:11:30,455 cleverhans]     Iteration 100 of 500: loss=3.66 l2=2.68\n",
      "[DEBUG 2018-10-25 04:11:31,883 cleverhans]     Iteration 150 of 500: loss=3.59 l2=2.68\n",
      "[DEBUG 2018-10-25 04:11:33,294 cleverhans]     Iteration 200 of 500: loss=3.47 l2=2.68\n",
      "[DEBUG 2018-10-25 04:11:34,717 cleverhans]     Iteration 250 of 500: loss=3.25 l2=2.61\n",
      "[DEBUG 2018-10-25 04:11:36,121 cleverhans]     Iteration 300 of 500: loss=3.02 l2=2.54\n",
      "[DEBUG 2018-10-25 04:11:37,446 cleverhans]     Iteration 350 of 500: loss=2.83 l2=2.45\n",
      "[DEBUG 2018-10-25 04:11:38,842 cleverhans]     Iteration 400 of 500: loss=2.68 l2=2.37\n",
      "[DEBUG 2018-10-25 04:11:40,284 cleverhans]     Iteration 450 of 500: loss=2.56 l2=2.31\n",
      "[DEBUG 2018-10-25 04:11:41,757 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 04:11:41,758 cleverhans]    Mean successful distortion: 1.451\n",
      "[DEBUG 2018-10-25 04:11:41,760 cleverhans]   Binary search step 2 of 10\n",
      "[DEBUG 2018-10-25 04:11:41,777 cleverhans]     Iteration 0 of 500: loss=5.3 l2=0\n",
      "[DEBUG 2018-10-25 04:11:43,491 cleverhans]     Iteration 50 of 500: loss=3.17 l2=1.55\n",
      "[DEBUG 2018-10-25 04:11:45,165 cleverhans]     Iteration 100 of 500: loss=3.13 l2=1.54\n",
      "[DEBUG 2018-10-25 04:11:46,846 cleverhans]     Iteration 150 of 500: loss=3.1 l2=1.54\n",
      "[DEBUG 2018-10-25 04:11:48,548 cleverhans]     Iteration 200 of 500: loss=3.07 l2=1.55\n",
      "[DEBUG 2018-10-25 04:11:50,207 cleverhans]     Iteration 250 of 500: loss=2.99 l2=1.55\n",
      "[DEBUG 2018-10-25 04:11:51,871 cleverhans]     Iteration 300 of 500: loss=2.89 l2=1.57\n",
      "[DEBUG 2018-10-25 04:11:53,556 cleverhans]     Iteration 350 of 500: loss=2.79 l2=1.59\n",
      "[DEBUG 2018-10-25 04:11:55,208 cleverhans]     Iteration 400 of 500: loss=2.69 l2=1.61\n",
      "[DEBUG 2018-10-25 04:11:56,898 cleverhans]     Iteration 450 of 500: loss=2.59 l2=1.64\n",
      "[DEBUG 2018-10-25 04:11:58,577 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 04:11:58,578 cleverhans]    Mean successful distortion: 1.448\n",
      "[DEBUG 2018-10-25 04:11:58,580 cleverhans]   Binary search step 3 of 10\n",
      "[DEBUG 2018-10-25 04:11:58,597 cleverhans]     Iteration 0 of 500: loss=5.6 l2=0\n",
      "[DEBUG 2018-10-25 04:12:00,318 cleverhans]     Iteration 50 of 500: loss=3.35 l2=1.78\n",
      "[DEBUG 2018-10-25 04:12:02,007 cleverhans]     Iteration 100 of 500: loss=3.3 l2=1.77\n",
      "[DEBUG 2018-10-25 04:12:03,706 cleverhans]     Iteration 150 of 500: loss=3.29 l2=1.77\n",
      "[DEBUG 2018-10-25 04:12:05,386 cleverhans]     Iteration 200 of 500: loss=3.24 l2=1.78\n",
      "[DEBUG 2018-10-25 04:12:07,098 cleverhans]     Iteration 250 of 500: loss=3.12 l2=1.82\n",
      "[DEBUG 2018-10-25 04:12:08,758 cleverhans]     Iteration 300 of 500: loss=2.98 l2=1.85\n",
      "[DEBUG 2018-10-25 04:12:10,398 cleverhans]     Iteration 350 of 500: loss=2.82 l2=1.87\n",
      "[DEBUG 2018-10-25 04:12:12,036 cleverhans]     Iteration 400 of 500: loss=2.68 l2=1.88\n",
      "[DEBUG 2018-10-25 04:12:13,701 cleverhans]     Iteration 450 of 500: loss=2.56 l2=1.87\n",
      "[DEBUG 2018-10-25 04:12:15,321 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 04:12:15,322 cleverhans]    Mean successful distortion: 1.445\n",
      "[DEBUG 2018-10-25 04:12:15,323 cleverhans]   Binary search step 4 of 10\n",
      "[DEBUG 2018-10-25 04:12:15,340 cleverhans]     Iteration 0 of 500: loss=5.48 l2=0\n",
      "[DEBUG 2018-10-25 04:12:17,091 cleverhans]     Iteration 50 of 500: loss=3.41 l2=1.77\n",
      "[DEBUG 2018-10-25 04:12:18,840 cleverhans]     Iteration 100 of 500: loss=3.37 l2=1.78\n",
      "[DEBUG 2018-10-25 04:12:20,548 cleverhans]     Iteration 150 of 500: loss=3.37 l2=1.78\n",
      "[DEBUG 2018-10-25 04:12:22,266 cleverhans]     Iteration 200 of 500: loss=3.33 l2=1.79\n",
      "[DEBUG 2018-10-25 04:12:23,991 cleverhans]     Iteration 250 of 500: loss=3.24 l2=1.83\n",
      "[DEBUG 2018-10-25 04:12:25,681 cleverhans]     Iteration 300 of 500: loss=3.1 l2=1.89\n",
      "[DEBUG 2018-10-25 04:12:27,390 cleverhans]     Iteration 350 of 500: loss=2.94 l2=1.94\n",
      "[DEBUG 2018-10-25 04:12:29,077 cleverhans]     Iteration 400 of 500: loss=2.8 l2=1.99\n",
      "[DEBUG 2018-10-25 04:12:30,793 cleverhans]     Iteration 450 of 500: loss=2.67 l2=2.02\n",
      "[DEBUG 2018-10-25 04:12:32,486 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 04:12:32,487 cleverhans]    Mean successful distortion: 1.444\n",
      "[DEBUG 2018-10-25 04:12:32,488 cleverhans]   Binary search step 5 of 10\n",
      "[DEBUG 2018-10-25 04:12:32,504 cleverhans]     Iteration 0 of 500: loss=5.45 l2=0\n",
      "[DEBUG 2018-10-25 04:12:34,300 cleverhans]     Iteration 50 of 500: loss=3.43 l2=1.77\n",
      "[DEBUG 2018-10-25 04:12:36,046 cleverhans]     Iteration 100 of 500: loss=3.39 l2=1.77\n",
      "[DEBUG 2018-10-25 04:12:37,823 cleverhans]     Iteration 150 of 500: loss=3.39 l2=1.77\n",
      "[DEBUG 2018-10-25 04:12:39,526 cleverhans]     Iteration 200 of 500: loss=3.36 l2=1.79\n",
      "[DEBUG 2018-10-25 04:12:41,228 cleverhans]     Iteration 250 of 500: loss=3.27 l2=1.82\n",
      "[DEBUG 2018-10-25 04:12:42,931 cleverhans]     Iteration 300 of 500: loss=3.13 l2=1.89\n",
      "[DEBUG 2018-10-25 04:12:44,656 cleverhans]     Iteration 350 of 500: loss=2.99 l2=1.96\n",
      "[DEBUG 2018-10-25 04:12:46,356 cleverhans]     Iteration 400 of 500: loss=2.84 l2=2.05\n",
      "[DEBUG 2018-10-25 04:12:48,059 cleverhans]     Iteration 450 of 500: loss=2.69 l2=2.1\n",
      "[DEBUG 2018-10-25 04:12:49,734 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 04:12:49,735 cleverhans]    Mean successful distortion: 1.443\n",
      "[DEBUG 2018-10-25 04:12:49,737 cleverhans]   Binary search step 6 of 10\n",
      "[DEBUG 2018-10-25 04:12:49,753 cleverhans]     Iteration 0 of 500: loss=5.42 l2=0\n",
      "[DEBUG 2018-10-25 04:12:51,519 cleverhans]     Iteration 50 of 500: loss=3.44 l2=1.75\n",
      "[DEBUG 2018-10-25 04:12:53,285 cleverhans]     Iteration 100 of 500: loss=3.4 l2=1.75\n",
      "[DEBUG 2018-10-25 04:12:55,049 cleverhans]     Iteration 150 of 500: loss=3.39 l2=1.76\n",
      "[DEBUG 2018-10-25 04:12:56,803 cleverhans]     Iteration 200 of 500: loss=3.36 l2=1.77\n",
      "[DEBUG 2018-10-25 04:12:58,568 cleverhans]     Iteration 250 of 500: loss=3.28 l2=1.8\n",
      "[DEBUG 2018-10-25 04:13:00,360 cleverhans]     Iteration 300 of 500: loss=3.14 l2=1.88\n",
      "[DEBUG 2018-10-25 04:13:02,135 cleverhans]     Iteration 350 of 500: loss=3 l2=1.95\n",
      "[DEBUG 2018-10-25 04:13:03,888 cleverhans]     Iteration 400 of 500: loss=2.85 l2=2.04\n",
      "[DEBUG 2018-10-25 04:13:05,611 cleverhans]     Iteration 450 of 500: loss=2.7 l2=2.13\n",
      "[DEBUG 2018-10-25 04:13:07,298 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 04:13:07,299 cleverhans]    Mean successful distortion: 1.443\n",
      "[DEBUG 2018-10-25 04:13:07,300 cleverhans]   Binary search step 7 of 10\n",
      "[DEBUG 2018-10-25 04:13:07,317 cleverhans]     Iteration 0 of 500: loss=5.42 l2=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DEBUG 2018-10-25 04:13:09,058 cleverhans]     Iteration 50 of 500: loss=3.44 l2=1.76\n",
      "[DEBUG 2018-10-25 04:13:10,787 cleverhans]     Iteration 100 of 500: loss=3.41 l2=1.76\n",
      "[DEBUG 2018-10-25 04:13:12,587 cleverhans]     Iteration 150 of 500: loss=3.4 l2=1.76\n",
      "[DEBUG 2018-10-25 04:13:14,397 cleverhans]     Iteration 200 of 500: loss=3.37 l2=1.78\n",
      "[DEBUG 2018-10-25 04:13:16,151 cleverhans]     Iteration 250 of 500: loss=3.29 l2=1.81\n",
      "[DEBUG 2018-10-25 04:13:17,863 cleverhans]     Iteration 300 of 500: loss=3.15 l2=1.88\n",
      "[DEBUG 2018-10-25 04:13:19,613 cleverhans]     Iteration 350 of 500: loss=3 l2=1.96\n",
      "[DEBUG 2018-10-25 04:13:21,312 cleverhans]     Iteration 400 of 500: loss=2.85 l2=2.06\n",
      "[DEBUG 2018-10-25 04:13:23,013 cleverhans]     Iteration 450 of 500: loss=2.71 l2=2.15\n",
      "[DEBUG 2018-10-25 04:13:24,705 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 04:13:24,706 cleverhans]    Mean successful distortion: 1.442\n",
      "[DEBUG 2018-10-25 04:13:24,707 cleverhans]   Binary search step 8 of 10\n",
      "[DEBUG 2018-10-25 04:13:24,724 cleverhans]     Iteration 0 of 500: loss=5.42 l2=0\n",
      "[DEBUG 2018-10-25 04:13:26,513 cleverhans]     Iteration 50 of 500: loss=3.44 l2=1.76\n",
      "[DEBUG 2018-10-25 04:13:28,304 cleverhans]     Iteration 100 of 500: loss=3.4 l2=1.77\n",
      "[DEBUG 2018-10-25 04:13:30,052 cleverhans]     Iteration 150 of 500: loss=3.39 l2=1.77\n",
      "[DEBUG 2018-10-25 04:13:31,829 cleverhans]     Iteration 200 of 500: loss=3.36 l2=1.79\n",
      "[DEBUG 2018-10-25 04:13:33,607 cleverhans]     Iteration 250 of 500: loss=3.28 l2=1.81\n",
      "[DEBUG 2018-10-25 04:13:35,352 cleverhans]     Iteration 300 of 500: loss=3.15 l2=1.88\n",
      "[DEBUG 2018-10-25 04:13:37,115 cleverhans]     Iteration 350 of 500: loss=3 l2=1.96\n",
      "[DEBUG 2018-10-25 04:13:38,852 cleverhans]     Iteration 400 of 500: loss=2.86 l2=2.05\n",
      "[DEBUG 2018-10-25 04:13:40,559 cleverhans]     Iteration 450 of 500: loss=2.71 l2=2.15\n",
      "[DEBUG 2018-10-25 04:13:42,254 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 04:13:42,255 cleverhans]    Mean successful distortion: 1.442\n",
      "[DEBUG 2018-10-25 04:13:42,257 cleverhans]   Binary search step 9 of 10\n",
      "[DEBUG 2018-10-25 04:13:42,273 cleverhans]     Iteration 0 of 500: loss=5.46 l2=0\n",
      "[DEBUG 2018-10-25 04:13:44,027 cleverhans]     Iteration 50 of 500: loss=3.44 l2=1.81\n",
      "[DEBUG 2018-10-25 04:13:45,772 cleverhans]     Iteration 100 of 500: loss=3.39 l2=1.82\n",
      "[DEBUG 2018-10-25 04:13:47,509 cleverhans]     Iteration 150 of 500: loss=3.38 l2=1.82\n",
      "[DEBUG 2018-10-25 04:13:49,298 cleverhans]     Iteration 200 of 500: loss=3.36 l2=1.84\n",
      "[DEBUG 2018-10-25 04:13:51,101 cleverhans]     Iteration 250 of 500: loss=3.27 l2=1.87\n",
      "[DEBUG 2018-10-25 04:13:52,882 cleverhans]     Iteration 300 of 500: loss=3.12 l2=1.94\n",
      "[DEBUG 2018-10-25 04:13:54,659 cleverhans]     Iteration 350 of 500: loss=2.98 l2=2.02\n",
      "[DEBUG 2018-10-25 04:13:56,381 cleverhans]     Iteration 400 of 500: loss=2.82 l2=2.13\n",
      "[DEBUG 2018-10-25 04:13:58,097 cleverhans]     Iteration 450 of 500: loss=2.66 l2=2.23\n",
      "[DEBUG 2018-10-25 04:13:59,738 cleverhans]   Successfully generated adversarial examples on 1000 of 1000 instances.\n",
      "[DEBUG 2018-10-25 04:13:59,739 cleverhans]    Mean successful distortion: 1.442\n"
     ]
    }
   ],
   "source": [
    "keras.backend.set_learning_phase(0)\n",
    "set_log_level(logging.DEBUG)\n",
    "\n",
    "# CarliniWagner attack\n",
    "from lib.my_cw import CarliniWagnerL2\n",
    "\n",
    "attack_iterations = 500\n",
    "cw_params = {'binary_search_steps': 10,\n",
    "             'max_iterations': attack_iterations,\n",
    "             'learning_rate': 0.1,\n",
    "             'batch_size': n_attack,\n",
    "             'initial_const': 1}\n",
    "cw = CarliniWagnerL2(hingenet, sess=sess)\n",
    "adv = cw.generate_np(X_atk, **cw_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = hingenet.predict_model(sess, adv)\n",
    "\n",
    "for x, y in zip(adv[:10], y_pred[:10]):\n",
    "    print(np.argmax(y))\n",
    "    print(y)\n",
    "    plt.imshow(x[:, :, 0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "del hingenet.model\n",
    "del hingenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.global_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import (Activation, Dense, Flatten, Lambda, Conv2D, Input,\n",
    "                          MaxPooling2D, Reshape, Concatenate, Cropping2D, Add,\n",
    "                          Dropout)\n",
    "\n",
    "inpt = Input(shape=(28, 28, 1))\n",
    "conv1 = Conv2D(32, (5, 5), activation='relu')(inpt)\n",
    "conv2 = Conv2D(64, (3, 3), activation='relu')(conv1)\n",
    "conv3 = Conv2D(128, (3, 3), activation='relu')(conv2)\n",
    "flat = Flatten()(conv3)\n",
    "dense1 = Dense(512, activation='relu')(flat)\n",
    "drop1 = Dropout(0.25)(dense1)\n",
    "dense2 = Dense(128, activation='relu')(drop1)\n",
    "drop2 = Dropout(0.5)(dense2)\n",
    "output = Dense(10, activation=None)(drop2)\n",
    "model = keras.models.Model(inputs=inpt, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"model/softmax_xent.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import foolbox\n",
    "\n",
    "# instantiate model\n",
    "keras.backend.set_learning_phase(0)\n",
    "kmodel = model\n",
    "preprocessing = (np.array([0, 0, 0]), 1)\n",
    "fmodel = foolbox.models.KerasModel(kmodel, bounds=(0, 1), \n",
    "                                   preprocessing=preprocessing,\n",
    "                                   predicts='logits')\n",
    "\n",
    "# apply attack on source image\n",
    "# attack = foolbox.attacks.FGSM(fmodel)\n",
    "# adv = attack(X_atk[0], label=y_atk[0], unpack=True, epsilons=1000, max_epsilon=1)\n",
    "\n",
    "# from foolbox.attacks import LBFGSAttack\n",
    "# from foolbox.criteria import TargetClassProbability\n",
    "\n",
    "# criterion = TargetClassProbability(6, p=0.99)\n",
    "# attack = LBFGSAttack(fmodel, criterion)\n",
    "# adv = attack(X_atk[0], label=y_atk[0])\n",
    "\n",
    "from foolbox.attacks import BoundaryAttack\n",
    "from foolbox.criteria import TargetClassProbability\n",
    "\n",
    "criterion = TargetClassProbability(6, p=0.99)\n",
    "attack = BoundaryAttack(fmodel, criterion)\n",
    "adv = attack(X_atk[0], label=y_atk[0],\n",
    "             iterations=5000, max_directions=25, starting_point=X_atk[11], \n",
    "             initialization_attack=None, log_every_n_steps=1, \n",
    "             spherical_step=0.01, source_step=0.01, step_adaptation=1.5, \n",
    "             batch_size=1, tune_batch_size=True, threaded_rnd=True, \n",
    "             threaded_gen=True, alternative_generator=False, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X_atk[0][np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(adv[np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.square(adv - X_atk[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(adv[:, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_atk[0, :, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_atk[11, :, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
